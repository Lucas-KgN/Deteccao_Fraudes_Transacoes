<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Deteccao_Fraude_Transacoes</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0px solid transparent;
  border-right: 0px solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0px solid transparent;
  border-bottom: 0px solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
	border:1px solid transparent;
  background-color: transparent;
  position: absolute;
	z-index:1;
	right:3%;
	top: 0;
	bottom: 0;
	margin: auto;
	padding: 7px 0;
	display: none;
	vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
	content: "X";
	display: block;
	width: 15px;
	height: 15px;
	text-align: center;
	color:#000;
	font-weight: normal;
	font-size: 12px;
	cursor: pointer;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing : border-box;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing : border-box;
  background: inherit;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-bottom:10px;
  margin-top:0; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  font-size:36px;
  line-height:40px; }

h2.bp3-heading, .bp3-running-text h2{
  font-size:28px;
  line-height:32px; }

h3.bp3-heading, .bp3-running-text h3{
  font-size:22px;
  line-height:25px; }

h4.bp3-heading, .bp3-running-text h4{
  font-size:18px;
  line-height:21px; }

h5.bp3-heading, .bp3-running-text h5{
  font-size:16px;
  line-height:19px; }

h6.bp3-heading, .bp3-running-text h6{
  font-size:14px;
  line-height:16px; }
.bp3-ui-text{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none; }

.bp3-monospace-text{
  font-family:monospace;
  text-transform:none; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  font-size:14px;
  line-height:1.5; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15);
    margin:20px 0; }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  color:#106ba3;
  text-decoration:none; }
  a:hover{
    color:#106ba3;
    cursor:pointer;
    text-decoration:underline; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  font-size:smaller;
  padding:2px 5px; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  color:#182026;
  display:block;
  font-size:13px;
  line-height:1.4;
  margin:10px 0;
  padding:13px 15px 12px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit;
    font-size:inherit;
    padding:0; }

.bp3-running-text kbd, .bp3-key{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-family:inherit;
  font-size:12px;
  height:24px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  line-height:24px;
  min-width:24px;
  padding:3px 6px;
  vertical-align:middle; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  margin:0 0 10px;
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    font-size:40px;
    margin-right:20px;
    margin-top:0; }

.bp3-alert-contents{
  word-break:break-word; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  cursor:default;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  height:30px;
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-breadcrumbs > li{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }
    .bp3-breadcrumbs > li::after{
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 00-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 001.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      content:"";
      display:block;
      height:16px;
      margin:0 5px;
      width:16px; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    font-size:inherit;
    font-weight:inherit;
    vertical-align:baseline; }

.bp3-breadcrumbs-collapsed{
  background:#ced9e0;
  border:none;
  border-radius:3px;
  cursor:pointer;
  margin-right:2px;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    content:"";
    display:block;
    height:16px;
    width:16px; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    color:#182026;
    text-decoration:none; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  min-height:30px;
  min-width:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      background-color:#106ba3;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      background-color:#0e5a8a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      background-color:#0d8050;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      background-color:#0a6640;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      background-color:#bf7326;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      background-color:#a66321;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      background-color:#c23030;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      background-color:#a82a2a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-height:40px;
    min-width:40px;
    font-size:16px;
    padding:5px 15px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      margin:0;
      position:absolute; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button.bp3-minimal:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button.bp3-outlined{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    border:1px solid rgba(24, 32, 38, 0.2);
    -webkit-box-sizing:border-box;
            box-sizing:border-box; }
    .bp3-button.bp3-outlined:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-outlined:active, .bp3-button.bp3-outlined.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-outlined{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-outlined:hover, .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-outlined:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover, .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover, .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover, .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover, .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled:hover{
      border-color:rgba(92, 112, 128, 0.1); }
    .bp3-dark .bp3-button.bp3-outlined{
      border-color:rgba(255, 255, 255, 0.4); }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        border-color:rgba(255, 255, 255, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      border-color:rgba(16, 107, 163, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        border-color:rgba(16, 107, 163, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        border-color:rgba(72, 175, 240, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          border-color:rgba(72, 175, 240, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      border-color:rgba(13, 128, 80, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        border-color:rgba(13, 128, 80, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        border-color:rgba(61, 204, 145, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          border-color:rgba(61, 204, 145, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      border-color:rgba(191, 115, 38, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        border-color:rgba(191, 115, 38, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        border-color:rgba(255, 179, 102, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          border-color:rgba(255, 179, 102, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      border-color:rgba(194, 48, 48, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        border-color:rgba(194, 48, 48, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        border-color:rgba(255, 115, 115, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          border-color:rgba(255, 115, 115, 0.2); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    border-bottom-right-radius:0;
    border-top-right-radius:0;
    margin-right:-1px; }
  .bp3-button-group.bp3-minimal .bp3-button{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      height:100%;
      width:unset; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  font-size:14px;
  line-height:1.5;
  background-color:rgba(138, 155, 168, 0.15);
  border-radius:3px;
  padding:10px 12px 9px;
  position:relative;
  width:100%; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout .bp3-heading{
    line-height:20px;
    margin-bottom:5px;
    margin-top:0; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  opacity:0.9;
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  width:100%; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }

.bp3-dialog{
  background:#ebf1f5;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text;
  width:500px; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    background:#293742;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-dialog-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding-left:20px;
  padding-right:5px;
  z-index:30; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    background:#30404d;
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  margin:20px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-multistep-dialog-panels{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }

.bp3-multistep-dialog-left-panel{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:1;
      -ms-flex:1;
          flex:1;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column; }
  .bp3-dark .bp3-multistep-dialog-left-panel{
    background:#202b33; }

.bp3-multistep-dialog-right-panel{
  background-color:#f5f8fa;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  border-radius:0 0 6px 0;
  -webkit-box-flex:3;
      -ms-flex:3;
          flex:3;
  min-width:0; }
  .bp3-dark .bp3-multistep-dialog-right-panel{
    background-color:#293742;
    border-left:1px solid rgba(16, 22, 26, 0.4); }

.bp3-multistep-dialog-footer{
  background-color:#ffffff;
  border-radius:0 0 6px 0;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  padding:10px; }
  .bp3-dark .bp3-multistep-dialog-footer{
    background:#30404d;
    border-top:1px solid rgba(16, 22, 26, 0.4); }

.bp3-dialog-step-container{
  background-color:#f5f8fa;
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-dialog-step-container{
    background:#293742;
    border-bottom:1px solid rgba(16, 22, 26, 0.4); }
  .bp3-dialog-step-container.bp3-dialog-step-viewed{
    background-color:#ffffff; }
    .bp3-dark .bp3-dialog-step-container.bp3-dialog-step-viewed{
      background:#30404d; }

.bp3-dialog-step{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:#f5f8fa;
  border-radius:6px;
  cursor:not-allowed;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin:4px;
  padding:6px 14px; }
  .bp3-dark .bp3-dialog-step{
    background:#293742; }
  .bp3-dialog-step-viewed .bp3-dialog-step{
    background-color:#ffffff;
    cursor:pointer; }
    .bp3-dark .bp3-dialog-step-viewed .bp3-dialog-step{
      background:#30404d; }
  .bp3-dialog-step:hover{
    background-color:#f5f8fa; }
    .bp3-dark .bp3-dialog-step:hover{
      background:#293742; }

.bp3-dialog-step-icon{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:rgba(92, 112, 128, 0.6);
  border-radius:50%;
  color:#ffffff;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:25px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:25px; }
  .bp3-dark .bp3-dialog-step-icon{
    background-color:rgba(167, 182, 194, 0.6); }
  .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-icon{
    background-color:#2b95d6; }
  .bp3-dialog-step-viewed .bp3-dialog-step-icon{
    background-color:#8a9ba8; }

.bp3-dialog-step-title{
  color:rgba(92, 112, 128, 0.6);
  -webkit-box-flex:1;
      -ms-flex:1;
          flex:1;
  padding-left:10px; }
  .bp3-dark .bp3-dialog-step-title{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-title{
    color:#2b95d6; }
  .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{
    color:#182026; }
    .bp3-dark .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{
      color:#f5f8fa; }
.bp3-drawer{
  background:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    height:50%;
    left:0;
    right:0;
    top:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-bottom{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-left{
    bottom:0;
    left:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-right{
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    background:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-drawer-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding:5px;
  padding-left:20px;
  position:relative; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  overflow:auto; }

.bp3-drawer-footer{
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  padding:10px 20px;
  position:relative; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  cursor:text;
  display:inline-block;
  max-width:100%;
  position:relative;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    bottom:-3px;
    left:-3px;
    position:absolute;
    right:-3px;
    top:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  color:inherit;
  display:inherit;
  font:inherit;
  letter-spacing:inherit;
  max-width:inherit;
  min-width:inherit;
  position:relative;
  resize:none;
  text-transform:inherit;
  vertical-align:top; }

.bp3-editable-text-input{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0;
  white-space:pre-wrap;
  width:100%; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    left:0;
    position:absolute;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    border-radius:inherit;
    z-index:2; }
    .bp3-control-group .bp3-input:focus{
      border-radius:3px;
      z-index:14; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    border-radius:inherit;
    z-index:4; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-left-container,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group .bp3-select:focus-within{
    z-index:5; }
  .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:-1px; }
  .bp3-control-group:not(.bp3-vertical) > .bp3-divider:not(:first-child){
    margin-left:6px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    border-radius:0 3px 3px 0;
    margin-right:0; }
  .bp3-control-group > :only-child{
    border-radius:3px;
    margin-right:0; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group .bp3-numeric-input:not(:first-child) .bp3-input-group{
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-control-group.bp3-fill{
    width:100%; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      border-radius:3px 3px 0 0;
      margin-top:0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  cursor:pointer;
  display:block;
  margin-bottom:10px;
  position:relative;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    left:0;
    opacity:0;
    position:absolute;
    top:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    cursor:pointer;
    display:inline-block;
    font-size:16px;
    height:1em;
    margin-right:10px;
    margin-top:-3px;
    position:relative;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none;
    vertical-align:middle;
    width:1em; }
    .bp3-control .bp3-control-indicator::before{
      content:"";
      display:block;
      height:1em;
      width:1em; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    background:#d8e1e8;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-left:10px;
    margin-top:1px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 00-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0012 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:auto; }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      background:#ffffff;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      height:calc(1em - 4px);
      left:0;
      margin:2px;
      position:absolute;
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      width:calc(1em - 4px); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    font-size:0.7em;
    text-align:center; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    line-height:0;
    margin-left:0.5em;
    margin-right:1.2em;
    visibility:hidden; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    line-height:1em;
    margin-left:1.2em;
    margin-right:0.5em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    line-height:1em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    line-height:0;
    visibility:hidden; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      background:#202b33;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  cursor:pointer;
  display:inline-block;
  height:30px;
  position:relative; }
  .bp3-file-input input{
    margin:0;
    min-width:200px;
    opacity:0; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      background:rgba(206, 217, 224, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(92, 112, 128, 0.6);
        cursor:not-allowed;
        outline:none; }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        background:rgba(57, 75, 89, 0.5);
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          -webkit-box-shadow:none;
                  box-shadow:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:rgba(92, 112, 128, 0.6);
  left:0;
  padding-right:80px;
  position:absolute;
  right:0;
  top:0;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-file-upload-input::after{
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026;
    min-height:24px;
    min-width:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    border-radius:3px;
    content:"Browse";
    line-height:24px;
    margin:3px;
    position:absolute;
    right:0;
    text-align:center;
    top:0;
    width:70px; }
    .bp3-file-upload-input::after:hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-file-upload-input:active::after{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-large .bp3-file-upload-input{
    font-size:16px;
    height:40px;
    line-height:40px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-height:30px;
      min-width:30px;
      line-height:30px;
      margin:5px;
      width:85px; }
  .bp3-dark .bp3-file-upload-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        background-color:#30404d;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        background-color:#202b33;
        background-image:none;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:active::after{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    color:#5c7080;
    font-size:12px;
    margin-top:5px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      line-height:40px;
      margin:0 10px 0 0; }
    .bp3-form-group.bp3-inline label.bp3-label{
      line-height:30px;
      margin:0 10px 0 0; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-input-left-container:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-input-left-container:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-height:24px;
    min-width:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-icon{
    z-index:1; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon{
    color:#5c7080; }
    .bp3-input-group > .bp3-input-left-container > .bp3-icon:empty,
    .bp3-input-group > .bp3-icon:empty{
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-height:30px;
    min-width:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle; }
  .bp3-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-input.bp3-large{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-bottom:15px;
  margin-top:0; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    font-weight:400;
    vertical-align:top;
    width:100%; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  min-height:0;
  padding:0;
  width:30px; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  -moz-appearance:none;
  -webkit-appearance:none;
  border-radius:3px;
  height:30px;
  padding:0 25px 0 10px;
  width:100%; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  background:none;
  -webkit-box-shadow:none;
          box-shadow:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    background:rgba(167, 182, 194, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026;
    text-decoration:none; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    background:rgba(115, 134, 148, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      color:rgba(167, 182, 194, 0.6);
      cursor:not-allowed; }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  font-size:16px;
  height:40px;
  padding-right:35px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    background-color:#202b33;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  background-color:rgba(206, 217, 224, 0.5);
  -webkit-box-shadow:none;
          box-shadow:none;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  color:#5c7080;
  pointer-events:none;
  position:absolute;
  right:7px;
  top:7px; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  letter-spacing:normal;
  position:relative;
  vertical-align:middle; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    right:12px;
    top:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select option:disabled, .bp3-dark
  .bp3-select option:disabled{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    text-align:left;
    vertical-align:top; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td,
  .bp3-running-text table tfoot tr:first-child th,
  table.bp3-html-table tfoot tr:first-child th,
  .bp3-running-text table tfoot tr:first-child td,
  table.bp3-html-table tfoot tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td,
  .bp3-dark .bp3-running-text table tfoot tr:first-child th,
  .bp3-running-text .bp3-dark table tfoot tr:first-child th,
  .bp3-dark table.bp3-html-table tfoot tr:first-child th,
  .bp3-dark .bp3-running-text table tfoot tr:first-child td,
  .bp3-running-text .bp3-dark table tfoot tr:first-child td,
  .bp3-dark table.bp3-html-table tfoot tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-bottom:6px;
  padding-top:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td,
table.bp3-html-table.bp3-html-table-bordered tfoot tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),
  table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table{ }
  .bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
    background:rgba(92, 112, 128, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td,
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){
      -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
              box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
    background-color:rgba(92, 112, 128, 0.3);
    cursor:pointer; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
    background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  padding-bottom:0;
  top:40px; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-left:0;
  margin-right:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  font-family:"Icons20";
  font-size:inherit;
  font-style:normal;
  font-weight:400;
  line-height:1; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagnosis::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-lab-test::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }
  .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{ }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  background:#ffffff;
  border-radius:3px;
  color:#182026;
  list-style:none;
  margin:0;
  min-width:180px;
  padding:5px;
  text-align:left; }

.bp3-menu-divider{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px; }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  color:inherit;
  line-height:20px;
  padding:5px 7px;
  text-decoration:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    color:#5c7080;
    margin-top:2px; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit !important;
    color:rgba(92, 112, 128, 0.6) !important;
    cursor:not-allowed !important;
    outline:none !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    font-size:16px;
    line-height:22px;
    padding:9px 7px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-right:10px;
      margin-top:1px; }

button.bp3-menu-item{
  background:none;
  border:none;
  text-align:left;
  width:100%; }
.bp3-menu-header{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px;
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    line-height:17px;
    margin:0;
    padding:10px 7px 0 1px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    font-size:18px;
    padding-bottom:5px;
    padding-top:15px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item{ }
  .bp3-dark .bp3-menu-item.bp3-intent-primary{
    color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-success{
    color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning{
    color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger{
    color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item::before,
  .bp3-dark .bp3-menu-item > .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item .bp3-menu-item-label{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
    background-color:rgba(138, 155, 168, 0.3); }
  .bp3-dark .bp3-menu-item.bp3-disabled{
    color:rgba(167, 182, 194, 0.6) !important; }
    .bp3-dark .bp3-menu-item.bp3-disabled::before,
    .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  background-color:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  height:50px;
  padding:0 15px;
  position:relative;
  width:100%;
  z-index:10; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    left:0;
    position:fixed;
    right:0;
    top:0; }

.bp3-navbar-heading{
  font-size:16px;
  margin-right:15px; }

.bp3-navbar-group{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px;
  margin:0 10px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:100%;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  text-align:center;
  width:100%; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  bottom:0;
  left:0;
  position:static;
  right:0;
  top:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    overflow:hidden;
    position:fixed; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    overflow:auto;
    position:fixed; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  bottom:0;
  left:0;
  position:fixed;
  right:0;
  top:0;
  opacity:1;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  z-index:20; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  overflow:hidden;
  position:relative; }

.bp3-panel-stack-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  height:30px;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  bottom:0;
  left:0;
  position:absolute;
  right:0;
  top:0;
  background-color:#ffffff;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  overflow-y:auto;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }
  .bp3-panel-stack-view:nth-last-child(n + 4){
    display:none; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }
.bp3-panel-stack2{
  overflow:hidden;
  position:relative; }

.bp3-panel-stack2-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  height:30px;
  z-index:1; }
  .bp3-dark .bp3-panel-stack2-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack2-header > span{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1; }
  .bp3-panel-stack2-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack2-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack2-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack2-view{
  bottom:0;
  left:0;
  position:absolute;
  right:0;
  top:0;
  background-color:#ffffff;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  overflow-y:auto;
  z-index:1; }
  .bp3-dark .bp3-panel-stack2-view{
    background-color:#30404d; }
  .bp3-panel-stack2-view:nth-last-child(n + 4){
    display:none; }

.bp3-panel-stack2-push .bp3-panel-stack2-enter, .bp3-panel-stack2-push .bp3-panel-stack2-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack2-push .bp3-panel-stack2-enter-active, .bp3-panel-stack2-push .bp3-panel-stack2-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-push .bp3-panel-stack2-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack2-push .bp3-panel-stack2-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-pop .bp3-panel-stack2-enter, .bp3-panel-stack2-pop .bp3-panel-stack2-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack2-pop .bp3-panel-stack2-enter-active, .bp3-panel-stack2-pop .bp3-panel-stack2-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-pop .bp3-panel-stack2-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack2-pop .bp3-panel-stack2-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  border-radius:3px;
  display:inline-block;
  z-index:20; }
  .bp3-popover .bp3-popover-arrow{
    height:30px;
    position:absolute;
    width:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      height:20px;
      margin:5px;
      width:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-bottom:17px;
    margin-top:-17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-left:-17px;
    margin-right:17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover .bp3-popover-content{
    border-radius:3px;
    position:relative; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  border-radius:2px;
  content:"";
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg); }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  left:0;
  position:absolute;
  right:0;
  top:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  background:rgba(92, 112, 128, 0.2);
  border-radius:40px;
  display:block;
  height:8px;
  overflow:hidden;
  position:relative;
  width:100%; }
  .bp3-progress-bar .bp3-progress-meter{
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    border-radius:40px;
    height:100%;
    position:absolute;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:100%; }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  color:transparent !important;
  cursor:default;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  height:40px;
  min-width:150px;
  width:100%;
  cursor:default;
  outline:none;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    cursor:not-allowed;
    opacity:0.5; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  height:6px;
  left:0;
  right:0;
  top:5px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  height:16px;
  left:0;
  position:absolute;
  top:0;
  width:16px; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab;
    z-index:2; }
  .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    background:#bfccd6;
    -webkit-box-shadow:none;
            box-shadow:none;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    background:#5c7080;
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-slider-handle .bp3-slider-label{
    background:#394b59;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    color:#f5f8fa;
    margin-left:8px; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      background:#e1e8ed;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-bottom-right-radius:0;
    border-top-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    border-bottom-left-radius:0;
    border-top-left-radius:0;
    margin-left:8px; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  font-size:12px;
  line-height:1;
  padding:2px 5px;
  position:absolute;
  vertical-align:top; }

.bp3-slider.bp3-vertical{
  height:150px;
  min-width:40px;
  width:40px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    bottom:0;
    height:auto;
    left:5px;
    top:0;
    width:6px; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-left:0;
      margin-top:-8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      height:8px;
      margin-left:0;
      width:16px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-bottom-right-radius:3px;
      border-top-left-radius:0; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      border-bottom-left-radius:0;
      border-bottom-right-radius:0;
      border-top-left-radius:3px;
      margin-bottom:8px; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round;
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      padding:0 10px;
      width:100%; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        background-color:rgba(19, 124, 189, 0.2);
        -webkit-box-shadow:none;
                box-shadow:none; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      background-color:rgba(19, 124, 189, 0.2);
      border-radius:3px;
      bottom:0;
      height:auto;
      left:0;
      right:0;
      top:0; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  border:none;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  list-style:none;
  margin:0;
  padding:0;
  position:relative; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:#182026;
  cursor:pointer;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  font-size:14px;
  line-height:30px;
  max-width:100%;
  position:relative;
  vertical-align:top; }
  .bp3-tab a{
    color:inherit;
    display:block;
    text-decoration:none; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    background-color:transparent !important;
    -webkit-box-shadow:none !important;
            box-shadow:none !important; }
  .bp3-tab[aria-disabled="true"]{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    font-size:16px;
    line-height:40px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  left:0;
  pointer-events:none;
  position:absolute;
  top:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    background-color:#106ba3;
    bottom:0;
    height:3px;
    left:0;
    position:absolute;
    right:0; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:#5c7080;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  color:#f5f8fa;
  font-size:12px;
  line-height:16px;
  max-width:100%;
  min-height:20px;
  min-width:20px;
  padding:2px 6px;
  position:relative; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-left:8px;
    padding-right:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    font-size:14px;
    line-height:20px;
    min-height:30px;
    min-width:30px;
    padding:5px 10px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-left:12px;
      padding-right:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  background:none;
  border:none;
  color:inherit;
  cursor:pointer;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin-bottom:-2px;
  margin-right:-6px !important;
  margin-top:-2px;
  opacity:0.5;
  padding:2px;
  padding-left:0; }
  .bp3-tag-remove:hover{
    background:none;
    opacity:0.8;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:0 5px 0 0; }
    .bp3-large .bp3-tag-remove:empty::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  line-height:inherit;
  min-height:30px;
  padding-left:5px;
  padding-right:0; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    color:#5c7080;
    margin-left:2px;
    margin-right:7px;
    margin-top:7px; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    margin-right:7px;
    margin-top:5px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:20px;
    width:80px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-left:5px;
      margin-top:10px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-height:30px;
      min-width:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin:20px 0 0;
  max-width:500px;
  min-width:300px;
  pointer-events:all;
  position:relative !important; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-delay:50ms;
            transition-delay:50ms;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    color:#5c7080;
    margin:12px;
    margin-right:0; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    background-color:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  left:0;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none;
  right:0;
  z-index:40; }
  .bp3-toast-container.bp3-toast-container-in-portal{
    position:fixed; }
  .bp3-toast-container.bp3-toast-container-inline{
    position:absolute; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0; }
  .bp3-toast-container.bp3-toast-container-bottom{
    bottom:0;
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-exit-active ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    height:22px;
    position:absolute;
    width:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      height:14px;
      margin:4px;
      width:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-bottom:11px;
    margin-top:-11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-left:-11px;
    margin-right:11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  list-style:none;
  margin:0;
  padding-left:0; }

.bp3-tree-root{
  background-color:transparent;
  cursor:default;
  padding-left:0;
  position:relative; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:30px;
  padding-right:5px;
  width:100%; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  cursor:pointer;
  padding:7px;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  margin-right:7px;
  position:relative; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  left:calc(50% - 250px);
  top:20vh;
  width:500px;
  z-index:21; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar .bp3-input{
    background-color:transparent;
    border-radius:0; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    background-color:transparent;
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}
.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}
.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}
.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-border-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0px;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-warn-color0);
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px 5px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FileDialog-Checkbox {
  margin-top: 35px;
  display: flex;
  flex-direction: row;
  align-items: end;
  width: 100%;
}

.jp-FileDialog-Checkbox > label {
  flex: 1 1 auto;
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
  overflow-x: auto;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 50px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -50px; margin-right: -50px;
  padding-bottom: 50px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 50px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
  outline: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -50px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .remote-caret {
  position: relative;
  border-left: 2px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .remote-caret > div {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -2px;
  font-size: 0.95em;
  background-color: rgb(250, 129, 0);
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 3;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .remote-caret.hide-name > div {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .remote-caret:hover > div {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
  margin: 8px 12px 0px 12px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: flex-start;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0px;
  padding-right: 2px;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 40px;
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent {
  width: 72px;
  background: var(--jp-brand-color1);
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent:focus-visible {
  background-color: var(--jp-brand-color0);
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent
  .jp-icon3 {
  fill: white;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileBrowser-filterBox {
  padding: 0px;
  flex: 0 0 auto;
  margin: 8px 12px 0px 12px;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing:focus-visible {
  border: 1px solid var(--jp-brand-color1);
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon:before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

body[data-format='mobile'] .jp-OutputArea-child {
  flex-direction: column;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

body[data-format='mobile'] .jp-OutputPrompt {
  flex: 0 0 auto;
  text-align: left;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

body[data-format='mobile'] .jp-OutputArea-child .jp-OutputArea-output {
  margin-left: var(--jp-notebook-padding);
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
  overflow: hidden;
}

body[data-format='mobile'] .jp-InputArea {
  flex-direction: column;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
  overflow: hidden;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

body[data-format='mobile'] .jp-InputArea-editor {
  margin-left: var(--jp-notebook-padding);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

body[data-format='mobile'] .jp-InputPrompt {
  flex: 0 0 auto;
  text-align: left;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

.jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
}

.jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-collapseHeadingButton {
  display: none;
}

.jp-MarkdownCell:hover .jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  position: absolute;
  right: 0;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook-render * {
  contain: none !important;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
  float: left;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt:before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body div {
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

.highlight  {
  margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.CodeMirror pre {
  margin: 0;
  padding: 0;
}

/* Using table instead of flexbox so that we can use break-inside property */
/* CSS rules under this comment should not be required anymore after we move to the JupyterLab 4.0 CSS */


.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  min-width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-OutputArea-child {
  display: table;
  width: 100%;
}

.jp-OutputPrompt {
  display: table-cell;
  vertical-align: top;
  min-width: var(--jp-cell-prompt-width);
}

body[data-format='mobile'] .jp-OutputPrompt {
  display: table-row;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
}

body[data-format='mobile'] .jp-OutputArea-child .jp-OutputArea-output {
  display: table-row;
}

.jp-OutputArea-output.jp-OutputArea-executeResult {
  width: 100%;
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }

  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}
</style>

<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">

<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Detec%C3%A7%C3%A3o-de-fraude-em-transa%C3%A7%C3%B5es-de-cart%C3%A3o-de-cr%C3%A9dito">Detec&#231;&#227;o de fraude em transa&#231;&#245;es de cart&#227;o de cr&#233;dito<a class="anchor-link" href="#Detec%C3%A7%C3%A3o-de-fraude-em-transa%C3%A7%C3%B5es-de-cart%C3%A3o-de-cr%C3%A9dito">&#182;</a></h1><h4 id="Objetivo:-Desenvolver-um-modelo-de-detec%C3%A7%C3%A3o-de-fraude-em-transa%C3%A7%C3%B5es-de-cart%C3%A3o-de-cr%C3%A9dito,-capaz-de-identificar-transa%C3%A7%C3%B5es-fraudulentas-com-base-em-atributos-relevantes.">Objetivo: Desenvolver um modelo de detec&#231;&#227;o de fraude em transa&#231;&#245;es de cart&#227;o de cr&#233;dito, capaz de identificar transa&#231;&#245;es fraudulentas com base em atributos relevantes.<a class="anchor-link" href="#Objetivo:-Desenvolver-um-modelo-de-detec%C3%A7%C3%A3o-de-fraude-em-transa%C3%A7%C3%B5es-de-cart%C3%A3o-de-cr%C3%A9dito,-capaz-de-identificar-transa%C3%A7%C3%B5es-fraudulentas-com-base-em-atributos-relevantes.">&#182;</a></h4><h4 id="Dados:-Transa%C3%A7%C3%B5es-de-cart%C3%A3o-de-cr%C3%A9dito-realizadas-durante-2-dias,-onde-algumas-s%C3%A3o-fraudulentas-e-outras-s%C3%A3o-leg%C3%ADtimas.">Dados: Transa&#231;&#245;es de cart&#227;o de cr&#233;dito realizadas durante 2 dias, onde algumas s&#227;o fraudulentas e outras s&#227;o leg&#237;timas.<a class="anchor-link" href="#Dados:-Transa%C3%A7%C3%B5es-de-cart%C3%A3o-de-cr%C3%A9dito-realizadas-durante-2-dias,-onde-algumas-s%C3%A3o-fraudulentas-e-outras-s%C3%A3o-leg%C3%ADtimas.">&#182;</a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Bibliotecas-utilizadas">Bibliotecas utilizadas<a class="anchor-link" href="#Bibliotecas-utilizadas">&#182;</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">optuna</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">resample</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># Modelos</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">catboost</span> <span class="kn">import</span> <span class="n">CatBoostClassifier</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Dicion%C3%A1rio-dos-dados">Dicion&#225;rio dos dados<a class="anchor-link" href="#Dicion%C3%A1rio-dos-dados">&#182;</a></h2><h4 id="Com-base-na-descri%C3%A7%C3%A3o-do-Kaggle:-https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/">Com base na descri&#231;&#227;o do Kaggle: <a href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/">https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/</a><a class="anchor-link" href="#Com-base-na-descri%C3%A7%C3%A3o-do-Kaggle:-https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/">&#182;</a></h4><ul>
<li><p><strong>Time</strong>: Segundos decorridos entre esta transação e a primeira transação no conjunto de dados.</p>
</li>
<li><p><strong>V1 - V28</strong>: Variáveis afetadas pela aplicação do método de redução de dimensionalidade PCA, aplicado para proteger as informações sensíveis das variáveis.</p>
</li>
<li><p><strong>Amount</strong>: Valor da transação.</p>
</li>
<li><p><strong>Class</strong>: Classificação da transação, sendo <strong>1</strong> para fraudulenta e <strong>0</strong> para não fraudulenta.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_original</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./creditcard.csv'</span><span class="p">)</span>

<span class="n">df_original</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[2]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>284802</th>
      <td>172786.0</td>
      <td>-11.881118</td>
      <td>10.071785</td>
      <td>-9.834783</td>
      <td>-2.066656</td>
      <td>-5.364473</td>
      <td>-2.606837</td>
      <td>-4.918215</td>
      <td>7.305334</td>
      <td>1.914428</td>
      <td>...</td>
      <td>0.213454</td>
      <td>0.111864</td>
      <td>1.014480</td>
      <td>-0.509348</td>
      <td>1.436807</td>
      <td>0.250034</td>
      <td>0.943651</td>
      <td>0.823731</td>
      <td>0.77</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284803</th>
      <td>172787.0</td>
      <td>-0.732789</td>
      <td>-0.055080</td>
      <td>2.035030</td>
      <td>-0.738589</td>
      <td>0.868229</td>
      <td>1.058415</td>
      <td>0.024330</td>
      <td>0.294869</td>
      <td>0.584800</td>
      <td>...</td>
      <td>0.214205</td>
      <td>0.924384</td>
      <td>0.012463</td>
      <td>-1.016226</td>
      <td>-0.606624</td>
      <td>-0.395255</td>
      <td>0.068472</td>
      <td>-0.053527</td>
      <td>24.79</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284804</th>
      <td>172788.0</td>
      <td>1.919565</td>
      <td>-0.301254</td>
      <td>-3.249640</td>
      <td>-0.557828</td>
      <td>2.630515</td>
      <td>3.031260</td>
      <td>-0.296827</td>
      <td>0.708417</td>
      <td>0.432454</td>
      <td>...</td>
      <td>0.232045</td>
      <td>0.578229</td>
      <td>-0.037501</td>
      <td>0.640134</td>
      <td>0.265745</td>
      <td>-0.087371</td>
      <td>0.004455</td>
      <td>-0.026561</td>
      <td>67.88</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284805</th>
      <td>172788.0</td>
      <td>-0.240440</td>
      <td>0.530483</td>
      <td>0.702510</td>
      <td>0.689799</td>
      <td>-0.377961</td>
      <td>0.623708</td>
      <td>-0.686180</td>
      <td>0.679145</td>
      <td>0.392087</td>
      <td>...</td>
      <td>0.265245</td>
      <td>0.800049</td>
      <td>-0.163298</td>
      <td>0.123205</td>
      <td>-0.569159</td>
      <td>0.546668</td>
      <td>0.108821</td>
      <td>0.104533</td>
      <td>10.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284806</th>
      <td>172792.0</td>
      <td>-0.533413</td>
      <td>-0.189733</td>
      <td>0.703337</td>
      <td>-0.506271</td>
      <td>-0.012546</td>
      <td>-0.649617</td>
      <td>1.577006</td>
      <td>-0.414650</td>
      <td>0.486180</td>
      <td>...</td>
      <td>0.261057</td>
      <td>0.643078</td>
      <td>0.376777</td>
      <td>0.008797</td>
      <td>-0.473649</td>
      <td>-0.818267</td>
      <td>-0.002415</td>
      <td>0.013649</td>
      <td>217.00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>284807 rows × 31 columns</p>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="An%C3%A1lise-explorat%C3%B3ria">An&#225;lise explorat&#243;ria<a class="anchor-link" href="#An%C3%A1lise-explorat%C3%B3ria">&#182;</a></h2><ul>
<li><p>Não existem valores nulos em nenhuma das colunas.</p>
</li>
<li><p>As variáveis V1 a V28 estão dentro de uma escala, já que o método de redução de dimensionalidade PCA foi aplicado.</p>
</li>
<li><p>Existem transações com valores que podem ser considerados outliers.</p>
</li>
<li><p>A média dos valores das transações é de <strong>US\$ 88.34</strong>, mas essa média é afetada pelos outliers presentes nessa variável.</p>
</li>
<li><p>O maior valor transacionado para 99% dos registros é de US\$ 1017.97, apesar do valor máximo para todas as transações ser de US\$ 25691.16.</p>
</li>
<li><p>Do total de transações, <strong>99.83%</strong> são legítimas e somente <strong>0.17%</strong> são fraudes.</p>
</li>
<li><p>Apesar da média de valores nas transações ser maior na base de fraudes, os maiores valores de transações estão presentes na base sem fraudes.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_original</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>284807.000000</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>...</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>284807.000000</td>
      <td>284807.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94813.859575</td>
      <td>1.168375e-15</td>
      <td>3.416908e-16</td>
      <td>-1.379537e-15</td>
      <td>2.074095e-15</td>
      <td>9.604066e-16</td>
      <td>1.487313e-15</td>
      <td>-5.556467e-16</td>
      <td>1.213481e-16</td>
      <td>-2.406331e-15</td>
      <td>...</td>
      <td>1.654067e-16</td>
      <td>-3.568593e-16</td>
      <td>2.578648e-16</td>
      <td>4.473266e-15</td>
      <td>5.340915e-16</td>
      <td>1.683437e-15</td>
      <td>-3.660091e-16</td>
      <td>-1.227390e-16</td>
      <td>88.349619</td>
      <td>0.001727</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47488.145955</td>
      <td>1.958696e+00</td>
      <td>1.651309e+00</td>
      <td>1.516255e+00</td>
      <td>1.415869e+00</td>
      <td>1.380247e+00</td>
      <td>1.332271e+00</td>
      <td>1.237094e+00</td>
      <td>1.194353e+00</td>
      <td>1.098632e+00</td>
      <td>...</td>
      <td>7.345240e-01</td>
      <td>7.257016e-01</td>
      <td>6.244603e-01</td>
      <td>6.056471e-01</td>
      <td>5.212781e-01</td>
      <td>4.822270e-01</td>
      <td>4.036325e-01</td>
      <td>3.300833e-01</td>
      <td>250.120109</td>
      <td>0.041527</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-5.640751e+01</td>
      <td>-7.271573e+01</td>
      <td>-4.832559e+01</td>
      <td>-5.683171e+00</td>
      <td>-1.137433e+02</td>
      <td>-2.616051e+01</td>
      <td>-4.355724e+01</td>
      <td>-7.321672e+01</td>
      <td>-1.343407e+01</td>
      <td>...</td>
      <td>-3.483038e+01</td>
      <td>-1.093314e+01</td>
      <td>-4.480774e+01</td>
      <td>-2.836627e+00</td>
      <td>-1.029540e+01</td>
      <td>-2.604551e+00</td>
      <td>-2.256568e+01</td>
      <td>-1.543008e+01</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54201.500000</td>
      <td>-9.203734e-01</td>
      <td>-5.985499e-01</td>
      <td>-8.903648e-01</td>
      <td>-8.486401e-01</td>
      <td>-6.915971e-01</td>
      <td>-7.682956e-01</td>
      <td>-5.540759e-01</td>
      <td>-2.086297e-01</td>
      <td>-6.430976e-01</td>
      <td>...</td>
      <td>-2.283949e-01</td>
      <td>-5.423504e-01</td>
      <td>-1.618463e-01</td>
      <td>-3.545861e-01</td>
      <td>-3.171451e-01</td>
      <td>-3.269839e-01</td>
      <td>-7.083953e-02</td>
      <td>-5.295979e-02</td>
      <td>5.600000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84692.000000</td>
      <td>1.810880e-02</td>
      <td>6.548556e-02</td>
      <td>1.798463e-01</td>
      <td>-1.984653e-02</td>
      <td>-5.433583e-02</td>
      <td>-2.741871e-01</td>
      <td>4.010308e-02</td>
      <td>2.235804e-02</td>
      <td>-5.142873e-02</td>
      <td>...</td>
      <td>-2.945017e-02</td>
      <td>6.781943e-03</td>
      <td>-1.119293e-02</td>
      <td>4.097606e-02</td>
      <td>1.659350e-02</td>
      <td>-5.213911e-02</td>
      <td>1.342146e-03</td>
      <td>1.124383e-02</td>
      <td>22.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139320.500000</td>
      <td>1.315642e+00</td>
      <td>8.037239e-01</td>
      <td>1.027196e+00</td>
      <td>7.433413e-01</td>
      <td>6.119264e-01</td>
      <td>3.985649e-01</td>
      <td>5.704361e-01</td>
      <td>3.273459e-01</td>
      <td>5.971390e-01</td>
      <td>...</td>
      <td>1.863772e-01</td>
      <td>5.285536e-01</td>
      <td>1.476421e-01</td>
      <td>4.395266e-01</td>
      <td>3.507156e-01</td>
      <td>2.409522e-01</td>
      <td>9.104512e-02</td>
      <td>7.827995e-02</td>
      <td>77.165000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>90%</th>
      <td>157640.400000</td>
      <td>2.015409e+00</td>
      <td>1.326635e+00</td>
      <td>1.676173e+00</td>
      <td>1.482807e+00</td>
      <td>1.407893e+00</td>
      <td>1.509365e+00</td>
      <td>1.039387e+00</td>
      <td>7.693811e-01</td>
      <td>1.301671e+00</td>
      <td>...</td>
      <td>3.761555e-01</td>
      <td>9.148826e-01</td>
      <td>3.392860e-01</td>
      <td>7.054036e-01</td>
      <td>6.009027e-01</td>
      <td>6.889469e-01</td>
      <td>2.653679e-01</td>
      <td>1.799362e-01</td>
      <td>203.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>99%</th>
      <td>170560.940000</td>
      <td>2.237130e+00</td>
      <td>3.801811e+00</td>
      <td>2.728434e+00</td>
      <td>4.248032e+00</td>
      <td>3.424903e+00</td>
      <td>4.200085e+00</td>
      <td>2.696205e+00</td>
      <td>2.075973e+00</td>
      <td>2.986773e+00</td>
      <td>...</td>
      <td>1.931852e+00</td>
      <td>1.530152e+00</td>
      <td>1.508703e+00</td>
      <td>1.063748e+00</td>
      <td>1.203955e+00</td>
      <td>1.158698e+00</td>
      <td>9.313604e-01</td>
      <td>5.411264e-01</td>
      <td>1017.970000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172792.000000</td>
      <td>2.454930e+00</td>
      <td>2.205773e+01</td>
      <td>9.382558e+00</td>
      <td>1.687534e+01</td>
      <td>3.480167e+01</td>
      <td>7.330163e+01</td>
      <td>1.205895e+02</td>
      <td>2.000721e+01</td>
      <td>1.559499e+01</td>
      <td>...</td>
      <td>2.720284e+01</td>
      <td>1.050309e+01</td>
      <td>2.252841e+01</td>
      <td>4.584549e+00</td>
      <td>7.519589e+00</td>
      <td>3.517346e+00</td>
      <td>3.161220e+01</td>
      <td>3.384781e+01</td>
      <td>25691.160000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 31 columns</p>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Contagem-de-nulos">Contagem de nulos<a class="anchor-link" href="#Contagem-de-nulos">&#182;</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_original</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">'Contagem de nulos'</span><span class="p">})</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Contagem de nulos</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Time</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V1</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V2</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V3</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V4</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V5</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V6</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V7</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V8</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V9</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V10</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V11</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V12</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V13</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V14</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V15</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V16</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V17</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V18</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V19</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V20</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V21</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V22</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V23</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V24</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V25</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V26</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V27</th>
      <td>0</td>
    </tr>
    <tr>
      <th>V28</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Amount</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Class</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Analisando-com-base-na-vari%C3%A1vel-de-fraude">Analisando com base na vari&#225;vel de fraude<a class="anchor-link" href="#Analisando-com-base-na-vari%C3%A1vel-de-fraude">&#182;</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_fraude</span> <span class="o">=</span> <span class="n">df_original</span><span class="p">[</span><span class="n">df_original</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">df_nao_fraude</span> <span class="o">=</span> <span class="n">df_original</span><span class="p">[</span><span class="n">df_original</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>

<span class="n">display</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Percentual de presença de transações fraudulentas: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">df_fraude</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df_original</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Percentual de presença de transações legítimas: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">df_nao_fraude</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df_original</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">df_fraude</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">df_nao_fraude</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>&#39;Percentual de presença de transações fraudulentas: 0.17%&#39;</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>&#39;Percentual de presença de transações legítimas: 99.83%&#39;</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>541</th>
      <td>406.0</td>
      <td>-2.312227</td>
      <td>1.951992</td>
      <td>-1.609851</td>
      <td>3.997906</td>
      <td>-0.522188</td>
      <td>-1.426545</td>
      <td>-2.537387</td>
      <td>1.391657</td>
      <td>-2.770089</td>
      <td>...</td>
      <td>0.517232</td>
      <td>-0.035049</td>
      <td>-0.465211</td>
      <td>0.320198</td>
      <td>0.044519</td>
      <td>0.177840</td>
      <td>0.261145</td>
      <td>-0.143276</td>
      <td>0.00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>623</th>
      <td>472.0</td>
      <td>-3.043541</td>
      <td>-3.157307</td>
      <td>1.088463</td>
      <td>2.288644</td>
      <td>1.359805</td>
      <td>-1.064823</td>
      <td>0.325574</td>
      <td>-0.067794</td>
      <td>-0.270953</td>
      <td>...</td>
      <td>0.661696</td>
      <td>0.435477</td>
      <td>1.375966</td>
      <td>-0.293803</td>
      <td>0.279798</td>
      <td>-0.145362</td>
      <td>-0.252773</td>
      <td>0.035764</td>
      <td>529.00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4920</th>
      <td>4462.0</td>
      <td>-2.303350</td>
      <td>1.759247</td>
      <td>-0.359745</td>
      <td>2.330243</td>
      <td>-0.821628</td>
      <td>-0.075788</td>
      <td>0.562320</td>
      <td>-0.399147</td>
      <td>-0.238253</td>
      <td>...</td>
      <td>-0.294166</td>
      <td>-0.932391</td>
      <td>0.172726</td>
      <td>-0.087330</td>
      <td>-0.156114</td>
      <td>-0.542628</td>
      <td>0.039566</td>
      <td>-0.153029</td>
      <td>239.93</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6108</th>
      <td>6986.0</td>
      <td>-4.397974</td>
      <td>1.358367</td>
      <td>-2.592844</td>
      <td>2.679787</td>
      <td>-1.128131</td>
      <td>-1.706536</td>
      <td>-3.496197</td>
      <td>-0.248778</td>
      <td>-0.247768</td>
      <td>...</td>
      <td>0.573574</td>
      <td>0.176968</td>
      <td>-0.436207</td>
      <td>-0.053502</td>
      <td>0.252405</td>
      <td>-0.657488</td>
      <td>-0.827136</td>
      <td>0.849573</td>
      <td>59.00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6329</th>
      <td>7519.0</td>
      <td>1.234235</td>
      <td>3.019740</td>
      <td>-4.304597</td>
      <td>4.732795</td>
      <td>3.624201</td>
      <td>-1.357746</td>
      <td>1.713445</td>
      <td>-0.496358</td>
      <td>-1.282858</td>
      <td>...</td>
      <td>-0.379068</td>
      <td>-0.704181</td>
      <td>-0.656805</td>
      <td>-1.632653</td>
      <td>1.488901</td>
      <td>0.566797</td>
      <td>-0.010016</td>
      <td>0.146793</td>
      <td>1.00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>279863</th>
      <td>169142.0</td>
      <td>-1.927883</td>
      <td>1.125653</td>
      <td>-4.518331</td>
      <td>1.749293</td>
      <td>-1.566487</td>
      <td>-2.010494</td>
      <td>-0.882850</td>
      <td>0.697211</td>
      <td>-2.064945</td>
      <td>...</td>
      <td>0.778584</td>
      <td>-0.319189</td>
      <td>0.639419</td>
      <td>-0.294885</td>
      <td>0.537503</td>
      <td>0.788395</td>
      <td>0.292680</td>
      <td>0.147968</td>
      <td>390.00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>280143</th>
      <td>169347.0</td>
      <td>1.378559</td>
      <td>1.289381</td>
      <td>-5.004247</td>
      <td>1.411850</td>
      <td>0.442581</td>
      <td>-1.326536</td>
      <td>-1.413170</td>
      <td>0.248525</td>
      <td>-1.127396</td>
      <td>...</td>
      <td>0.370612</td>
      <td>0.028234</td>
      <td>-0.145640</td>
      <td>-0.081049</td>
      <td>0.521875</td>
      <td>0.739467</td>
      <td>0.389152</td>
      <td>0.186637</td>
      <td>0.76</td>
      <td>1</td>
    </tr>
    <tr>
      <th>280149</th>
      <td>169351.0</td>
      <td>-0.676143</td>
      <td>1.126366</td>
      <td>-2.213700</td>
      <td>0.468308</td>
      <td>-1.120541</td>
      <td>-0.003346</td>
      <td>-2.234739</td>
      <td>1.210158</td>
      <td>-0.652250</td>
      <td>...</td>
      <td>0.751826</td>
      <td>0.834108</td>
      <td>0.190944</td>
      <td>0.032070</td>
      <td>-0.739695</td>
      <td>0.471111</td>
      <td>0.385107</td>
      <td>0.194361</td>
      <td>77.89</td>
      <td>1</td>
    </tr>
    <tr>
      <th>281144</th>
      <td>169966.0</td>
      <td>-3.113832</td>
      <td>0.585864</td>
      <td>-5.399730</td>
      <td>1.817092</td>
      <td>-0.840618</td>
      <td>-2.943548</td>
      <td>-2.208002</td>
      <td>1.058733</td>
      <td>-1.632333</td>
      <td>...</td>
      <td>0.583276</td>
      <td>-0.269209</td>
      <td>-0.456108</td>
      <td>-0.183659</td>
      <td>-0.328168</td>
      <td>0.606116</td>
      <td>0.884876</td>
      <td>-0.253700</td>
      <td>245.00</td>
      <td>1</td>
    </tr>
    <tr>
      <th>281674</th>
      <td>170348.0</td>
      <td>1.991976</td>
      <td>0.158476</td>
      <td>-2.583441</td>
      <td>0.408670</td>
      <td>1.151147</td>
      <td>-0.096695</td>
      <td>0.223050</td>
      <td>-0.068384</td>
      <td>0.577829</td>
      <td>...</td>
      <td>-0.164350</td>
      <td>-0.295135</td>
      <td>-0.072173</td>
      <td>-0.450261</td>
      <td>0.313267</td>
      <td>-0.289617</td>
      <td>0.002988</td>
      <td>-0.015309</td>
      <td>42.53</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>492 rows × 31 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>284802</th>
      <td>172786.0</td>
      <td>-11.881118</td>
      <td>10.071785</td>
      <td>-9.834783</td>
      <td>-2.066656</td>
      <td>-5.364473</td>
      <td>-2.606837</td>
      <td>-4.918215</td>
      <td>7.305334</td>
      <td>1.914428</td>
      <td>...</td>
      <td>0.213454</td>
      <td>0.111864</td>
      <td>1.014480</td>
      <td>-0.509348</td>
      <td>1.436807</td>
      <td>0.250034</td>
      <td>0.943651</td>
      <td>0.823731</td>
      <td>0.77</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284803</th>
      <td>172787.0</td>
      <td>-0.732789</td>
      <td>-0.055080</td>
      <td>2.035030</td>
      <td>-0.738589</td>
      <td>0.868229</td>
      <td>1.058415</td>
      <td>0.024330</td>
      <td>0.294869</td>
      <td>0.584800</td>
      <td>...</td>
      <td>0.214205</td>
      <td>0.924384</td>
      <td>0.012463</td>
      <td>-1.016226</td>
      <td>-0.606624</td>
      <td>-0.395255</td>
      <td>0.068472</td>
      <td>-0.053527</td>
      <td>24.79</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284804</th>
      <td>172788.0</td>
      <td>1.919565</td>
      <td>-0.301254</td>
      <td>-3.249640</td>
      <td>-0.557828</td>
      <td>2.630515</td>
      <td>3.031260</td>
      <td>-0.296827</td>
      <td>0.708417</td>
      <td>0.432454</td>
      <td>...</td>
      <td>0.232045</td>
      <td>0.578229</td>
      <td>-0.037501</td>
      <td>0.640134</td>
      <td>0.265745</td>
      <td>-0.087371</td>
      <td>0.004455</td>
      <td>-0.026561</td>
      <td>67.88</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284805</th>
      <td>172788.0</td>
      <td>-0.240440</td>
      <td>0.530483</td>
      <td>0.702510</td>
      <td>0.689799</td>
      <td>-0.377961</td>
      <td>0.623708</td>
      <td>-0.686180</td>
      <td>0.679145</td>
      <td>0.392087</td>
      <td>...</td>
      <td>0.265245</td>
      <td>0.800049</td>
      <td>-0.163298</td>
      <td>0.123205</td>
      <td>-0.569159</td>
      <td>0.546668</td>
      <td>0.108821</td>
      <td>0.104533</td>
      <td>10.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>284806</th>
      <td>172792.0</td>
      <td>-0.533413</td>
      <td>-0.189733</td>
      <td>0.703337</td>
      <td>-0.506271</td>
      <td>-0.012546</td>
      <td>-0.649617</td>
      <td>1.577006</td>
      <td>-0.414650</td>
      <td>0.486180</td>
      <td>...</td>
      <td>0.261057</td>
      <td>0.643078</td>
      <td>0.376777</td>
      <td>0.008797</td>
      <td>-0.473649</td>
      <td>-0.818267</td>
      <td>-0.002415</td>
      <td>0.013649</td>
      <td>217.00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>284315 rows × 31 columns</p>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Base-de-transa%C3%A7%C3%B5es-fraudulentas">Base de transa&#231;&#245;es fraudulentas<a class="anchor-link" href="#Base-de-transa%C3%A7%C3%B5es-fraudulentas">&#182;</a></h4><ul>
<li><p>O menor tempo decorrido entre a primeira transação e as transações fraudulentas é de 406 segundos.</p>
</li>
<li><p>A média de valores para as transações dessa base é de US\$ 122.21.</p>
</li>
<li><p>O valor máximo encontrado nessas transações é de US\$ 2125.87.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_fraude</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[6]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>...</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.000000</td>
      <td>492.0</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>80746.806911</td>
      <td>-4.771948</td>
      <td>3.623778</td>
      <td>-7.033281</td>
      <td>4.542029</td>
      <td>-3.151225</td>
      <td>-1.397737</td>
      <td>-5.568731</td>
      <td>0.570636</td>
      <td>-2.581123</td>
      <td>...</td>
      <td>0.713588</td>
      <td>0.014049</td>
      <td>-0.040308</td>
      <td>-0.105130</td>
      <td>0.041449</td>
      <td>0.051648</td>
      <td>0.170575</td>
      <td>0.075667</td>
      <td>122.211321</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47835.365138</td>
      <td>6.783687</td>
      <td>4.291216</td>
      <td>7.110937</td>
      <td>2.873318</td>
      <td>5.372468</td>
      <td>1.858124</td>
      <td>7.206773</td>
      <td>6.797831</td>
      <td>2.500896</td>
      <td>...</td>
      <td>3.869304</td>
      <td>1.494602</td>
      <td>1.579642</td>
      <td>0.515577</td>
      <td>0.797205</td>
      <td>0.471679</td>
      <td>1.376766</td>
      <td>0.547291</td>
      <td>256.683288</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>min</th>
      <td>406.000000</td>
      <td>-30.552380</td>
      <td>-8.402154</td>
      <td>-31.103685</td>
      <td>-1.313275</td>
      <td>-22.105532</td>
      <td>-6.406267</td>
      <td>-43.557242</td>
      <td>-41.044261</td>
      <td>-13.434066</td>
      <td>...</td>
      <td>-22.797604</td>
      <td>-8.887017</td>
      <td>-19.254328</td>
      <td>-2.028024</td>
      <td>-4.781606</td>
      <td>-1.152671</td>
      <td>-7.263482</td>
      <td>-1.869290</td>
      <td>0.000000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>41241.500000</td>
      <td>-6.036063</td>
      <td>1.188226</td>
      <td>-8.643489</td>
      <td>2.373050</td>
      <td>-4.792835</td>
      <td>-2.501511</td>
      <td>-7.965295</td>
      <td>-0.195336</td>
      <td>-3.872383</td>
      <td>...</td>
      <td>0.041787</td>
      <td>-0.533764</td>
      <td>-0.342175</td>
      <td>-0.436809</td>
      <td>-0.314348</td>
      <td>-0.259416</td>
      <td>-0.020025</td>
      <td>-0.108868</td>
      <td>1.000000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>75568.500000</td>
      <td>-2.342497</td>
      <td>2.717869</td>
      <td>-5.075257</td>
      <td>4.177147</td>
      <td>-1.522962</td>
      <td>-1.424616</td>
      <td>-3.034402</td>
      <td>0.621508</td>
      <td>-2.208768</td>
      <td>...</td>
      <td>0.592146</td>
      <td>0.048434</td>
      <td>-0.073135</td>
      <td>-0.060795</td>
      <td>0.088371</td>
      <td>0.004321</td>
      <td>0.394926</td>
      <td>0.146344</td>
      <td>9.250000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>128483.000000</td>
      <td>-0.419200</td>
      <td>4.971257</td>
      <td>-2.276185</td>
      <td>6.348729</td>
      <td>0.214562</td>
      <td>-0.413216</td>
      <td>-0.945954</td>
      <td>1.764879</td>
      <td>-0.787850</td>
      <td>...</td>
      <td>1.244611</td>
      <td>0.617474</td>
      <td>0.308378</td>
      <td>0.285328</td>
      <td>0.456515</td>
      <td>0.396733</td>
      <td>0.826029</td>
      <td>0.381152</td>
      <td>105.890000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>max</th>
      <td>170348.000000</td>
      <td>2.132386</td>
      <td>22.057729</td>
      <td>2.250210</td>
      <td>12.114672</td>
      <td>11.095089</td>
      <td>6.474115</td>
      <td>5.802537</td>
      <td>20.007208</td>
      <td>3.353525</td>
      <td>...</td>
      <td>27.202839</td>
      <td>8.361985</td>
      <td>5.466230</td>
      <td>1.091435</td>
      <td>2.208209</td>
      <td>2.745261</td>
      <td>3.052358</td>
      <td>1.779364</td>
      <td>2125.870000</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Base-de-transa%C3%A7%C3%B5es-leg%C3%ADtimas">Base de transa&#231;&#245;es leg&#237;timas<a class="anchor-link" href="#Base-de-transa%C3%A7%C3%B5es-leg%C3%ADtimas">&#182;</a></h4><ul>
<li><p>A transação com maior tempo decorrido da primeira transação na base completa não é fraudulenta.</p>
</li>
<li><p>A transação de maior valor na base completa não é fraudulenta.</p>
</li>
<li><p>A média de valores para as transações dessa base é de US\$ 88.29, valor bem próximo da base completa.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_nao_fraude</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>...</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.000000</td>
      <td>284315.0</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94838.202258</td>
      <td>0.008258</td>
      <td>-0.006271</td>
      <td>0.012171</td>
      <td>-0.007860</td>
      <td>0.005453</td>
      <td>0.002419</td>
      <td>0.009637</td>
      <td>-0.000987</td>
      <td>0.004467</td>
      <td>...</td>
      <td>-0.001235</td>
      <td>-0.000024</td>
      <td>0.000070</td>
      <td>0.000182</td>
      <td>-0.000072</td>
      <td>-0.000089</td>
      <td>-0.000295</td>
      <td>-0.000131</td>
      <td>88.291022</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47484.015786</td>
      <td>1.929814</td>
      <td>1.636146</td>
      <td>1.459429</td>
      <td>1.399333</td>
      <td>1.356952</td>
      <td>1.329913</td>
      <td>1.178812</td>
      <td>1.161283</td>
      <td>1.089372</td>
      <td>...</td>
      <td>0.716743</td>
      <td>0.723668</td>
      <td>0.621541</td>
      <td>0.605776</td>
      <td>0.520673</td>
      <td>0.482241</td>
      <td>0.399847</td>
      <td>0.329570</td>
      <td>250.105092</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-56.407510</td>
      <td>-72.715728</td>
      <td>-48.325589</td>
      <td>-5.683171</td>
      <td>-113.743307</td>
      <td>-26.160506</td>
      <td>-31.764946</td>
      <td>-73.216718</td>
      <td>-6.290730</td>
      <td>...</td>
      <td>-34.830382</td>
      <td>-10.933144</td>
      <td>-44.807735</td>
      <td>-2.836627</td>
      <td>-10.295397</td>
      <td>-2.604551</td>
      <td>-22.565679</td>
      <td>-15.430084</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54230.000000</td>
      <td>-0.917544</td>
      <td>-0.599473</td>
      <td>-0.884541</td>
      <td>-0.850077</td>
      <td>-0.689398</td>
      <td>-0.766847</td>
      <td>-0.551442</td>
      <td>-0.208633</td>
      <td>-0.640412</td>
      <td>...</td>
      <td>-0.228509</td>
      <td>-0.542403</td>
      <td>-0.161702</td>
      <td>-0.354425</td>
      <td>-0.317145</td>
      <td>-0.327074</td>
      <td>-0.070852</td>
      <td>-0.052950</td>
      <td>5.650000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84711.000000</td>
      <td>0.020023</td>
      <td>0.064070</td>
      <td>0.182158</td>
      <td>-0.022405</td>
      <td>-0.053457</td>
      <td>-0.273123</td>
      <td>0.041138</td>
      <td>0.022041</td>
      <td>-0.049964</td>
      <td>...</td>
      <td>-0.029821</td>
      <td>0.006736</td>
      <td>-0.011147</td>
      <td>0.041082</td>
      <td>0.016417</td>
      <td>-0.052227</td>
      <td>0.001230</td>
      <td>0.011199</td>
      <td>22.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139333.000000</td>
      <td>1.316218</td>
      <td>0.800446</td>
      <td>1.028372</td>
      <td>0.737624</td>
      <td>0.612181</td>
      <td>0.399619</td>
      <td>0.571019</td>
      <td>0.326200</td>
      <td>0.598230</td>
      <td>...</td>
      <td>0.185626</td>
      <td>0.528407</td>
      <td>0.147522</td>
      <td>0.439869</td>
      <td>0.350594</td>
      <td>0.240671</td>
      <td>0.090573</td>
      <td>0.077962</td>
      <td>77.050000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172792.000000</td>
      <td>2.454930</td>
      <td>18.902453</td>
      <td>9.382558</td>
      <td>16.875344</td>
      <td>34.801666</td>
      <td>73.301626</td>
      <td>120.589494</td>
      <td>18.709255</td>
      <td>15.594995</td>
      <td>...</td>
      <td>22.614889</td>
      <td>10.503090</td>
      <td>22.528412</td>
      <td>4.584549</td>
      <td>7.519589</td>
      <td>3.517346</td>
      <td>31.612198</td>
      <td>33.847808</td>
      <td>25691.160000</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Matriz-de-correla%C3%A7%C3%A3o">Matriz de correla&#231;&#227;o<a class="anchor-link" href="#Matriz-de-correla%C3%A7%C3%A3o">&#182;</a></h3><h4 id="Correla%C3%A7%C3%A3o-positiva-em-destaque">Correla&#231;&#227;o positiva em destaque<a class="anchor-link" href="#Correla%C3%A7%C3%A3o-positiva-em-destaque">&#182;</a></h4><ul>
<li><p>Time: V1 (0.12), <strong>V5 (0.17)</strong>, V12 (0.12) e V22 (0.14) tem correlação positiva acima de 0.12 em relação a variável Time.</p>
</li>
<li><p>Amount: V6 (0.22), <strong>V7 (0.40)</strong>, V20 (0.34) tem correlação positiva acima de 0.22 em relação a variável Amount.</p>
</li>
<li><p>Class: V2 (0.09), V4 (0.13), <strong>V11 (0.15)</strong> tem correlação positiva acima de 0.09 em relação a variável Class.</p>
</li>
</ul>
<h4 id="Correla%C3%A7%C3%A3o-negativa-em-destaque">Correla&#231;&#227;o negativa em destaque<a class="anchor-link" href="#Correla%C3%A7%C3%A3o-negativa-em-destaque">&#182;</a></h4><ul>
<li><p>Time: <strong>V3 (-0.42)</strong>, V11 (-0.25) e V25 (-0.23) tem correlação negativa abaixo de -0.23 em relação a variável Time.</p>
</li>
<li><p>Amount: V1 (-0.23), <strong>V2 (-0.53)</strong>, V3 (-0.21), V5 (-0.25) tem correlação negativa abaixo de -0.21 em relação a variável Amount.</p>
</li>
<li><p>Class: V10 (-0.22), V12 (-0.26), V14 (-0.30), <strong>V17 (-0.33)</strong> tem correlação negativa abaixo de -0.22 em relação a variável Class.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df_original</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'coolwarm'</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">".2f"</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Matriz de Correlação'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Split-nos-dados-originais">Split nos dados originais<a class="anchor-link" href="#Split-nos-dados-originais">&#182;</a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_original</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_original</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_original</span><span class="p">,</span> <span class="n">X_test_original</span><span class="p">,</span> <span class="n">y_train_original</span><span class="p">,</span> <span class="n">y_test_original</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h4 id="Validando-as-distribui%C3%A7%C3%B5es">Validando as distribui&#231;&#245;es<a class="anchor-link" href="#Validando-as-distribui%C3%A7%C3%B5es">&#182;</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Describe de treino:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_train_original</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Describe de teste:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_test_original</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Distribuição de fraude na base de treino:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_train_original</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_train_original</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Distribuição de fraude na base de teste:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_test_original</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_test_original</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Describe de treino:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>...</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
      <td>227845.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94799.020676</td>
      <td>0.000174</td>
      <td>-0.001365</td>
      <td>-0.003386</td>
      <td>0.000190</td>
      <td>-0.001483</td>
      <td>-0.001034</td>
      <td>0.000631</td>
      <td>0.000670</td>
      <td>0.001430</td>
      <td>...</td>
      <td>-0.000340</td>
      <td>0.000432</td>
      <td>0.000257</td>
      <td>0.000195</td>
      <td>-0.000562</td>
      <td>0.000228</td>
      <td>-0.000222</td>
      <td>0.000013</td>
      <td>0.000099</td>
      <td>88.502064</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47499.435070</td>
      <td>1.971155</td>
      <td>1.659895</td>
      <td>1.523706</td>
      <td>1.414941</td>
      <td>1.388924</td>
      <td>1.332236</td>
      <td>1.246508</td>
      <td>1.196834</td>
      <td>1.099960</td>
      <td>...</td>
      <td>0.780951</td>
      <td>0.739792</td>
      <td>0.725920</td>
      <td>0.618714</td>
      <td>0.605352</td>
      <td>0.521667</td>
      <td>0.482660</td>
      <td>0.404577</td>
      <td>0.337103</td>
      <td>253.374134</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-56.407510</td>
      <td>-72.715728</td>
      <td>-48.325589</td>
      <td>-5.600607</td>
      <td>-113.743307</td>
      <td>-26.160506</td>
      <td>-43.557242</td>
      <td>-73.216718</td>
      <td>-13.434066</td>
      <td>...</td>
      <td>-54.497720</td>
      <td>-34.830382</td>
      <td>-10.933144</td>
      <td>-36.666000</td>
      <td>-2.836627</td>
      <td>-8.696627</td>
      <td>-2.604551</td>
      <td>-9.895244</td>
      <td>-15.430084</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54207.000000</td>
      <td>-0.918277</td>
      <td>-0.599558</td>
      <td>-0.890923</td>
      <td>-0.846347</td>
      <td>-0.692015</td>
      <td>-0.768632</td>
      <td>-0.554119</td>
      <td>-0.208743</td>
      <td>-0.641823</td>
      <td>...</td>
      <td>-0.211975</td>
      <td>-0.228295</td>
      <td>-0.541723</td>
      <td>-0.161636</td>
      <td>-0.355073</td>
      <td>-0.317322</td>
      <td>-0.327169</td>
      <td>-0.070836</td>
      <td>-0.052863</td>
      <td>5.550000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84640.000000</td>
      <td>0.023214</td>
      <td>0.063697</td>
      <td>0.178479</td>
      <td>-0.020248</td>
      <td>-0.053146</td>
      <td>-0.274135</td>
      <td>0.040140</td>
      <td>0.022464</td>
      <td>-0.049549</td>
      <td>...</td>
      <td>-0.062511</td>
      <td>-0.029427</td>
      <td>0.006495</td>
      <td>-0.010720</td>
      <td>0.040768</td>
      <td>0.016919</td>
      <td>-0.052481</td>
      <td>0.001430</td>
      <td>0.011195</td>
      <td>22.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139341.000000</td>
      <td>1.316427</td>
      <td>0.801844</td>
      <td>1.025052</td>
      <td>0.741196</td>
      <td>0.612317</td>
      <td>0.398258</td>
      <td>0.570453</td>
      <td>0.326785</td>
      <td>0.597619</td>
      <td>...</td>
      <td>0.132858</td>
      <td>0.186852</td>
      <td>0.529203</td>
      <td>0.147814</td>
      <td>0.438815</td>
      <td>0.351273</td>
      <td>0.240843</td>
      <td>0.090744</td>
      <td>0.078089</td>
      <td>77.050000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172792.000000</td>
      <td>2.454930</td>
      <td>22.057729</td>
      <td>4.226108</td>
      <td>16.875344</td>
      <td>34.801666</td>
      <td>73.301626</td>
      <td>120.589494</td>
      <td>20.007208</td>
      <td>10.392889</td>
      <td>...</td>
      <td>39.420904</td>
      <td>27.202839</td>
      <td>10.503090</td>
      <td>22.528412</td>
      <td>4.584549</td>
      <td>7.519589</td>
      <td>3.517346</td>
      <td>31.612198</td>
      <td>33.847808</td>
      <td>25691.160000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 30 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Describe de teste:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>...</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
      <td>56962.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94873.214389</td>
      <td>-0.000696</td>
      <td>0.005461</td>
      <td>0.013544</td>
      <td>-0.000759</td>
      <td>0.005933</td>
      <td>0.004136</td>
      <td>-0.002523</td>
      <td>-0.002681</td>
      <td>-0.005718</td>
      <td>...</td>
      <td>0.001361</td>
      <td>-0.001727</td>
      <td>-0.001029</td>
      <td>-0.000780</td>
      <td>0.002247</td>
      <td>-0.000913</td>
      <td>0.000889</td>
      <td>-0.000051</td>
      <td>-0.000398</td>
      <td>87.739847</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47443.333461</td>
      <td>1.908064</td>
      <td>1.616511</td>
      <td>1.486015</td>
      <td>1.419584</td>
      <td>1.344975</td>
      <td>1.332416</td>
      <td>1.198706</td>
      <td>1.184385</td>
      <td>1.093296</td>
      <td>...</td>
      <td>0.729451</td>
      <td>0.713068</td>
      <td>0.724833</td>
      <td>0.646939</td>
      <td>0.606827</td>
      <td>0.519724</td>
      <td>0.480492</td>
      <td>0.399836</td>
      <td>0.300371</td>
      <td>236.658343</td>
    </tr>
    <tr>
      <th>min</th>
      <td>7.000000</td>
      <td>-35.274010</td>
      <td>-40.978852</td>
      <td>-25.390229</td>
      <td>-5.683171</td>
      <td>-32.092129</td>
      <td>-17.574835</td>
      <td>-37.060311</td>
      <td>-50.688419</td>
      <td>-11.126624</td>
      <td>...</td>
      <td>-23.646890</td>
      <td>-22.757540</td>
      <td>-7.417140</td>
      <td>-44.807735</td>
      <td>-2.824849</td>
      <td>-10.295397</td>
      <td>-2.068561</td>
      <td>-22.565679</td>
      <td>-11.710896</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54187.750000</td>
      <td>-0.927959</td>
      <td>-0.593680</td>
      <td>-0.887022</td>
      <td>-0.856560</td>
      <td>-0.689161</td>
      <td>-0.767067</td>
      <td>-0.553645</td>
      <td>-0.208363</td>
      <td>-0.647741</td>
      <td>...</td>
      <td>-0.210603</td>
      <td>-0.228883</td>
      <td>-0.545206</td>
      <td>-0.162599</td>
      <td>-0.352707</td>
      <td>-0.316404</td>
      <td>-0.326273</td>
      <td>-0.070866</td>
      <td>-0.053396</td>
      <td>5.710000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84954.500000</td>
      <td>-0.005976</td>
      <td>0.073120</td>
      <td>0.184959</td>
      <td>-0.018467</td>
      <td>-0.058519</td>
      <td>-0.274496</td>
      <td>0.039913</td>
      <td>0.021839</td>
      <td>-0.058020</td>
      <td>...</td>
      <td>-0.062382</td>
      <td>-0.029645</td>
      <td>0.008421</td>
      <td>-0.012990</td>
      <td>0.041594</td>
      <td>0.015041</td>
      <td>-0.051164</td>
      <td>0.001114</td>
      <td>0.011424</td>
      <td>22.075000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139248.000000</td>
      <td>1.311509</td>
      <td>0.811470</td>
      <td>1.035517</td>
      <td>0.751192</td>
      <td>0.610188</td>
      <td>0.400931</td>
      <td>0.570343</td>
      <td>0.330141</td>
      <td>0.595253</td>
      <td>...</td>
      <td>0.133647</td>
      <td>0.184584</td>
      <td>0.525947</td>
      <td>0.146984</td>
      <td>0.442354</td>
      <td>0.348289</td>
      <td>0.241437</td>
      <td>0.092101</td>
      <td>0.079004</td>
      <td>77.695000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172785.000000</td>
      <td>2.422508</td>
      <td>19.167239</td>
      <td>9.382558</td>
      <td>13.143668</td>
      <td>24.363532</td>
      <td>21.393069</td>
      <td>34.303177</td>
      <td>15.374630</td>
      <td>15.594995</td>
      <td>...</td>
      <td>17.281859</td>
      <td>16.666465</td>
      <td>7.357255</td>
      <td>18.946734</td>
      <td>4.014444</td>
      <td>5.852484</td>
      <td>3.122747</td>
      <td>8.932639</td>
      <td>15.407019</td>
      <td>7862.390000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 30 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Distribuição de fraude na base de treino:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    227462
1       383
Name: Class, dtype: int64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    0.998319
1    0.001681
Name: Class, dtype: float64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Distribuição de fraude na base de teste:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    56853
1      109
Name: Class, dtype: int64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    0.998086
1    0.001914
Name: Class, dtype: float64</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Pr%C3%A9-processamento-dos-dados">Pr&#233;-processamento dos dados<a class="anchor-link" href="#Pr%C3%A9-processamento-dos-dados">&#182;</a></h1><h4 id="Dados-muito-desbalanceados,-e-por-isso-ser%C3%A3o-aplicadas-t%C3%A9cnicas-de-balanceamento-dos-dados,-como-Oversampling-e-Undersampling.">Dados muito desbalanceados, e por isso ser&#227;o aplicadas t&#233;cnicas de balanceamento dos dados, como Oversampling e Undersampling.<a class="anchor-link" href="#Dados-muito-desbalanceados,-e-por-isso-ser%C3%A3o-aplicadas-t%C3%A9cnicas-de-balanceamento-dos-dados,-como-Oversampling-e-Undersampling.">&#182;</a></h4><h4 id="A-divis%C3%A3o-entre-dados-de-treino-e-teste-deve-ser-feita-antes-da-aplica%C3%A7%C3%A3o-dos-m%C3%A9todos-de-balanceamento,-pois-deseja-se-testar-o-modelo-com-os-dados-originais.">A divis&#227;o entre dados de treino e teste deve ser feita antes da aplica&#231;&#227;o dos m&#233;todos de balanceamento, pois deseja-se testar o modelo com os dados originais.<a class="anchor-link" href="#A-divis%C3%A3o-entre-dados-de-treino-e-teste-deve-ser-feita-antes-da-aplica%C3%A7%C3%A3o-dos-m%C3%A9todos-de-balanceamento,-pois-deseja-se-testar-o-modelo-com-os-dados-originais.">&#182;</a></h4><h4 id="Dados-resultantes-a-partir-dos-m%C3%A9todos-de-Oversampling-e-Undersampling-ser%C3%A3o-usados-para-definir-qual-modelo-de-classifica%C3%A7%C3%A3o-ser%C3%A1-aplicado.">Dados resultantes a partir dos m&#233;todos de Oversampling e Undersampling ser&#227;o usados para definir qual modelo de classifica&#231;&#227;o ser&#225; aplicado.<a class="anchor-link" href="#Dados-resultantes-a-partir-dos-m%C3%A9todos-de-Oversampling-e-Undersampling-ser%C3%A3o-usados-para-definir-qual-modelo-de-classifica%C3%A7%C3%A3o-ser%C3%A1-aplicado.">&#182;</a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Escalonando-as-vari%C3%A1veis-Time-e-Amount">Escalonando as vari&#225;veis Time e Amount<a class="anchor-link" href="#Escalonando-as-vari%C3%A1veis-Time-e-Amount">&#182;</a></h2><ul>
<li><p>Somente essas variáveis não estão escalonadas, e como também serão usadas no treinamento do modelo, devem ser escalonadas.</p>
</li>
<li><p>Ambas as variáveis possuem outliers, portanto não é recomendado aplicar o <strong>StandardScaler()</strong>, pois esse método é mais sensível a valores extremos.</p>
</li>
<li><p>Uma boa solução para esse caso é a aplicação do método <strong>RobustScaler()</strong>, pois esse método utiliza os valores dos quartis e a mediana para ajustar os dados, não sendo influenciado pelos outliers.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">robust_scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>

<span class="c1"># Criando as novas colunas de Time e Amount escalonadas nas bases de treino e teste</span>
<span class="n">X_train_original</span><span class="p">[</span><span class="s1">'Time_scaled'</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_original</span><span class="p">[</span><span class="s1">'Time'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_train_original</span><span class="p">[</span><span class="s1">'Amount_scaled'</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_original</span><span class="p">[</span><span class="s1">'Amount'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">X_test_original</span><span class="p">[</span><span class="s1">'Time_scaled'</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test_original</span><span class="p">[</span><span class="s1">'Time'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_test_original</span><span class="p">[</span><span class="s1">'Amount_scaled'</span><span class="p">]</span> <span class="o">=</span> <span class="n">robust_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test_original</span><span class="p">[</span><span class="s1">'Amount'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Dropando as colunas não escalonadas</span>
<span class="n">X_train_original</span> <span class="o">=</span> <span class="n">X_train_original</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Time'</span><span class="p">,</span> <span class="s1">'Amount'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_original</span> <span class="o">=</span> <span class="n">X_test_original</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Time'</span><span class="p">,</span> <span class="s1">'Amount'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">X_train_original</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_test_original</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>193580</th>
      <td>-0.799840</td>
      <td>0.475496</td>
      <td>0.945912</td>
      <td>0.360518</td>
      <td>0.849287</td>
      <td>-0.022402</td>
      <td>0.946082</td>
      <td>-0.118777</td>
      <td>-0.132950</td>
      <td>-0.676126</td>
      <td>...</td>
      <td>-0.211023</td>
      <td>-0.301974</td>
      <td>0.365713</td>
      <td>-0.575632</td>
      <td>-0.598082</td>
      <td>-1.066174</td>
      <td>0.020482</td>
      <td>-0.058998</td>
      <td>0.535133</td>
      <td>0.704895</td>
    </tr>
    <tr>
      <th>281512</th>
      <td>1.606285</td>
      <td>-0.703248</td>
      <td>-0.394818</td>
      <td>1.486715</td>
      <td>-0.788096</td>
      <td>-0.504766</td>
      <td>-0.227999</td>
      <td>-0.115749</td>
      <td>0.882403</td>
      <td>0.140248</td>
      <td>...</td>
      <td>0.335594</td>
      <td>0.713657</td>
      <td>-0.021267</td>
      <td>0.040442</td>
      <td>-0.156591</td>
      <td>-0.583700</td>
      <td>0.022747</td>
      <td>0.002051</td>
      <td>1.005345</td>
      <td>2.323077</td>
    </tr>
    <tr>
      <th>83404</th>
      <td>1.281666</td>
      <td>0.069899</td>
      <td>-0.068433</td>
      <td>-0.118893</td>
      <td>-0.178783</td>
      <td>-0.795593</td>
      <td>0.142466</td>
      <td>-0.089915</td>
      <td>-0.153660</td>
      <td>0.061727</td>
      <td>...</td>
      <td>-0.428059</td>
      <td>-1.371226</td>
      <td>0.159838</td>
      <td>-0.059506</td>
      <td>0.088230</td>
      <td>0.631566</td>
      <td>-0.111973</td>
      <td>-0.012174</td>
      <td>-0.291376</td>
      <td>-0.189091</td>
    </tr>
    <tr>
      <th>131366</th>
      <td>-0.247623</td>
      <td>1.192310</td>
      <td>0.733828</td>
      <td>-0.278547</td>
      <td>0.832577</td>
      <td>-0.141225</td>
      <td>0.796655</td>
      <td>-0.069621</td>
      <td>-0.526500</td>
      <td>-0.556700</td>
      <td>...</td>
      <td>-0.336441</td>
      <td>-0.825071</td>
      <td>-0.196949</td>
      <td>-1.027739</td>
      <td>0.078189</td>
      <td>0.153566</td>
      <td>0.252257</td>
      <td>0.087571</td>
      <td>-0.059494</td>
      <td>-0.209930</td>
    </tr>
    <tr>
      <th>169064</th>
      <td>2.109995</td>
      <td>0.161872</td>
      <td>-1.950143</td>
      <td>0.263848</td>
      <td>0.775884</td>
      <td>-0.440883</td>
      <td>0.182684</td>
      <td>-0.192945</td>
      <td>0.477652</td>
      <td>-0.396496</td>
      <td>...</td>
      <td>-0.394579</td>
      <td>-1.001854</td>
      <td>0.267583</td>
      <td>-0.111757</td>
      <td>-0.179542</td>
      <td>0.213154</td>
      <td>-0.057794</td>
      <td>-0.036438</td>
      <td>0.409590</td>
      <td>-0.289650</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>63856</th>
      <td>-0.043734</td>
      <td>-0.551311</td>
      <td>1.569492</td>
      <td>-1.903996</td>
      <td>-1.151121</td>
      <td>-0.053123</td>
      <td>-0.499013</td>
      <td>0.135010</td>
      <td>-2.136722</td>
      <td>1.023972</td>
      <td>...</td>
      <td>-0.343545</td>
      <td>-0.583264</td>
      <td>-0.013246</td>
      <td>-0.049053</td>
      <td>-0.101647</td>
      <td>-0.366528</td>
      <td>0.056215</td>
      <td>0.013936</td>
      <td>-0.396375</td>
      <td>0.111888</td>
    </tr>
    <tr>
      <th>81968</th>
      <td>1.140277</td>
      <td>-0.004898</td>
      <td>0.072729</td>
      <td>0.918752</td>
      <td>-0.129861</td>
      <td>-0.042564</td>
      <td>-0.127994</td>
      <td>0.223495</td>
      <td>0.153317</td>
      <td>0.211107</td>
      <td>...</td>
      <td>0.066068</td>
      <td>0.058538</td>
      <td>-0.107472</td>
      <td>-0.369613</td>
      <td>0.528540</td>
      <td>-0.288810</td>
      <td>0.004279</td>
      <td>0.001099</td>
      <td>-0.299023</td>
      <td>0.036364</td>
    </tr>
    <tr>
      <th>140036</th>
      <td>-0.754934</td>
      <td>-1.802975</td>
      <td>0.866239</td>
      <td>-1.690596</td>
      <td>-3.007219</td>
      <td>1.865597</td>
      <td>0.741822</td>
      <td>0.098395</td>
      <td>-1.798257</td>
      <td>0.883077</td>
      <td>...</td>
      <td>0.243652</td>
      <td>1.268334</td>
      <td>0.620800</td>
      <td>-0.282679</td>
      <td>-1.342805</td>
      <td>-0.245118</td>
      <td>0.375048</td>
      <td>0.193864</td>
      <td>-0.013367</td>
      <td>7.153846</td>
    </tr>
    <tr>
      <th>202552</th>
      <td>2.051854</td>
      <td>-1.051863</td>
      <td>-2.279919</td>
      <td>-1.689759</td>
      <td>-0.048993</td>
      <td>-0.868512</td>
      <td>0.092609</td>
      <td>-0.329633</td>
      <td>-0.646595</td>
      <td>0.696963</td>
      <td>...</td>
      <td>-0.291720</td>
      <td>-0.583088</td>
      <td>0.081217</td>
      <td>0.366751</td>
      <td>-0.048046</td>
      <td>0.634649</td>
      <td>-0.124288</td>
      <td>-0.065370</td>
      <td>0.584291</td>
      <td>1.234126</td>
    </tr>
    <tr>
      <th>80841</th>
      <td>-0.496414</td>
      <td>0.902277</td>
      <td>1.383164</td>
      <td>0.036025</td>
      <td>0.031949</td>
      <td>-0.852536</td>
      <td>0.523787</td>
      <td>0.097163</td>
      <td>-0.586178</td>
      <td>-0.324452</td>
      <td>...</td>
      <td>-0.189754</td>
      <td>-0.588153</td>
      <td>0.046176</td>
      <td>0.469163</td>
      <td>-0.226233</td>
      <td>0.043261</td>
      <td>0.231659</td>
      <td>0.092114</td>
      <td>-0.304955</td>
      <td>-0.149930</td>
    </tr>
  </tbody>
</table>
<p>227845 rows × 30 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>47499</th>
      <td>-4.907464</td>
      <td>-3.219507</td>
      <td>1.976099</td>
      <td>1.501927</td>
      <td>0.089397</td>
      <td>0.565583</td>
      <td>-0.662498</td>
      <td>-1.134323</td>
      <td>3.474498</td>
      <td>2.871005</td>
      <td>...</td>
      <td>-0.657012</td>
      <td>1.063759</td>
      <td>-1.247375</td>
      <td>0.293825</td>
      <td>-0.890266</td>
      <td>1.099830</td>
      <td>-2.892506</td>
      <td>0.858852</td>
      <td>-0.490494</td>
      <td>-0.224144</td>
    </tr>
    <tr>
      <th>234614</th>
      <td>-2.343356</td>
      <td>-0.956658</td>
      <td>2.558260</td>
      <td>2.960781</td>
      <td>2.619159</td>
      <td>-0.350503</td>
      <td>-1.083410</td>
      <td>0.613996</td>
      <td>-1.031398</td>
      <td>0.491581</td>
      <td>...</td>
      <td>0.323283</td>
      <td>0.187637</td>
      <td>-0.028306</td>
      <td>0.540639</td>
      <td>0.673751</td>
      <td>0.089682</td>
      <td>-0.050855</td>
      <td>0.112183</td>
      <td>0.741751</td>
      <td>-0.306661</td>
    </tr>
    <tr>
      <th>128968</th>
      <td>1.225044</td>
      <td>0.135849</td>
      <td>-0.232285</td>
      <td>-0.062222</td>
      <td>0.981707</td>
      <td>1.707754</td>
      <td>-0.353523</td>
      <td>0.492103</td>
      <td>-0.320422</td>
      <td>0.016330</td>
      <td>...</td>
      <td>-0.204101</td>
      <td>-0.753336</td>
      <td>0.302322</td>
      <td>3.267346</td>
      <td>0.216635</td>
      <td>-0.042515</td>
      <td>-0.036323</td>
      <td>0.036737</td>
      <td>-0.071108</td>
      <td>-0.288741</td>
    </tr>
    <tr>
      <th>182186</th>
      <td>-1.461526</td>
      <td>0.519650</td>
      <td>1.588467</td>
      <td>-0.711261</td>
      <td>0.042390</td>
      <td>-0.343000</td>
      <td>0.685782</td>
      <td>-0.609369</td>
      <td>1.327158</td>
      <td>0.598965</td>
      <td>...</td>
      <td>0.128365</td>
      <td>0.903383</td>
      <td>-0.231424</td>
      <td>0.037264</td>
      <td>-0.206913</td>
      <td>0.505154</td>
      <td>-0.880873</td>
      <td>-0.177428</td>
      <td>0.474293</td>
      <td>0.059526</td>
    </tr>
    <tr>
      <th>180179</th>
      <td>-2.388231</td>
      <td>-0.669561</td>
      <td>2.824465</td>
      <td>2.460076</td>
      <td>3.215267</td>
      <td>-0.105877</td>
      <td>0.246819</td>
      <td>-0.761898</td>
      <td>-0.643063</td>
      <td>1.723674</td>
      <td>...</td>
      <td>-0.171976</td>
      <td>0.428055</td>
      <td>-0.959228</td>
      <td>0.534217</td>
      <td>0.524773</td>
      <td>-0.117508</td>
      <td>-0.919279</td>
      <td>-0.473075</td>
      <td>0.463924</td>
      <td>-0.296103</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>178816</th>
      <td>-0.565451</td>
      <td>-0.517422</td>
      <td>-0.123326</td>
      <td>-0.270570</td>
      <td>1.198575</td>
      <td>-0.882160</td>
      <td>0.781620</td>
      <td>-0.283067</td>
      <td>0.226887</td>
      <td>0.076829</td>
      <td>...</td>
      <td>0.283158</td>
      <td>1.240972</td>
      <td>0.576767</td>
      <td>-0.488070</td>
      <td>-0.265460</td>
      <td>-0.146576</td>
      <td>-0.048595</td>
      <td>-0.237884</td>
      <td>0.456612</td>
      <td>0.054525</td>
    </tr>
    <tr>
      <th>142058</th>
      <td>-0.448134</td>
      <td>0.304089</td>
      <td>1.586149</td>
      <td>-1.774752</td>
      <td>-0.989646</td>
      <td>0.219339</td>
      <td>-1.465000</td>
      <td>-2.343226</td>
      <td>1.088058</td>
      <td>-2.051250</td>
      <td>...</td>
      <td>-1.302742</td>
      <td>0.297854</td>
      <td>-0.283698</td>
      <td>-0.032659</td>
      <td>1.447444</td>
      <td>-0.670875</td>
      <td>0.051334</td>
      <td>0.163837</td>
      <td>-0.004579</td>
      <td>-0.292769</td>
    </tr>
    <tr>
      <th>69294</th>
      <td>1.257516</td>
      <td>0.097742</td>
      <td>-0.299899</td>
      <td>0.869715</td>
      <td>0.715477</td>
      <td>1.119524</td>
      <td>-0.116036</td>
      <td>0.273541</td>
      <td>0.227526</td>
      <td>0.065064</td>
      <td>...</td>
      <td>-0.174101</td>
      <td>-0.300020</td>
      <td>-0.275479</td>
      <td>-1.704110</td>
      <td>0.849335</td>
      <td>-0.220576</td>
      <td>0.031867</td>
      <td>-0.014047</td>
      <td>-0.371495</td>
      <td>-0.292769</td>
    </tr>
    <tr>
      <th>156894</th>
      <td>-0.460331</td>
      <td>0.675030</td>
      <td>1.784743</td>
      <td>-0.580025</td>
      <td>0.876680</td>
      <td>1.001622</td>
      <td>0.331326</td>
      <td>0.073187</td>
      <td>1.418784</td>
      <td>-0.960307</td>
      <td>...</td>
      <td>-0.337706</td>
      <td>-0.634420</td>
      <td>-0.386967</td>
      <td>-0.475001</td>
      <td>0.377240</td>
      <td>-0.712676</td>
      <td>-0.097320</td>
      <td>-0.160700</td>
      <td>0.284322</td>
      <td>-0.161214</td>
    </tr>
    <tr>
      <th>279021</th>
      <td>-0.283365</td>
      <td>-3.919257</td>
      <td>-3.961012</td>
      <td>0.919706</td>
      <td>-0.377837</td>
      <td>-0.798445</td>
      <td>2.460863</td>
      <td>-0.730901</td>
      <td>-0.140860</td>
      <td>-0.355759</td>
      <td>...</td>
      <td>1.068077</td>
      <td>0.352034</td>
      <td>-1.258735</td>
      <td>0.896639</td>
      <td>0.246736</td>
      <td>0.275734</td>
      <td>-0.352874</td>
      <td>0.120716</td>
      <td>0.983297</td>
      <td>17.002501</td>
    </tr>
  </tbody>
</table>
<p>56962 rows × 30 columns</p>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Aplicando-o-Undersampling">Aplicando o Undersampling<a class="anchor-link" href="#Aplicando-o-Undersampling">&#182;</a></h2><ul>
<li><strong>Conceito</strong>: Consiste em reduzir o número de registros da classe majoritária para o mesmo número de registros da classe minoritária, tornando assim os dados balanceados.</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Unindo as bases de treino</span>
<span class="n">df_train_merged</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_original</span><span class="p">,</span> <span class="n">y_train_original</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_train_merged</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[16]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>193580</th>
      <td>-0.799840</td>
      <td>0.475496</td>
      <td>0.945912</td>
      <td>0.360518</td>
      <td>0.849287</td>
      <td>-0.022402</td>
      <td>0.946082</td>
      <td>-0.118777</td>
      <td>-0.132950</td>
      <td>-0.676126</td>
      <td>...</td>
      <td>-0.301974</td>
      <td>0.365713</td>
      <td>-0.575632</td>
      <td>-0.598082</td>
      <td>-1.066174</td>
      <td>0.020482</td>
      <td>-0.058998</td>
      <td>0.535133</td>
      <td>0.704895</td>
      <td>0</td>
    </tr>
    <tr>
      <th>281512</th>
      <td>1.606285</td>
      <td>-0.703248</td>
      <td>-0.394818</td>
      <td>1.486715</td>
      <td>-0.788096</td>
      <td>-0.504766</td>
      <td>-0.227999</td>
      <td>-0.115749</td>
      <td>0.882403</td>
      <td>0.140248</td>
      <td>...</td>
      <td>0.713657</td>
      <td>-0.021267</td>
      <td>0.040442</td>
      <td>-0.156591</td>
      <td>-0.583700</td>
      <td>0.022747</td>
      <td>0.002051</td>
      <td>1.005345</td>
      <td>2.323077</td>
      <td>0</td>
    </tr>
    <tr>
      <th>83404</th>
      <td>1.281666</td>
      <td>0.069899</td>
      <td>-0.068433</td>
      <td>-0.118893</td>
      <td>-0.178783</td>
      <td>-0.795593</td>
      <td>0.142466</td>
      <td>-0.089915</td>
      <td>-0.153660</td>
      <td>0.061727</td>
      <td>...</td>
      <td>-1.371226</td>
      <td>0.159838</td>
      <td>-0.059506</td>
      <td>0.088230</td>
      <td>0.631566</td>
      <td>-0.111973</td>
      <td>-0.012174</td>
      <td>-0.291376</td>
      <td>-0.189091</td>
      <td>0</td>
    </tr>
    <tr>
      <th>131366</th>
      <td>-0.247623</td>
      <td>1.192310</td>
      <td>0.733828</td>
      <td>-0.278547</td>
      <td>0.832577</td>
      <td>-0.141225</td>
      <td>0.796655</td>
      <td>-0.069621</td>
      <td>-0.526500</td>
      <td>-0.556700</td>
      <td>...</td>
      <td>-0.825071</td>
      <td>-0.196949</td>
      <td>-1.027739</td>
      <td>0.078189</td>
      <td>0.153566</td>
      <td>0.252257</td>
      <td>0.087571</td>
      <td>-0.059494</td>
      <td>-0.209930</td>
      <td>0</td>
    </tr>
    <tr>
      <th>169064</th>
      <td>2.109995</td>
      <td>0.161872</td>
      <td>-1.950143</td>
      <td>0.263848</td>
      <td>0.775884</td>
      <td>-0.440883</td>
      <td>0.182684</td>
      <td>-0.192945</td>
      <td>0.477652</td>
      <td>-0.396496</td>
      <td>...</td>
      <td>-1.001854</td>
      <td>0.267583</td>
      <td>-0.111757</td>
      <td>-0.179542</td>
      <td>0.213154</td>
      <td>-0.057794</td>
      <td>-0.036438</td>
      <td>0.409590</td>
      <td>-0.289650</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>63856</th>
      <td>-0.043734</td>
      <td>-0.551311</td>
      <td>1.569492</td>
      <td>-1.903996</td>
      <td>-1.151121</td>
      <td>-0.053123</td>
      <td>-0.499013</td>
      <td>0.135010</td>
      <td>-2.136722</td>
      <td>1.023972</td>
      <td>...</td>
      <td>-0.583264</td>
      <td>-0.013246</td>
      <td>-0.049053</td>
      <td>-0.101647</td>
      <td>-0.366528</td>
      <td>0.056215</td>
      <td>0.013936</td>
      <td>-0.396375</td>
      <td>0.111888</td>
      <td>0</td>
    </tr>
    <tr>
      <th>81968</th>
      <td>1.140277</td>
      <td>-0.004898</td>
      <td>0.072729</td>
      <td>0.918752</td>
      <td>-0.129861</td>
      <td>-0.042564</td>
      <td>-0.127994</td>
      <td>0.223495</td>
      <td>0.153317</td>
      <td>0.211107</td>
      <td>...</td>
      <td>0.058538</td>
      <td>-0.107472</td>
      <td>-0.369613</td>
      <td>0.528540</td>
      <td>-0.288810</td>
      <td>0.004279</td>
      <td>0.001099</td>
      <td>-0.299023</td>
      <td>0.036364</td>
      <td>0</td>
    </tr>
    <tr>
      <th>140036</th>
      <td>-0.754934</td>
      <td>-1.802975</td>
      <td>0.866239</td>
      <td>-1.690596</td>
      <td>-3.007219</td>
      <td>1.865597</td>
      <td>0.741822</td>
      <td>0.098395</td>
      <td>-1.798257</td>
      <td>0.883077</td>
      <td>...</td>
      <td>1.268334</td>
      <td>0.620800</td>
      <td>-0.282679</td>
      <td>-1.342805</td>
      <td>-0.245118</td>
      <td>0.375048</td>
      <td>0.193864</td>
      <td>-0.013367</td>
      <td>7.153846</td>
      <td>0</td>
    </tr>
    <tr>
      <th>202552</th>
      <td>2.051854</td>
      <td>-1.051863</td>
      <td>-2.279919</td>
      <td>-1.689759</td>
      <td>-0.048993</td>
      <td>-0.868512</td>
      <td>0.092609</td>
      <td>-0.329633</td>
      <td>-0.646595</td>
      <td>0.696963</td>
      <td>...</td>
      <td>-0.583088</td>
      <td>0.081217</td>
      <td>0.366751</td>
      <td>-0.048046</td>
      <td>0.634649</td>
      <td>-0.124288</td>
      <td>-0.065370</td>
      <td>0.584291</td>
      <td>1.234126</td>
      <td>0</td>
    </tr>
    <tr>
      <th>80841</th>
      <td>-0.496414</td>
      <td>0.902277</td>
      <td>1.383164</td>
      <td>0.036025</td>
      <td>0.031949</td>
      <td>-0.852536</td>
      <td>0.523787</td>
      <td>0.097163</td>
      <td>-0.586178</td>
      <td>-0.324452</td>
      <td>...</td>
      <td>-0.588153</td>
      <td>0.046176</td>
      <td>0.469163</td>
      <td>-0.226233</td>
      <td>0.043261</td>
      <td>0.231659</td>
      <td>0.092114</td>
      <td>-0.304955</td>
      <td>-0.149930</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>227845 rows × 31 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Dividindo os dados com base na classe das transações</span>
<span class="n">classe_majoritaria</span> <span class="o">=</span> <span class="n">df_train_merged</span><span class="p">[</span><span class="n">df_train_merged</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">classe_minoritaria</span> <span class="o">=</span> <span class="n">df_train_merged</span><span class="p">[</span><span class="n">df_train_merged</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Aplicando o Undersampling de forma randômica no dataframe da classe majoritária, com base no número de registros do dataframe da classe minotirária</span>
<span class="n">classe_majoritaria_undersampled</span> <span class="o">=</span> <span class="n">resample</span><span class="p">(</span><span class="n">classe_majoritaria</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">classe_minoritaria</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">classe_majoritaria_undersampled</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[18]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>68840</th>
      <td>1.154025</td>
      <td>-0.359806</td>
      <td>1.093413</td>
      <td>0.429951</td>
      <td>-1.239700</td>
      <td>-0.527943</td>
      <td>-0.636029</td>
      <td>0.067462</td>
      <td>1.027800</td>
      <td>-0.272498</td>
      <td>...</td>
      <td>-0.139390</td>
      <td>0.035046</td>
      <td>0.411535</td>
      <td>0.120332</td>
      <td>0.622361</td>
      <td>-0.022939</td>
      <td>0.025590</td>
      <td>-0.369735</td>
      <td>0.214545</td>
      <td>0</td>
    </tr>
    <tr>
      <th>61514</th>
      <td>-0.297973</td>
      <td>0.351290</td>
      <td>1.849945</td>
      <td>1.638667</td>
      <td>0.685234</td>
      <td>0.642582</td>
      <td>0.026520</td>
      <td>0.118727</td>
      <td>-0.901637</td>
      <td>0.723482</td>
      <td>...</td>
      <td>0.604820</td>
      <td>0.052452</td>
      <td>-0.221895</td>
      <td>-1.119664</td>
      <td>0.925630</td>
      <td>-0.001380</td>
      <td>-0.032474</td>
      <td>-0.408368</td>
      <td>-0.236923</td>
      <td>0</td>
    </tr>
    <tr>
      <th>201755</th>
      <td>2.110644</td>
      <td>0.268234</td>
      <td>-2.179975</td>
      <td>1.034858</td>
      <td>0.959632</td>
      <td>-0.766823</td>
      <td>0.649142</td>
      <td>-0.309518</td>
      <td>0.070663</td>
      <td>0.402032</td>
      <td>...</td>
      <td>0.240494</td>
      <td>-0.008892</td>
      <td>0.229223</td>
      <td>0.494869</td>
      <td>-0.481817</td>
      <td>-0.042575</td>
      <td>-0.065100</td>
      <td>0.580074</td>
      <td>-0.293706</td>
      <td>0</td>
    </tr>
    <tr>
      <th>66278</th>
      <td>-2.418556</td>
      <td>-1.656510</td>
      <td>2.581566</td>
      <td>-0.555481</td>
      <td>1.666799</td>
      <td>-0.470054</td>
      <td>-1.456528</td>
      <td>0.759810</td>
      <td>0.231895</td>
      <td>-0.578651</td>
      <td>...</td>
      <td>0.610574</td>
      <td>0.137288</td>
      <td>-0.204685</td>
      <td>0.194957</td>
      <td>1.094020</td>
      <td>0.178317</td>
      <td>0.142975</td>
      <td>-0.383736</td>
      <td>-0.048392</td>
      <td>0</td>
    </tr>
    <tr>
      <th>112829</th>
      <td>-0.849435</td>
      <td>1.693047</td>
      <td>1.018407</td>
      <td>0.991312</td>
      <td>1.520834</td>
      <td>0.162477</td>
      <td>1.402944</td>
      <td>-0.164761</td>
      <td>-1.678905</td>
      <td>0.108561</td>
      <td>...</td>
      <td>0.139724</td>
      <td>-0.439915</td>
      <td>-0.742381</td>
      <td>0.514093</td>
      <td>-0.039313</td>
      <td>-0.236555</td>
      <td>0.072259</td>
      <td>-0.138828</td>
      <td>-0.297063</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>60127</th>
      <td>0.810782</td>
      <td>-0.742485</td>
      <td>-0.018558</td>
      <td>0.132433</td>
      <td>-0.760161</td>
      <td>-1.028473</td>
      <td>0.381905</td>
      <td>-0.354080</td>
      <td>0.123121</td>
      <td>-0.316518</td>
      <td>...</td>
      <td>-0.003712</td>
      <td>-0.287888</td>
      <td>0.456330</td>
      <td>0.313603</td>
      <td>1.076095</td>
      <td>-0.131116</td>
      <td>0.045679</td>
      <td>-0.416626</td>
      <td>3.332867</td>
      <td>0</td>
    </tr>
    <tr>
      <th>164271</th>
      <td>2.012017</td>
      <td>-0.180197</td>
      <td>-1.028308</td>
      <td>0.333356</td>
      <td>-0.232256</td>
      <td>-0.969360</td>
      <td>0.007041</td>
      <td>-0.129667</td>
      <td>0.446591</td>
      <td>0.275221</td>
      <td>...</td>
      <td>-0.662015</td>
      <td>0.352867</td>
      <td>0.046517</td>
      <td>-0.379175</td>
      <td>0.176481</td>
      <td>-0.081817</td>
      <td>-0.071598</td>
      <td>0.375326</td>
      <td>-0.282657</td>
      <td>0</td>
    </tr>
    <tr>
      <th>255685</th>
      <td>-1.757812</td>
      <td>1.268514</td>
      <td>-0.243560</td>
      <td>0.834001</td>
      <td>0.370026</td>
      <td>0.082730</td>
      <td>0.201648</td>
      <td>0.651833</td>
      <td>0.323763</td>
      <td>1.018907</td>
      <td>...</td>
      <td>0.851019</td>
      <td>-0.144330</td>
      <td>0.699116</td>
      <td>0.010938</td>
      <td>-0.428783</td>
      <td>0.202376</td>
      <td>-0.080685</td>
      <td>0.854054</td>
      <td>-0.167832</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1232</th>
      <td>-0.194291</td>
      <td>1.418104</td>
      <td>-0.121403</td>
      <td>0.923643</td>
      <td>0.281804</td>
      <td>-0.714429</td>
      <td>0.606500</td>
      <td>0.267974</td>
      <td>-0.778569</td>
      <td>-0.074793</td>
      <td>...</td>
      <td>0.757402</td>
      <td>0.085444</td>
      <td>0.104186</td>
      <td>-0.743330</td>
      <td>-0.385085</td>
      <td>0.335413</td>
      <td>0.165982</td>
      <td>-0.983039</td>
      <td>-0.296643</td>
      <td>0</td>
    </tr>
    <tr>
      <th>243711</th>
      <td>2.043561</td>
      <td>-0.274111</td>
      <td>-0.545477</td>
      <td>0.005392</td>
      <td>-0.309407</td>
      <td>-0.386478</td>
      <td>-0.384668</td>
      <td>-0.149291</td>
      <td>1.134972</td>
      <td>-0.254586</td>
      <td>...</td>
      <td>-0.405086</td>
      <td>0.281361</td>
      <td>-0.636967</td>
      <td>-0.356891</td>
      <td>-0.248859</td>
      <td>0.018335</td>
      <td>-0.039005</td>
      <td>0.791705</td>
      <td>-0.167832</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>383 rows × 31 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Unindo os dataframes das diferentes classes</span>
<span class="n">df_undersampled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">classe_majoritaria_undersampled</span><span class="p">,</span> <span class="n">classe_minoritaria</span><span class="p">])</span>
<span class="n">display</span><span class="p">(</span><span class="n">df_undersampled</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">df_undersampled</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>68840</th>
      <td>1.154025</td>
      <td>-0.359806</td>
      <td>1.093413</td>
      <td>0.429951</td>
      <td>-1.239700</td>
      <td>-0.527943</td>
      <td>-0.636029</td>
      <td>0.067462</td>
      <td>1.027800</td>
      <td>-0.272498</td>
      <td>...</td>
      <td>-0.139390</td>
      <td>0.035046</td>
      <td>0.411535</td>
      <td>0.120332</td>
      <td>0.622361</td>
      <td>-0.022939</td>
      <td>0.025590</td>
      <td>-0.369735</td>
      <td>0.214545</td>
      <td>0</td>
    </tr>
    <tr>
      <th>61514</th>
      <td>-0.297973</td>
      <td>0.351290</td>
      <td>1.849945</td>
      <td>1.638667</td>
      <td>0.685234</td>
      <td>0.642582</td>
      <td>0.026520</td>
      <td>0.118727</td>
      <td>-0.901637</td>
      <td>0.723482</td>
      <td>...</td>
      <td>0.604820</td>
      <td>0.052452</td>
      <td>-0.221895</td>
      <td>-1.119664</td>
      <td>0.925630</td>
      <td>-0.001380</td>
      <td>-0.032474</td>
      <td>-0.408368</td>
      <td>-0.236923</td>
      <td>0</td>
    </tr>
    <tr>
      <th>201755</th>
      <td>2.110644</td>
      <td>0.268234</td>
      <td>-2.179975</td>
      <td>1.034858</td>
      <td>0.959632</td>
      <td>-0.766823</td>
      <td>0.649142</td>
      <td>-0.309518</td>
      <td>0.070663</td>
      <td>0.402032</td>
      <td>...</td>
      <td>0.240494</td>
      <td>-0.008892</td>
      <td>0.229223</td>
      <td>0.494869</td>
      <td>-0.481817</td>
      <td>-0.042575</td>
      <td>-0.065100</td>
      <td>0.580074</td>
      <td>-0.293706</td>
      <td>0</td>
    </tr>
    <tr>
      <th>66278</th>
      <td>-2.418556</td>
      <td>-1.656510</td>
      <td>2.581566</td>
      <td>-0.555481</td>
      <td>1.666799</td>
      <td>-0.470054</td>
      <td>-1.456528</td>
      <td>0.759810</td>
      <td>0.231895</td>
      <td>-0.578651</td>
      <td>...</td>
      <td>0.610574</td>
      <td>0.137288</td>
      <td>-0.204685</td>
      <td>0.194957</td>
      <td>1.094020</td>
      <td>0.178317</td>
      <td>0.142975</td>
      <td>-0.383736</td>
      <td>-0.048392</td>
      <td>0</td>
    </tr>
    <tr>
      <th>112829</th>
      <td>-0.849435</td>
      <td>1.693047</td>
      <td>1.018407</td>
      <td>0.991312</td>
      <td>1.520834</td>
      <td>0.162477</td>
      <td>1.402944</td>
      <td>-0.164761</td>
      <td>-1.678905</td>
      <td>0.108561</td>
      <td>...</td>
      <td>0.139724</td>
      <td>-0.439915</td>
      <td>-0.742381</td>
      <td>0.514093</td>
      <td>-0.039313</td>
      <td>-0.236555</td>
      <td>0.072259</td>
      <td>-0.138828</td>
      <td>-0.297063</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>42945</th>
      <td>-13.680760</td>
      <td>6.990389</td>
      <td>-13.770001</td>
      <td>8.694897</td>
      <td>-11.426968</td>
      <td>-2.919845</td>
      <td>-14.594562</td>
      <td>8.622905</td>
      <td>-8.090697</td>
      <td>-12.780634</td>
      <td>...</td>
      <td>0.497599</td>
      <td>-0.509290</td>
      <td>0.732503</td>
      <td>0.280528</td>
      <td>0.280037</td>
      <td>-1.406687</td>
      <td>-0.663643</td>
      <td>-0.508986</td>
      <td>-0.297063</td>
      <td>1</td>
    </tr>
    <tr>
      <th>57615</th>
      <td>-1.232804</td>
      <td>2.244119</td>
      <td>-1.703826</td>
      <td>1.492536</td>
      <td>-1.192985</td>
      <td>-1.686110</td>
      <td>-1.864612</td>
      <td>0.856122</td>
      <td>-1.973535</td>
      <td>-3.942383</td>
      <td>...</td>
      <td>0.165682</td>
      <td>-0.013754</td>
      <td>0.474935</td>
      <td>-0.218725</td>
      <td>0.302809</td>
      <td>0.466031</td>
      <td>0.250134</td>
      <td>-0.430592</td>
      <td>-0.297063</td>
      <td>1</td>
    </tr>
    <tr>
      <th>150663</th>
      <td>-5.839192</td>
      <td>7.151532</td>
      <td>-12.816760</td>
      <td>7.031115</td>
      <td>-9.651272</td>
      <td>-2.938427</td>
      <td>-11.543207</td>
      <td>4.843627</td>
      <td>-3.494276</td>
      <td>-13.320789</td>
      <td>...</td>
      <td>1.054865</td>
      <td>0.530481</td>
      <td>0.472670</td>
      <td>-0.275998</td>
      <td>0.282435</td>
      <td>0.104886</td>
      <td>0.254417</td>
      <td>0.108218</td>
      <td>4.112727</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6108</th>
      <td>-4.397974</td>
      <td>1.358367</td>
      <td>-2.592844</td>
      <td>2.679787</td>
      <td>-1.128131</td>
      <td>-1.706536</td>
      <td>-3.496197</td>
      <td>-0.248778</td>
      <td>-0.247768</td>
      <td>-4.801637</td>
      <td>...</td>
      <td>0.176968</td>
      <td>-0.436207</td>
      <td>-0.053502</td>
      <td>0.252405</td>
      <td>-0.657488</td>
      <td>-0.827136</td>
      <td>0.849573</td>
      <td>-0.912139</td>
      <td>0.517483</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8972</th>
      <td>-4.064005</td>
      <td>3.100935</td>
      <td>-1.188498</td>
      <td>3.264633</td>
      <td>-1.903562</td>
      <td>0.320351</td>
      <td>-0.954940</td>
      <td>-3.277535</td>
      <td>2.820829</td>
      <td>1.015113</td>
      <td>...</td>
      <td>-0.078845</td>
      <td>0.193731</td>
      <td>0.479496</td>
      <td>-0.506603</td>
      <td>-0.409863</td>
      <td>-3.036271</td>
      <td>-0.630605</td>
      <td>-0.848627</td>
      <td>2.205035</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>766 rows × 31 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    383
1    383
Name: Class, dtype: int64</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Dividindo os registros já balanceados entre X e y</span>
<span class="n">X_undersampled</span> <span class="o">=</span> <span class="n">df_undersampled</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_undersampled</span> <span class="o">=</span> <span class="n">df_undersampled</span><span class="p">[</span><span class="s1">'Class'</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Aplicando-o-Oversampling">Aplicando o Oversampling<a class="anchor-link" href="#Aplicando-o-Oversampling">&#182;</a></h2><ul>
<li><strong>Conceito</strong>: Consiste em aumentar o número de registros da classe minoritária, criando instâncias sintéticas com base nas instâncias já existentes da classe minoritária, tornando assim os dados balanceados.</li>
</ul>
<h4 id="O-m%C3%A9todo-SMOTE-foi-aplicado,-pois-cria-registros-sint%C3%A9ticos-com-base-nos-valores-existentes-da-classe-minorit%C3%A1ria.">O m&#233;todo SMOTE foi aplicado, pois cria registros sint&#233;ticos com base nos valores existentes da classe minorit&#225;ria.<a class="anchor-link" href="#O-m%C3%A9todo-SMOTE-foi-aplicado,-pois-cria-registros-sint%C3%A9ticos-com-base-nos-valores-existentes-da-classe-minorit%C3%A1ria.">&#182;</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Criando o método, para aplicar somente para a classe minoritária</span>
<span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="s1">'minority'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>
<span class="n">X_oversampled</span><span class="p">,</span> <span class="n">y_oversampled</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train_original</span><span class="p">,</span> <span class="n">y_train_original</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_oversampled</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[22]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.799840</td>
      <td>0.475496</td>
      <td>0.945912</td>
      <td>0.360518</td>
      <td>0.849287</td>
      <td>-0.022402</td>
      <td>0.946082</td>
      <td>-0.118777</td>
      <td>-0.132950</td>
      <td>-0.676126</td>
      <td>...</td>
      <td>-0.211023</td>
      <td>-0.301974</td>
      <td>0.365713</td>
      <td>-0.575632</td>
      <td>-0.598082</td>
      <td>-1.066174</td>
      <td>0.020482</td>
      <td>-0.058998</td>
      <td>0.535133</td>
      <td>0.704895</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.606285</td>
      <td>-0.703248</td>
      <td>-0.394818</td>
      <td>1.486715</td>
      <td>-0.788096</td>
      <td>-0.504766</td>
      <td>-0.227999</td>
      <td>-0.115749</td>
      <td>0.882403</td>
      <td>0.140248</td>
      <td>...</td>
      <td>0.335594</td>
      <td>0.713657</td>
      <td>-0.021267</td>
      <td>0.040442</td>
      <td>-0.156591</td>
      <td>-0.583700</td>
      <td>0.022747</td>
      <td>0.002051</td>
      <td>1.005345</td>
      <td>2.323077</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.281666</td>
      <td>0.069899</td>
      <td>-0.068433</td>
      <td>-0.118893</td>
      <td>-0.178783</td>
      <td>-0.795593</td>
      <td>0.142466</td>
      <td>-0.089915</td>
      <td>-0.153660</td>
      <td>0.061727</td>
      <td>...</td>
      <td>-0.428059</td>
      <td>-1.371226</td>
      <td>0.159838</td>
      <td>-0.059506</td>
      <td>0.088230</td>
      <td>0.631566</td>
      <td>-0.111973</td>
      <td>-0.012174</td>
      <td>-0.291376</td>
      <td>-0.189091</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.247623</td>
      <td>1.192310</td>
      <td>0.733828</td>
      <td>-0.278547</td>
      <td>0.832577</td>
      <td>-0.141225</td>
      <td>0.796655</td>
      <td>-0.069621</td>
      <td>-0.526500</td>
      <td>-0.556700</td>
      <td>...</td>
      <td>-0.336441</td>
      <td>-0.825071</td>
      <td>-0.196949</td>
      <td>-1.027739</td>
      <td>0.078189</td>
      <td>0.153566</td>
      <td>0.252257</td>
      <td>0.087571</td>
      <td>-0.059494</td>
      <td>-0.209930</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.109995</td>
      <td>0.161872</td>
      <td>-1.950143</td>
      <td>0.263848</td>
      <td>0.775884</td>
      <td>-0.440883</td>
      <td>0.182684</td>
      <td>-0.192945</td>
      <td>0.477652</td>
      <td>-0.396496</td>
      <td>...</td>
      <td>-0.394579</td>
      <td>-1.001854</td>
      <td>0.267583</td>
      <td>-0.111757</td>
      <td>-0.179542</td>
      <td>0.213154</td>
      <td>-0.057794</td>
      <td>-0.036438</td>
      <td>0.409590</td>
      <td>-0.289650</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>454919</th>
      <td>-3.991890</td>
      <td>7.638717</td>
      <td>-13.239118</td>
      <td>9.487160</td>
      <td>-3.028639</td>
      <td>-3.116221</td>
      <td>-9.277551</td>
      <td>3.787909</td>
      <td>-5.984908</td>
      <td>-12.481804</td>
      <td>...</td>
      <td>1.867388</td>
      <td>0.039730</td>
      <td>-0.005285</td>
      <td>-1.193885</td>
      <td>0.309492</td>
      <td>0.620309</td>
      <td>1.758245</td>
      <td>0.799006</td>
      <td>-0.842056</td>
      <td>-0.293706</td>
    </tr>
    <tr>
      <th>454920</th>
      <td>-3.406233</td>
      <td>4.762496</td>
      <td>-8.832773</td>
      <td>5.861748</td>
      <td>-4.989291</td>
      <td>-3.996457</td>
      <td>-9.561903</td>
      <td>2.289039</td>
      <td>-3.484404</td>
      <td>-12.968203</td>
      <td>...</td>
      <td>2.137093</td>
      <td>0.584988</td>
      <td>-0.155884</td>
      <td>0.430295</td>
      <td>0.244165</td>
      <td>-0.206568</td>
      <td>1.945475</td>
      <td>0.985656</td>
      <td>0.107176</td>
      <td>-0.297065</td>
    </tr>
    <tr>
      <th>454921</th>
      <td>-5.908505</td>
      <td>3.517956</td>
      <td>-6.115408</td>
      <td>2.947817</td>
      <td>-2.192448</td>
      <td>-1.792948</td>
      <td>-4.181312</td>
      <td>0.371658</td>
      <td>-1.603796</td>
      <td>-4.318051</td>
      <td>...</td>
      <td>1.688749</td>
      <td>0.229929</td>
      <td>0.187394</td>
      <td>0.815977</td>
      <td>-0.503573</td>
      <td>0.372799</td>
      <td>-1.976511</td>
      <td>1.478033</td>
      <td>0.790481</td>
      <td>-0.007214</td>
    </tr>
    <tr>
      <th>454922</th>
      <td>-3.408834</td>
      <td>7.068453</td>
      <td>-12.271033</td>
      <td>9.250790</td>
      <td>-2.395075</td>
      <td>-3.011166</td>
      <td>-8.569481</td>
      <td>3.113141</td>
      <td>-6.043548</td>
      <td>-12.696984</td>
      <td>...</td>
      <td>1.805505</td>
      <td>0.004375</td>
      <td>-0.213528</td>
      <td>-1.188233</td>
      <td>0.492257</td>
      <td>0.615049</td>
      <td>1.901056</td>
      <td>0.843547</td>
      <td>-0.853387</td>
      <td>-0.293706</td>
    </tr>
    <tr>
      <th>454923</th>
      <td>-2.271696</td>
      <td>3.303448</td>
      <td>-1.702260</td>
      <td>1.103686</td>
      <td>0.403484</td>
      <td>1.713068</td>
      <td>-2.554233</td>
      <td>-9.026292</td>
      <td>2.714446</td>
      <td>-0.123169</td>
      <td>...</td>
      <td>8.519251</td>
      <td>-1.992894</td>
      <td>1.204436</td>
      <td>-0.340628</td>
      <td>-0.848678</td>
      <td>-0.548045</td>
      <td>-0.086632</td>
      <td>-0.104056</td>
      <td>0.330388</td>
      <td>-0.204389</td>
    </tr>
  </tbody>
</table>
<p>454924 rows × 30 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_oversampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[23]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>0    227462
1    227462
Name: Class, dtype: int64</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Sele%C3%A7%C3%A3o-de-modelos">Sele&#231;&#227;o de modelos<a class="anchor-link" href="#Sele%C3%A7%C3%A3o-de-modelos">&#182;</a></h1><h4 id="Agora-que-os-dados-j%C3%A1-est%C3%A3o-balanceados-pela-aplica%C3%A7%C3%A3o-dos-m%C3%A9todos-Undersampling-e-Oversampling,-a-etapa-de-sele%C3%A7%C3%A3o-dos-dados-pode-ser-aplicada.">Agora que os dados j&#225; est&#227;o balanceados pela aplica&#231;&#227;o dos m&#233;todos Undersampling e Oversampling, a etapa de sele&#231;&#227;o dos dados pode ser aplicada.<a class="anchor-link" href="#Agora-que-os-dados-j%C3%A1-est%C3%A3o-balanceados-pela-aplica%C3%A7%C3%A3o-dos-m%C3%A9todos-Undersampling-e-Oversampling,-a-etapa-de-sele%C3%A7%C3%A3o-dos-dados-pode-ser-aplicada.">&#182;</a></h4><h4 id="A-Valida%C3%A7%C3%A3o-Cruzada-Estratificada-ser%C3%A1-aplicada-nos-dados-de-Undersampling,-para-avaliar-qual-dos-classificadores-escolhidos-%C3%A9-o-que-obt%C3%A9m-melhor-performance-com-dados-balanceados.-Por-quest%C3%A3o-de-processamento,-essa-valida%C3%A7%C3%A3o-n%C3%A3o-ser%C3%A1-feita-nos-dados-de-Oversampling.">A Valida&#231;&#227;o Cruzada Estratificada ser&#225; aplicada nos dados de Undersampling, para avaliar qual dos classificadores escolhidos &#233; o que obt&#233;m melhor performance com dados balanceados. Por quest&#227;o de processamento, essa valida&#231;&#227;o n&#227;o ser&#225; feita nos dados de Oversampling.<a class="anchor-link" href="#A-Valida%C3%A7%C3%A3o-Cruzada-Estratificada-ser%C3%A1-aplicada-nos-dados-de-Undersampling,-para-avaliar-qual-dos-classificadores-escolhidos-%C3%A9-o-que-obt%C3%A9m-melhor-performance-com-dados-balanceados.-Por-quest%C3%A3o-de-processamento,-essa-valida%C3%A7%C3%A3o-n%C3%A3o-ser%C3%A1-feita-nos-dados-de-Oversampling.">&#182;</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Criando a instância do tipo StratifiedKFold()</span>
<span class="n">validacao_cruzada_estratificada</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Lista de algoritmos de classificação</span>
<span class="n">algoritmos_classificacao</span> <span class="o">=</span> <span class="p">[</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">(),</span> <span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span> 
                            <span class="n">GradientBoostingClassifier</span><span class="p">(),</span> <span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="n">allow_writing_files</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">XGBClassifier</span><span class="p">(),</span> <span class="n">LGBMClassifier</span><span class="p">()]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Avaliando-classificadores-com-dados-do-Undersampling">Avaliando classificadores com dados do Undersampling<a class="anchor-link" href="#Avaliando-classificadores-com-dados-do-Undersampling">&#182;</a></h2><h4 id="LGBMClassifier-obteve-o-melhor-resultado,-com-base-na-m%C3%A9dia-das-acur%C3%A1cias-e-no-desvio-padr%C3%A3o.">LGBMClassifier obteve o melhor resultado, com base na m&#233;dia das acur&#225;cias e no desvio padr&#227;o.<a class="anchor-link" href="#LGBMClassifier-obteve-o-melhor-resultado,-com-base-na-m%C3%A9dia-das-acur%C3%A1cias-e-no-desvio-padr%C3%A3o.">&#182;</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Lista para armazenar os resultados obtidos </span>
<span class="n">resultados_algoritmos_undersampling</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop para avaliar cada algoritmo, e armazenar seus resultados em uma lista</span>
<span class="k">for</span> <span class="n">classificador</span> <span class="ow">in</span> <span class="n">algoritmos_classificacao</span><span class="p">:</span>
    <span class="n">resultados_algoritmos_undersampling</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classificador</span><span class="p">,</span> <span class="n">X_undersampled</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y_undersampled</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s2">"accuracy"</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">validacao_cruzada_estratificada</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Listas para armazenar as médias da acurácia e os desvios padrões</span>
<span class="n">cv_means_undersampling</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">cv_std_undersampling</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Armazenando os resultados em cada uma das listas</span>
<span class="k">for</span> <span class="n">resultado</span> <span class="ow">in</span> <span class="n">resultados_algoritmos_undersampling</span><span class="p">:</span>
    <span class="n">cv_means_undersampling</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resultado</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">cv_std_undersampling</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resultado</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
    
<span class="c1"># Criando um Dataframe com os resultados obtidos</span>
<span class="n">df_result_undersampling</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">"MediaCV"</span><span class="p">:</span><span class="n">cv_means_undersampling</span><span class="p">,</span> <span class="s2">"DesvioPadraoCV"</span><span class="p">:</span> <span class="n">cv_std_undersampling</span><span class="p">,</span> 
                                        <span class="s2">"Algoritmo"</span><span class="p">:[</span><span class="s2">"LogisticRegression"</span><span class="p">,</span><span class="s2">"SVC"</span><span class="p">,</span> <span class="s2">"GaussianNB"</span><span class="p">,</span> <span class="s2">"RandomForest"</span><span class="p">,</span>
                                                     <span class="s2">"GradientBoosting"</span><span class="p">,</span> <span class="s2">"CatBoostClassifier"</span><span class="p">,</span> <span class="s2">"XGBClassifier"</span><span class="p">,</span> 
                                                     <span class="s2">"LGBMClassifier"</span><span class="p">]})</span>

<span class="n">df_result_undersampling</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">'MediaCV'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[29]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MediaCV</th>
      <th>DesvioPadraoCV</th>
      <th>Algoritmo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>0.942618</td>
      <td>0.022690</td>
      <td>CatBoostClassifier</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.942601</td>
      <td>0.018541</td>
      <td>LGBMClassifier</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.941302</td>
      <td>0.024250</td>
      <td>LogisticRegression</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.937389</td>
      <td>0.020796</td>
      <td>XGBClassifier</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.932177</td>
      <td>0.021544</td>
      <td>RandomForest</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.932160</td>
      <td>0.015009</td>
      <td>SVC</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.925649</td>
      <td>0.020063</td>
      <td>GradientBoosting</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.912577</td>
      <td>0.026596</td>
      <td>GaussianNB</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Treinando-o-modelo-LightGBM-Classifier">Treinando o modelo LightGBM Classifier<a class="anchor-link" href="#Treinando-o-modelo-LightGBM-Classifier">&#182;</a></h1><h4 id="Nesta-etapa,-o-modelo-LightGBM-ser%C3%A1-treinado-e-validado-com-base-nas-etapas-a-seguir:">Nesta etapa, o modelo LightGBM ser&#225; treinado e validado com base nas etapas a seguir:<a class="anchor-link" href="#Nesta-etapa,-o-modelo-LightGBM-ser%C3%A1-treinado-e-validado-com-base-nas-etapas-a-seguir:">&#182;</a></h4><p>1 - Utilizando dados da aplicação do Undersampling</p>
<p>2 - Utilizando dados da aplicação do Oversampling</p>
<p>3 - Validando seu melhor resultado com os dados originais</p>

</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Dados-do-Undersampling">Dados do Undersampling<a class="anchor-link" href="#Dados-do-Undersampling">&#182;</a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Split-nos-dados">Split nos dados<a class="anchor-link" href="#Split-nos-dados">&#182;</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_undersampled</span><span class="p">,</span> <span class="n">X_test_undersampled</span><span class="p">,</span> <span class="n">y_train_undersampled</span><span class="p">,</span> <span class="n">y_test_undersampled</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_undersampled</span><span class="p">,</span> <span class="n">y_undersampled</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Describe de treino:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_train_undersampled</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Describe de teste:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_test_undersampled</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Distribuição de fraude na base de treino:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_train_undersampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_train_undersampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Distribuição de fraude na base de teste:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_test_undersampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_test_undersampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Describe de treino:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>...</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
      <td>612.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-2.139180</td>
      <td>1.712597</td>
      <td>-3.300969</td>
      <td>2.197681</td>
      <td>-1.383054</td>
      <td>-0.642261</td>
      <td>-2.631275</td>
      <td>0.171444</td>
      <td>-1.204045</td>
      <td>-2.699635</td>
      <td>...</td>
      <td>0.534399</td>
      <td>-0.041808</td>
      <td>0.039245</td>
      <td>-0.055013</td>
      <td>0.021896</td>
      <td>0.016167</td>
      <td>0.101054</td>
      <td>0.048531</td>
      <td>0.049127</td>
      <td>1.018098</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.128373</td>
      <td>3.468211</td>
      <td>5.790388</td>
      <td>3.091559</td>
      <td>3.918308</td>
      <td>1.768271</td>
      <td>5.470968</td>
      <td>5.177004</td>
      <td>2.208552</td>
      <td>4.312329</td>
      <td>...</td>
      <td>3.147286</td>
      <td>1.262770</td>
      <td>1.063030</td>
      <td>0.566786</td>
      <td>0.659983</td>
      <td>0.478604</td>
      <td>0.934868</td>
      <td>0.410894</td>
      <td>0.557564</td>
      <td>2.786663</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-30.552380</td>
      <td>-7.449015</td>
      <td>-31.103685</td>
      <td>-3.679228</td>
      <td>-22.105532</td>
      <td>-6.406267</td>
      <td>-43.557242</td>
      <td>-41.044261</td>
      <td>-13.320155</td>
      <td>-24.588262</td>
      <td>...</td>
      <td>-22.797604</td>
      <td>-8.887017</td>
      <td>-15.981649</td>
      <td>-2.096524</td>
      <td>-3.536716</td>
      <td>-1.380614</td>
      <td>-7.263482</td>
      <td>-1.869290</td>
      <td>-0.989381</td>
      <td>-0.307692</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-2.599443</td>
      <td>-0.219207</td>
      <td>-5.118062</td>
      <td>-0.142603</td>
      <td>-1.851255</td>
      <td>-1.572363</td>
      <td>-3.031843</td>
      <td>-0.229829</td>
      <td>-2.294145</td>
      <td>-4.518809</td>
      <td>...</td>
      <td>-0.154015</td>
      <td>-0.549141</td>
      <td>-0.233307</td>
      <td>-0.402046</td>
      <td>-0.326053</td>
      <td>-0.313241</td>
      <td>-0.064591</td>
      <td>-0.054284</td>
      <td>-0.420161</td>
      <td>-0.280000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-0.793751</td>
      <td>0.915917</td>
      <td>-1.467593</td>
      <td>1.295292</td>
      <td>-0.383103</td>
      <td>-0.650664</td>
      <td>-0.697236</td>
      <td>0.228692</td>
      <td>-0.661950</td>
      <td>-0.819017</td>
      <td>...</td>
      <td>0.162164</td>
      <td>0.033164</td>
      <td>-0.022820</td>
      <td>0.001716</td>
      <td>0.062677</td>
      <td>-0.011277</td>
      <td>0.050111</td>
      <td>0.034968</td>
      <td>-0.005715</td>
      <td>-0.045455</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.002407</td>
      <td>2.608072</td>
      <td>0.270655</td>
      <td>4.097316</td>
      <td>0.571255</td>
      <td>0.152826</td>
      <td>0.299879</td>
      <td>0.860635</td>
      <td>0.212117</td>
      <td>0.008943</td>
      <td>...</td>
      <td>0.714349</td>
      <td>0.583581</td>
      <td>0.227009</td>
      <td>0.377555</td>
      <td>0.403993</td>
      <td>0.319144</td>
      <td>0.462040</td>
      <td>0.212081</td>
      <td>0.565837</td>
      <td>1.090769</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.304316</td>
      <td>22.057729</td>
      <td>3.236927</td>
      <td>12.114672</td>
      <td>11.095089</td>
      <td>6.474115</td>
      <td>5.802537</td>
      <td>20.007208</td>
      <td>4.874550</td>
      <td>5.455026</td>
      <td>...</td>
      <td>27.202839</td>
      <td>8.316275</td>
      <td>5.466230</td>
      <td>1.169203</td>
      <td>2.208209</td>
      <td>1.524942</td>
      <td>2.706566</td>
      <td>1.521218</td>
      <td>1.023375</td>
      <td>29.424755</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 30 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Describe de teste:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>...</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
      <td>154.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-3.465037</td>
      <td>2.531079</td>
      <td>-4.698957</td>
      <td>2.692747</td>
      <td>-2.239051</td>
      <td>-0.831325</td>
      <td>-4.088755</td>
      <td>0.200644</td>
      <td>-1.653478</td>
      <td>-3.529197</td>
      <td>...</td>
      <td>-0.116045</td>
      <td>0.118390</td>
      <td>-0.033130</td>
      <td>-0.098518</td>
      <td>0.081253</td>
      <td>0.022328</td>
      <td>0.080129</td>
      <td>0.025482</td>
      <td>-0.004596</td>
      <td>0.752141</td>
    </tr>
    <tr>
      <th>std</th>
      <td>7.313412</td>
      <td>4.699177</td>
      <td>8.063140</td>
      <td>3.582612</td>
      <td>5.544513</td>
      <td>1.912784</td>
      <td>7.351036</td>
      <td>5.849888</td>
      <td>2.739945</td>
      <td>5.500280</td>
      <td>...</td>
      <td>2.758646</td>
      <td>1.292117</td>
      <td>0.800247</td>
      <td>0.546676</td>
      <td>0.737488</td>
      <td>0.482453</td>
      <td>1.271803</td>
      <td>0.481006</td>
      <td>0.553525</td>
      <td>2.332636</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-29.200329</td>
      <td>-8.402154</td>
      <td>-30.177317</td>
      <td>-2.525992</td>
      <td>-21.225810</td>
      <td>-5.773192</td>
      <td>-41.506796</td>
      <td>-38.987263</td>
      <td>-13.434066</td>
      <td>-24.403185</td>
      <td>...</td>
      <td>-21.453736</td>
      <td>-2.454964</td>
      <td>-4.908301</td>
      <td>-1.544331</td>
      <td>-2.501833</td>
      <td>-1.054397</td>
      <td>-7.263482</td>
      <td>-1.552593</td>
      <td>-0.983039</td>
      <td>-0.307692</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-3.883364</td>
      <td>0.064202</td>
      <td>-5.357303</td>
      <td>-0.091302</td>
      <td>-1.936381</td>
      <td>-1.883724</td>
      <td>-4.571700</td>
      <td>-0.288809</td>
      <td>-2.570676</td>
      <td>-6.017646</td>
      <td>...</td>
      <td>-0.310452</td>
      <td>-0.594326</td>
      <td>-0.261245</td>
      <td>-0.446803</td>
      <td>-0.275254</td>
      <td>-0.292187</td>
      <td>-0.049951</td>
      <td>-0.056428</td>
      <td>-0.487335</td>
      <td>-0.293706</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-0.715584</td>
      <td>0.957499</td>
      <td>-1.599712</td>
      <td>1.639880</td>
      <td>-0.292976</td>
      <td>-0.642363</td>
      <td>-0.843994</td>
      <td>0.092638</td>
      <td>-0.860739</td>
      <td>-0.786989</td>
      <td>...</td>
      <td>0.140900</td>
      <td>0.041874</td>
      <td>-0.066583</td>
      <td>-0.031501</td>
      <td>0.074999</td>
      <td>0.031588</td>
      <td>0.058248</td>
      <td>0.023517</td>
      <td>-0.044495</td>
      <td>-0.081189</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.064993</td>
      <td>3.791366</td>
      <td>0.120712</td>
      <td>5.500780</td>
      <td>0.596306</td>
      <td>0.080708</td>
      <td>0.215893</td>
      <td>0.857853</td>
      <td>0.091864</td>
      <td>-0.002775</td>
      <td>...</td>
      <td>0.698665</td>
      <td>0.718788</td>
      <td>0.126102</td>
      <td>0.254836</td>
      <td>0.466652</td>
      <td>0.311033</td>
      <td>0.524831</td>
      <td>0.232611</td>
      <td>0.468561</td>
      <td>0.674825</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.152914</td>
      <td>21.467203</td>
      <td>2.403048</td>
      <td>11.906170</td>
      <td>9.880564</td>
      <td>6.065901</td>
      <td>1.402944</td>
      <td>19.168327</td>
      <td>3.353525</td>
      <td>5.097069</td>
      <td>...</td>
      <td>10.005998</td>
      <td>8.361985</td>
      <td>4.909111</td>
      <td>1.074587</td>
      <td>2.103868</td>
      <td>2.745261</td>
      <td>2.262942</td>
      <td>1.779364</td>
      <td>1.012427</td>
      <td>19.126713</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 30 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Distribuição de fraude na base de treino:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    309
1    303
Name: Class, dtype: int64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    0.504902
1    0.495098
Name: Class, dtype: float64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Distribuição de fraude na base de teste:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>1    80
0    74
Name: Class, dtype: int64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>1    0.519481
0    0.480519
Name: Class, dtype: float64</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Ajuste-de-Hiperpar%C3%A2metros-utilizando-a-biblioteca-Optuna">Ajuste de Hiperpar&#226;metros utilizando a biblioteca Optuna<a class="anchor-link" href="#Ajuste-de-Hiperpar%C3%A2metros-utilizando-a-biblioteca-Optuna">&#182;</a></h3><ul>
<li><p><strong>Optuna</strong> é uma biblioteca que permite criar "estudos" que vão testar uma série de hiperparâmetros para modelos de machine learning, e retornar os que obtiverem os melhores resultados.</p>
</li>
<li><p>Essa biblioteca será útil para encontrar os melhores hiperparâmetros para o classificador.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Definindo a função que o Optuna irá utilizar para testar os hiperparâmetros</span>
<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="c1"># Definindo os hiperparâmetros da LightGBM</span>
    <span class="n">parametros</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'n_estimators'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'n_estimators'</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="c1"># Quantidade máxima de nós</span>
        <span class="s1">'num_leaves'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'num_leaves'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="c1"># Quantidade máxima de folhas</span>
        <span class="s1">'max_depth'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'max_depth'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="c1"># Profundidade máxima das árvores</span>
        <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'learning_rate'</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="c1"># Taxa de aprendizado</span>
        <span class="s1">'subsample'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s1">'subsample'</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="c1"># Subsample usado para impedir overfitting</span>
        <span class="s1">'min_child_weight'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'min_child_weight'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="c1"># Quantidade mínima para criar um novo nó</span>
        <span class="s1">'lambda_l1'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'lambda_l1'</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="c1"># Penalização Lasso nas árvores</span>
        <span class="s1">'lambda_l2'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'lambda_l2'</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="c1"># Penalização Ridge nas árvores</span>
    <span class="p">}</span>

    <span class="c1"># Criando o modelo LightGBM com os hiperparâmetros otimizados</span>
    <span class="n">modelo</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">parametros</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>

    <span class="c1"># Treinando o modelo nos dados já balanceados pelo Undersampling</span>
    <span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_undersampled</span><span class="p">,</span> <span class="n">y_train_undersampled</span><span class="p">)</span>

    <span class="c1"># Previsões para a base de testes</span>
    <span class="n">y_pred_undersampled</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_undersampled</span><span class="p">)</span>

    <span class="c1"># Realiza o cálculo da métrica de Recall, que seria a métrica mais segura dadas as condições originais dos dados</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_undersampled</span><span class="p">,</span> <span class="n">y_pred_undersampled</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">recall</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Criando a instância do estudo</span>
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">'maximize'</span><span class="p">)</span> <span class="c1"># Maximizar a Recall</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Selecionando os melhores parâmetros com base na Recall</span>
<span class="n">melhores_hiperparametros_under</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_params</span>
<span class="n">melhor_recall_under</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_value</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Melhores hiperparâmetros: </span><span class="si">{</span><span class="n">melhores_hiperparametros_under</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Melhor Recall: </span><span class="si">{</span><span class="n">melhor_recall_under</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:17,564] A new study created in memory with name: no-name-4285148a-2179-47e0-a857-c1abb78c6030
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,672] Trial 0 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 46, &#39;num_leaves&#39;: 25, &#39;max_depth&#39;: 50, &#39;learning_rate&#39;: 0.06414814759061052, &#39;subsample&#39;: 0.9572629832239857, &#39;min_child_weight&#39;: 10, &#39;lambda_l1&#39;: 7.64583054375054e-06, &#39;lambda_l2&#39;: 0.0010712363079788533}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,718] Trial 1 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 99, &#39;num_leaves&#39;: 50, &#39;max_depth&#39;: 29, &#39;learning_rate&#39;: 0.06318883807401204, &#39;subsample&#39;: 0.7883041037199355, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 9.883611860642721e-05, &#39;lambda_l2&#39;: 7.350969540114646e-06}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,755] Trial 2 finished with value: 0.8625 and parameters: {&#39;n_estimators&#39;: 90, &#39;num_leaves&#39;: 6, &#39;max_depth&#39;: 26, &#39;learning_rate&#39;: 0.01613487961268894, &#39;subsample&#39;: 0.9452460395859228, &#39;min_child_weight&#39;: 12, &#39;lambda_l1&#39;: 7.566439551792626e-05, &#39;lambda_l2&#39;: 0.516580070450994}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,776] Trial 3 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 42, &#39;num_leaves&#39;: 4, &#39;max_depth&#39;: 15, &#39;learning_rate&#39;: 0.0892632943591896, &#39;subsample&#39;: 0.7023498614008078, &#39;min_child_weight&#39;: 17, &#39;lambda_l1&#39;: 6.06535374956314e-05, &#39;lambda_l2&#39;: 4.075755078362125e-06}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,804] Trial 4 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 27, &#39;num_leaves&#39;: 26, &#39;max_depth&#39;: 14, &#39;learning_rate&#39;: 0.007611158327637206, &#39;subsample&#39;: 0.9137487162781801, &#39;min_child_weight&#39;: 11, &#39;lambda_l1&#39;: 0.0012394646174834361, &#39;lambda_l2&#39;: 6.273347710772897e-06}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,840] Trial 5 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 129, &#39;num_leaves&#39;: 21, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.03787680548641182, &#39;subsample&#39;: 0.8116023107064428, &#39;min_child_weight&#39;: 16, &#39;lambda_l1&#39;: 0.07907996081589717, &#39;lambda_l2&#39;: 0.0332351136758873}. Best is trial 0 with value: 0.875.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.64583054375054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.64583054375054e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010712363079788533, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010712363079788533
[LightGBM] [Warning] lambda_l1 is set=7.64583054375054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.64583054375054e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010712363079788533, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010712363079788533
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.64583054375054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.64583054375054e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010712363079788533, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010712363079788533
[LightGBM] [Warning] lambda_l1 is set=9.883611860642721e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.883611860642721e-05
[LightGBM] [Warning] lambda_l2 is set=7.350969540114646e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.350969540114646e-06
[LightGBM] [Warning] lambda_l1 is set=9.883611860642721e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.883611860642721e-05
[LightGBM] [Warning] lambda_l2 is set=7.350969540114646e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.350969540114646e-06
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=9.883611860642721e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.883611860642721e-05
[LightGBM] [Warning] lambda_l2 is set=7.350969540114646e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.350969540114646e-06
[LightGBM] [Warning] lambda_l1 is set=7.566439551792626e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.566439551792626e-05
[LightGBM] [Warning] lambda_l2 is set=0.516580070450994, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.516580070450994
[LightGBM] [Warning] lambda_l1 is set=7.566439551792626e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.566439551792626e-05
[LightGBM] [Warning] lambda_l2 is set=0.516580070450994, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.516580070450994
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.566439551792626e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.566439551792626e-05
[LightGBM] [Warning] lambda_l2 is set=0.516580070450994, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.516580070450994
[LightGBM] [Warning] lambda_l1 is set=6.06535374956314e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.06535374956314e-05
[LightGBM] [Warning] lambda_l2 is set=4.075755078362125e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.075755078362125e-06
[LightGBM] [Warning] lambda_l1 is set=6.06535374956314e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.06535374956314e-05
[LightGBM] [Warning] lambda_l2 is set=4.075755078362125e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.075755078362125e-06
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=6.06535374956314e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.06535374956314e-05
[LightGBM] [Warning] lambda_l2 is set=4.075755078362125e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.075755078362125e-06
[LightGBM] [Warning] lambda_l1 is set=0.0012394646174834361, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0012394646174834361
[LightGBM] [Warning] lambda_l2 is set=6.273347710772897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.273347710772897e-06
[LightGBM] [Warning] lambda_l1 is set=0.0012394646174834361, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0012394646174834361
[LightGBM] [Warning] lambda_l2 is set=6.273347710772897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.273347710772897e-06
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0012394646174834361, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0012394646174834361
[LightGBM] [Warning] lambda_l2 is set=6.273347710772897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.273347710772897e-06
[LightGBM] [Warning] lambda_l1 is set=0.07907996081589717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07907996081589717
[LightGBM] [Warning] lambda_l2 is set=0.0332351136758873, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0332351136758873
[LightGBM] [Warning] lambda_l1 is set=0.07907996081589717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07907996081589717
[LightGBM] [Warning] lambda_l2 is set=0.0332351136758873, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0332351136758873
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.07907996081589717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07907996081589717
[LightGBM] [Warning] lambda_l2 is set=0.0332351136758873, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0332351136758873
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,869] Trial 6 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 48, &#39;num_leaves&#39;: 41, &#39;max_depth&#39;: 32, &#39;learning_rate&#39;: 0.001279162572252376, &#39;subsample&#39;: 0.8610754767410738, &#39;min_child_weight&#39;: 12, &#39;lambda_l1&#39;: 1.916624110877686e-05, &#39;lambda_l2&#39;: 0.4739832543282769}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,901] Trial 7 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 80, &#39;num_leaves&#39;: 33, &#39;max_depth&#39;: 34, &#39;learning_rate&#39;: 0.1318717296334345, &#39;subsample&#39;: 0.9584014413360665, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 1.4973593632772095e-05, &#39;lambda_l2&#39;: 0.005769276752724098}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,922] Trial 8 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 122, &#39;num_leaves&#39;: 2, &#39;max_depth&#39;: 49, &#39;learning_rate&#39;: 0.08104987641561003, &#39;subsample&#39;: 0.766171204239624, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 0.3721044394160185, &#39;lambda_l2&#39;: 9.489649951670719e-06}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:17,965] Trial 9 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 71, &#39;num_leaves&#39;: 42, &#39;max_depth&#39;: 9, &#39;learning_rate&#39;: 0.057312708054139676, &#39;subsample&#39;: 0.637857239948179, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 1.098090606174043e-05, &#39;lambda_l2&#39;: 0.003744874032528493}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.916624110877686e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.916624110877686e-05
[LightGBM] [Warning] lambda_l2 is set=0.4739832543282769, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4739832543282769
[LightGBM] [Warning] lambda_l1 is set=1.916624110877686e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.916624110877686e-05
[LightGBM] [Warning] lambda_l2 is set=0.4739832543282769, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4739832543282769
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.916624110877686e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.916624110877686e-05
[LightGBM] [Warning] lambda_l2 is set=0.4739832543282769, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4739832543282769
[LightGBM] [Warning] lambda_l1 is set=1.4973593632772095e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4973593632772095e-05
[LightGBM] [Warning] lambda_l2 is set=0.005769276752724098, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005769276752724098
[LightGBM] [Warning] lambda_l1 is set=1.4973593632772095e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4973593632772095e-05
[LightGBM] [Warning] lambda_l2 is set=0.005769276752724098, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005769276752724098
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.4973593632772095e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4973593632772095e-05
[LightGBM] [Warning] lambda_l2 is set=0.005769276752724098, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005769276752724098
[LightGBM] [Warning] lambda_l1 is set=0.3721044394160185, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3721044394160185
[LightGBM] [Warning] lambda_l2 is set=9.489649951670719e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.489649951670719e-06
[LightGBM] [Warning] lambda_l1 is set=0.3721044394160185, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3721044394160185
[LightGBM] [Warning] lambda_l2 is set=9.489649951670719e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.489649951670719e-06
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] lambda_l1 is set=0.3721044394160185, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3721044394160185
[LightGBM] [Warning] lambda_l2 is set=9.489649951670719e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.489649951670719e-06
[LightGBM] [Warning] lambda_l1 is set=1.098090606174043e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.098090606174043e-05
[LightGBM] [Warning] lambda_l2 is set=0.003744874032528493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003744874032528493
[LightGBM] [Warning] lambda_l1 is set=1.098090606174043e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.098090606174043e-05
[LightGBM] [Warning] lambda_l2 is set=0.003744874032528493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003744874032528493
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.098090606174043e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.098090606174043e-05
[LightGBM] [Warning] lambda_l2 is set=0.003744874032528493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003744874032528493
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:18,094] Trial 10 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 168, &#39;num_leaves&#39;: 18, &#39;max_depth&#39;: 48, &#39;learning_rate&#39;: 0.19418102986509997, &#39;subsample&#39;: 0.9852450620997547, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 1.0512772996071637e-06, &#39;lambda_l2&#39;: 0.0005267849679487845}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:18,210] Trial 11 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 155, &#39;num_leaves&#39;: 50, &#39;max_depth&#39;: 23, &#39;learning_rate&#39;: 0.04332687146189726, &#39;subsample&#39;: 0.842739015590202, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 0.0006941620209573928, &#39;lambda_l2&#39;: 0.0001690601468737998}. Best is trial 0 with value: 0.875.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.0512772996071637e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0512772996071637e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005267849679487845, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005267849679487845
[LightGBM] [Warning] lambda_l1 is set=1.0512772996071637e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0512772996071637e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005267849679487845, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005267849679487845
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.0512772996071637e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0512772996071637e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005267849679487845, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005267849679487845
[LightGBM] [Warning] lambda_l1 is set=0.0006941620209573928, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006941620209573928
[LightGBM] [Warning] lambda_l2 is set=0.0001690601468737998, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001690601468737998
[LightGBM] [Warning] lambda_l1 is set=0.0006941620209573928, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006941620209573928
[LightGBM] [Warning] lambda_l2 is set=0.0001690601468737998, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001690601468737998
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0006941620209573928, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006941620209573928
[LightGBM] [Warning] lambda_l2 is set=0.0001690601468737998, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001690601468737998
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:18,380] Trial 12 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 196, &#39;num_leaves&#39;: 14, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.025398401417464012, &#39;subsample&#39;: 0.8914782347416722, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 1.090894929335231e-06, &#39;lambda_l2&#39;: 5.555598542118009e-05}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:18,472] Trial 13 finished with value: 0.8625 and parameters: {&#39;n_estimators&#39;: 101, &#39;num_leaves&#39;: 34, &#39;max_depth&#39;: 3, &#39;learning_rate&#39;: 0.16827920533514973, &#39;subsample&#39;: 0.7549160851045076, &#39;min_child_weight&#39;: 14, &#39;lambda_l1&#39;: 0.0005703931944206458, &#39;lambda_l2&#39;: 1.6076213132136765e-06}. Best is trial 0 with value: 0.875.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.090894929335231e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.090894929335231e-06
[LightGBM] [Warning] lambda_l2 is set=5.555598542118009e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.555598542118009e-05
[LightGBM] [Warning] lambda_l1 is set=1.090894929335231e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.090894929335231e-06
[LightGBM] [Warning] lambda_l2 is set=5.555598542118009e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.555598542118009e-05
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.090894929335231e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.090894929335231e-06
[LightGBM] [Warning] lambda_l2 is set=5.555598542118009e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.555598542118009e-05
[LightGBM] [Warning] lambda_l1 is set=0.0005703931944206458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005703931944206458
[LightGBM] [Warning] lambda_l2 is set=1.6076213132136765e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6076213132136765e-06
[LightGBM] [Warning] lambda_l1 is set=0.0005703931944206458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005703931944206458
[LightGBM] [Warning] lambda_l2 is set=1.6076213132136765e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6076213132136765e-06
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0005703931944206458, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005703931944206458
[LightGBM] [Warning] lambda_l2 is set=1.6076213132136765e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6076213132136765e-06
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:18,564] Trial 14 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 61, &#39;num_leaves&#39;: 50, &#39;max_depth&#39;: 44, &#39;learning_rate&#39;: 0.06983546424680495, &#39;subsample&#39;: 0.989835357831444, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.004745423803196523, &#39;lambda_l2&#39;: 8.066020334591394e-05}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:18,655] Trial 15 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 26, &#39;num_leaves&#39;: 31, &#39;max_depth&#39;: 21, &#39;learning_rate&#39;: 0.018909189451489776, &#39;subsample&#39;: 0.9101501955593626, &#39;min_child_weight&#39;: 19, &#39;lambda_l1&#39;: 0.00014756116551019316, &#39;lambda_l2&#39;: 3.1418463590342373e-05}. Best is trial 0 with value: 0.875.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.004745423803196523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004745423803196523
[LightGBM] [Warning] lambda_l2 is set=8.066020334591394e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.066020334591394e-05
[LightGBM] [Warning] lambda_l1 is set=0.004745423803196523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004745423803196523
[LightGBM] [Warning] lambda_l2 is set=8.066020334591394e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.066020334591394e-05
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.004745423803196523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004745423803196523
[LightGBM] [Warning] lambda_l2 is set=8.066020334591394e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.066020334591394e-05
[LightGBM] [Warning] lambda_l1 is set=0.00014756116551019316, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00014756116551019316
[LightGBM] [Warning] lambda_l2 is set=3.1418463590342373e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1418463590342373e-05
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=0.00014756116551019316, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00014756116551019316
[LightGBM] [Warning] lambda_l2 is set=3.1418463590342373e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1418463590342373e-05
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000830 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00014756116551019316, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00014756116551019316
[LightGBM] [Warning] lambda_l2 is set=3.1418463590342373e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1418463590342373e-05
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=4.713130174613604e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.713130174613604e-06
[LightGBM] [Warning] lambda_l2 is set=0.0004208422889111312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004208422889111312
[LightGBM] [Warning] lambda_l1 is set=4.713130174613604e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.713130174613604e-06
[LightGBM] [Warning] lambda_l2 is set=0.0004208422889111312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004208422889111312
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:18,770] Trial 16 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 112, &#39;num_leaves&#39;: 12, &#39;max_depth&#39;: 31, &#39;learning_rate&#39;: 0.009158932829243396, &#39;subsample&#39;: 0.827080089515844, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 4.713130174613604e-06, &#39;lambda_l2&#39;: 0.0004208422889111312}. Best is trial 16 with value: 0.9.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:18,893] Trial 17 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 140, &#39;num_leaves&#39;: 11, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.010002376176681786, &#39;subsample&#39;: 0.8575876288384223, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 3.125290832461192e-06, &#39;lambda_l2&#39;: 0.0005574365776815373}. Best is trial 16 with value: 0.9.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.713130174613604e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.713130174613604e-06
[LightGBM] [Warning] lambda_l2 is set=0.0004208422889111312, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004208422889111312
[LightGBM] [Warning] lambda_l1 is set=3.125290832461192e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.125290832461192e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005574365776815373, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005574365776815373
[LightGBM] [Warning] lambda_l1 is set=3.125290832461192e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.125290832461192e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005574365776815373, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005574365776815373
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.125290832461192e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.125290832461192e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005574365776815373, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005574365776815373
[LightGBM] [Warning] lambda_l1 is set=3.3616988217800515e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3616988217800515e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010503802469651726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010503802469651726
[LightGBM] [Warning] lambda_l1 is set=3.3616988217800515e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3616988217800515e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010503802469651726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010503802469651726
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:19,007] Trial 18 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 145, &#39;num_leaves&#39;: 9, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.0078070458830432204, &#39;subsample&#39;: 0.8331228010041789, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 3.3616988217800515e-06, &#39;lambda_l2&#39;: 0.0010503802469651726}. Best is trial 16 with value: 0.9.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:19,145] Trial 19 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 175, &#39;num_leaves&#39;: 10, &#39;max_depth&#39;: 34, &#39;learning_rate&#39;: 0.0053702514911910795, &#39;subsample&#39;: 0.8240860684119924, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 3.7288576115556744e-06, &#39;lambda_l2&#39;: 0.0002203276857233214}. Best is trial 16 with value: 0.9.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=3.3616988217800515e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3616988217800515e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010503802469651726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010503802469651726
[LightGBM] [Warning] lambda_l1 is set=3.7288576115556744e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7288576115556744e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002203276857233214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002203276857233214
[LightGBM] [Warning] lambda_l1 is set=3.7288576115556744e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7288576115556744e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002203276857233214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002203276857233214
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.7288576115556744e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7288576115556744e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002203276857233214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002203276857233214
[LightGBM] [Warning] lambda_l1 is set=1.011596483509109e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.011596483509109e-06
[LightGBM] [Warning] lambda_l2 is set=0.0021016520064800607, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021016520064800607
[LightGBM] [Warning] lambda_l1 is set=1.011596483509109e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.011596483509109e-06
[LightGBM] [Warning] lambda_l2 is set=0.0021016520064800607, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021016520064800607
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:19,275] Trial 20 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 116, &#39;num_leaves&#39;: 15, &#39;max_depth&#39;: 37, &#39;learning_rate&#39;: 0.0035431837229763473, &#39;subsample&#39;: 0.7480339407893895, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 1.011596483509109e-06, &#39;lambda_l2&#39;: 0.0021016520064800607}. Best is trial 16 with value: 0.9.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:19,404] Trial 21 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 183, &#39;num_leaves&#39;: 10, &#39;max_depth&#39;: 31, &#39;learning_rate&#39;: 0.006085433274257465, &#39;subsample&#39;: 0.8151908643724665, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 4.033660982410649e-06, &#39;lambda_l2&#39;: 0.00033904023221300174}. Best is trial 16 with value: 0.9.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.011596483509109e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.011596483509109e-06
[LightGBM] [Warning] lambda_l2 is set=0.0021016520064800607, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021016520064800607
[LightGBM] [Warning] lambda_l1 is set=4.033660982410649e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.033660982410649e-06
[LightGBM] [Warning] lambda_l2 is set=0.00033904023221300174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00033904023221300174
[LightGBM] [Warning] lambda_l1 is set=4.033660982410649e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.033660982410649e-06
[LightGBM] [Warning] lambda_l2 is set=0.00033904023221300174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00033904023221300174
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=4.033660982410649e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.033660982410649e-06
[LightGBM] [Warning] lambda_l2 is set=0.00033904023221300174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00033904023221300174
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:19,515] Trial 22 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 149, &#39;num_leaves&#39;: 8, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.004759860593378177, &#39;subsample&#39;: 0.8408969283477412, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 4.441950300000598e-06, &#39;lambda_l2&#39;: 0.00013707308063724274}. Best is trial 16 with value: 0.9.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.441950300000598e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.441950300000598e-06
[LightGBM] [Warning] lambda_l2 is set=0.00013707308063724274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00013707308063724274
[LightGBM] [Warning] lambda_l1 is set=4.441950300000598e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.441950300000598e-06
[LightGBM] [Warning] lambda_l2 is set=0.00013707308063724274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00013707308063724274
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] lambda_l1 is set=4.441950300000598e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.441950300000598e-06
[LightGBM] [Warning] lambda_l2 is set=0.00013707308063724274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00013707308063724274
[LightGBM] [Warning] lambda_l1 is set=2.6369062903547135e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6369062903547135e-05
[LightGBM] [Warning] lambda_l2 is set=3.210321709446033e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.210321709446033e-05
[LightGBM] [Warning] lambda_l1 is set=2.6369062903547135e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6369062903547135e-05
[LightGBM] [Warning] lambda_l2 is set=3.210321709446033e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.210321709446033e-05
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:19,722] Trial 23 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 167, &#39;num_leaves&#39;: 19, &#39;max_depth&#39;: 44, &#39;learning_rate&#39;: 0.011003888716473493, &#39;subsample&#39;: 0.8733316350583779, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 2.6369062903547135e-05, &#39;lambda_l2&#39;: 3.210321709446033e-05}. Best is trial 16 with value: 0.9.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.6369062903547135e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6369062903547135e-05
[LightGBM] [Warning] lambda_l2 is set=3.210321709446033e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.210321709446033e-05
[LightGBM] [Warning] lambda_l1 is set=3.1563679939992094e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1563679939992094e-06
[LightGBM] [Warning] lambda_l2 is set=0.00023264226437759417, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00023264226437759417
[LightGBM] [Warning] lambda_l1 is set=3.1563679939992094e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1563679939992094e-06
[LightGBM] [Warning] lambda_l2 is set=0.00023264226437759417, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00023264226437759417
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.1563679939992094e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1563679939992094e-06
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:19,879] Trial 24 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 139, &#39;num_leaves&#39;: 14, &#39;max_depth&#39;: 28, &#39;learning_rate&#39;: 0.0035219580849537697, &#39;subsample&#39;: 0.8145707382158625, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 3.1563679939992094e-06, &#39;lambda_l2&#39;: 0.00023264226437759417}. Best is trial 16 with value: 0.9.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:20,045] Trial 25 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 178, &#39;num_leaves&#39;: 10, &#39;max_depth&#39;: 25, &#39;learning_rate&#39;: 0.010013810115568712, &#39;subsample&#39;: 0.8366981572653496, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 2.5008311142877564e-05, &#39;lambda_l2&#39;: 0.0015063497290773832}. Best is trial 16 with value: 0.9.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l2 is set=0.00023264226437759417, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00023264226437759417
[LightGBM] [Warning] lambda_l1 is set=2.5008311142877564e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5008311142877564e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015063497290773832, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015063497290773832
[LightGBM] [Warning] lambda_l1 is set=2.5008311142877564e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5008311142877564e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015063497290773832, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015063497290773832
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.5008311142877564e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5008311142877564e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015063497290773832, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015063497290773832
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:20,211] Trial 26 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 157, &#39;num_leaves&#39;: 6, &#39;max_depth&#39;: 19, &#39;learning_rate&#39;: 0.014489543211496552, &#39;subsample&#39;: 0.7857828189640906, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 7.970676060991946e-06, &#39;lambda_l2&#39;: 0.008190714441160875}. Best is trial 16 with value: 0.9.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.970676060991946e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.970676060991946e-06
[LightGBM] [Warning] lambda_l2 is set=0.008190714441160875, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008190714441160875
[LightGBM] [Warning] lambda_l1 is set=7.970676060991946e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.970676060991946e-06
[LightGBM] [Warning] lambda_l2 is set=0.008190714441160875, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008190714441160875
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] lambda_l1 is set=7.970676060991946e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.970676060991946e-06
[LightGBM] [Warning] lambda_l2 is set=0.008190714441160875, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008190714441160875
[LightGBM] [Warning] lambda_l1 is set=3.389822235860942e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.389822235860942e-06
[LightGBM] [Warning] lambda_l2 is set=0.0006463335625404741, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006463335625404741
[LightGBM] [Warning] lambda_l1 is set=3.389822235860942e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.389822235860942e-06
[LightGBM] [Warning] lambda_l2 is set=0.0006463335625404741, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006463335625404741
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:20,344] Trial 27 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 130, &#39;num_leaves&#39;: 22, &#39;max_depth&#39;: 44, &#39;learning_rate&#39;: 0.006638434356364966, &#39;subsample&#39;: 0.8889324112921945, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 3.389822235860942e-06, &#39;lambda_l2&#39;: 0.0006463335625404741}. Best is trial 27 with value: 0.9125.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:20,458] Trial 28 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 108, &#39;num_leaves&#39;: 22, &#39;max_depth&#39;: 44, &#39;learning_rate&#39;: 0.02083784413825698, &#39;subsample&#39;: 0.8870896887922763, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 3.940072761318173e-05, &#39;lambda_l2&#39;: 0.0006334969832004695}. Best is trial 27 with value: 0.9125.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=3.389822235860942e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.389822235860942e-06
[LightGBM] [Warning] lambda_l2 is set=0.0006463335625404741, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006463335625404741
[LightGBM] [Warning] lambda_l1 is set=3.940072761318173e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.940072761318173e-05
[LightGBM] [Warning] lambda_l2 is set=0.0006334969832004695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006334969832004695
[LightGBM] [Warning] lambda_l1 is set=3.940072761318173e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.940072761318173e-05
[LightGBM] [Warning] lambda_l2 is set=0.0006334969832004695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006334969832004695
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.940072761318173e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.940072761318173e-05
[LightGBM] [Warning] lambda_l2 is set=0.0006334969832004695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006334969832004695
[LightGBM] [Warning] lambda_l1 is set=7.613819622647416e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.613819622647416e-06
[LightGBM] [Warning] lambda_l2 is set=0.0011892603582071403, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011892603582071403
[LightGBM] [Warning] lambda_l1 is set=7.613819622647416e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.613819622647416e-06
[LightGBM] [Warning] lambda_l2 is set=0.0011892603582071403, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011892603582071403
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:20,624] Trial 29 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 131, &#39;num_leaves&#39;: 26, &#39;max_depth&#39;: 42, &#39;learning_rate&#39;: 0.00908878865926108, &#39;subsample&#39;: 0.8720640154131222, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 7.613819622647416e-06, &#39;lambda_l2&#39;: 0.0011892603582071403}. Best is trial 27 with value: 0.9125.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:20,734] Trial 30 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 129, &#39;num_leaves&#39;: 27, &#39;max_depth&#39;: 47, &#39;learning_rate&#39;: 0.029662227268527415, &#39;subsample&#39;: 0.922132341750379, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 1.0121980976030396e-05, &#39;lambda_l2&#39;: 0.0009541982334159155}. Best is trial 27 with value: 0.9125.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.613819622647416e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.613819622647416e-06
[LightGBM] [Warning] lambda_l2 is set=0.0011892603582071403, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011892603582071403
[LightGBM] [Warning] lambda_l1 is set=1.0121980976030396e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0121980976030396e-05
[LightGBM] [Warning] lambda_l2 is set=0.0009541982334159155, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009541982334159155
[LightGBM] [Warning] lambda_l1 is set=1.0121980976030396e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0121980976030396e-05
[LightGBM] [Warning] lambda_l2 is set=0.0009541982334159155, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009541982334159155
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.0121980976030396e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0121980976030396e-05
[LightGBM] [Warning] lambda_l2 is set=0.0009541982334159155, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009541982334159155
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:20,902] Trial 31 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 140, &#39;num_leaves&#39;: 29, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.007551211447829674, &#39;subsample&#39;: 0.8750804543836551, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 2.013838835210629e-06, &#39;lambda_l2&#39;: 0.0007771472931457983}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.013838835210629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.013838835210629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0007771472931457983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007771472931457983
[LightGBM] [Warning] lambda_l1 is set=2.013838835210629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.013838835210629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0007771472931457983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007771472931457983
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.013838835210629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.013838835210629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0007771472931457983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007771472931457983
[LightGBM] [Warning] lambda_l1 is set=7.28751194955347e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.28751194955347e-06
[LightGBM] [Warning] lambda_l2 is set=0.0024954894572099405, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0024954894572099405
[LightGBM] [Warning] lambda_l1 is set=7.28751194955347e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.28751194955347e-06
[LightGBM] [Warning] lambda_l2 is set=0.0024954894572099405, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0024954894572099405
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:21,048] Trial 32 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 115, &#39;num_leaves&#39;: 29, &#39;max_depth&#39;: 42, &#39;learning_rate&#39;: 0.012645498938921834, &#39;subsample&#39;: 0.876005566855698, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 7.28751194955347e-06, &#39;lambda_l2&#39;: 0.0024954894572099405}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,151] Trial 33 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 93, &#39;num_leaves&#39;: 23, &#39;max_depth&#39;: 45, &#39;learning_rate&#39;: 0.014579292992965122, &#39;subsample&#39;: 0.8994069613826328, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 1.8457960492609788e-06, &#39;lambda_l2&#39;: 0.00034597267307924495}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.28751194955347e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.28751194955347e-06
[LightGBM] [Warning] lambda_l2 is set=0.0024954894572099405, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0024954894572099405
[LightGBM] [Warning] lambda_l1 is set=1.8457960492609788e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8457960492609788e-06
[LightGBM] [Warning] lambda_l2 is set=0.00034597267307924495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00034597267307924495
[LightGBM] [Warning] lambda_l1 is set=1.8457960492609788e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8457960492609788e-06
[LightGBM] [Warning] lambda_l2 is set=0.00034597267307924495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00034597267307924495
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.8457960492609788e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8457960492609788e-06
[LightGBM] [Warning] lambda_l2 is set=0.00034597267307924495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00034597267307924495
[LightGBM] [Warning] lambda_l1 is set=2.0679647587684145e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0679647587684145e-06
[LightGBM] [Warning] lambda_l2 is set=0.001129004119889417, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001129004119889417
[LightGBM] [Warning] lambda_l1 is set=2.0679647587684145e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0679647587684145e-06
[LightGBM] [Warning] lambda_l2 is set=0.001129004119889417, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001129004119889417
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,272] Trial 34 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 131, &#39;num_leaves&#39;: 37, &#39;max_depth&#39;: 50, &#39;learning_rate&#39;: 0.007585478708621993, &#39;subsample&#39;: 0.935169976317635, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 2.0679647587684145e-06, &#39;lambda_l2&#39;: 0.001129004119889417}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,387] Trial 35 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 103, &#39;num_leaves&#39;: 25, &#39;max_depth&#39;: 31, &#39;learning_rate&#39;: 0.018410068762579935, &#39;subsample&#39;: 0.8658994899481778, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 7.320177104964733e-06, &#39;lambda_l2&#39;: 0.007723169013384814}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.0679647587684145e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0679647587684145e-06
[LightGBM] [Warning] lambda_l2 is set=0.001129004119889417, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001129004119889417
[LightGBM] [Warning] lambda_l1 is set=7.320177104964733e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.320177104964733e-06
[LightGBM] [Warning] lambda_l2 is set=0.007723169013384814, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007723169013384814
[LightGBM] [Warning] lambda_l1 is set=7.320177104964733e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.320177104964733e-06
[LightGBM] [Warning] lambda_l2 is set=0.007723169013384814, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007723169013384814
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.320177104964733e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.320177104964733e-06
[LightGBM] [Warning] lambda_l2 is set=0.007723169013384814, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007723169013384814
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,504] Trial 36 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 122, &#39;num_leaves&#39;: 28, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.00390651972024006, &#39;subsample&#39;: 0.8922858421190967, &#39;min_child_weight&#39;: 10, &#39;lambda_l1&#39;: 4.832429361631194e-05, &#39;lambda_l2&#39;: 9.501730797637806e-05}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,621] Trial 37 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 89, &#39;num_leaves&#39;: 18, &#39;max_depth&#39;: 37, &#39;learning_rate&#39;: 0.0028688370861964605, &#39;subsample&#39;: 0.9310654848716615, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 0.00013016684261086354, &#39;lambda_l2&#39;: 0.01902072266674407}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.832429361631194e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.832429361631194e-05
[LightGBM] [Warning] lambda_l2 is set=9.501730797637806e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.501730797637806e-05
[LightGBM] [Warning] lambda_l1 is set=4.832429361631194e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.832429361631194e-05
[LightGBM] [Warning] lambda_l2 is set=9.501730797637806e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.501730797637806e-05
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=4.832429361631194e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.832429361631194e-05
[LightGBM] [Warning] lambda_l2 is set=9.501730797637806e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.501730797637806e-05
[LightGBM] [Warning] lambda_l1 is set=0.00013016684261086354, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00013016684261086354
[LightGBM] [Warning] lambda_l2 is set=0.01902072266674407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01902072266674407
[LightGBM] [Warning] lambda_l1 is set=0.00013016684261086354, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00013016684261086354
[LightGBM] [Warning] lambda_l2 is set=0.01902072266674407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01902072266674407
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00013016684261086354, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00013016684261086354
[LightGBM] [Warning] lambda_l2 is set=0.01902072266674407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01902072266674407
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,729] Trial 38 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 79, &#39;num_leaves&#39;: 18, &#39;max_depth&#39;: 46, &#39;learning_rate&#39;: 0.00238877187590439, &#39;subsample&#39;: 0.9442172926055239, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 8.192029909820454e-05, &#39;lambda_l2&#39;: 0.014240435098409682}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,826] Trial 39 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 89, &#39;num_leaves&#39;: 24, &#39;max_depth&#39;: 37, &#39;learning_rate&#39;: 0.002239370577545957, &#39;subsample&#39;: 0.9235382642720673, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 1.598191538280638e-05, &#39;lambda_l2&#39;: 0.03664664713239827}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=8.192029909820454e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.192029909820454e-05
[LightGBM] [Warning] lambda_l2 is set=0.014240435098409682, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014240435098409682
[LightGBM] [Warning] lambda_l1 is set=8.192029909820454e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.192029909820454e-05
[LightGBM] [Warning] lambda_l2 is set=0.014240435098409682, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014240435098409682
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=8.192029909820454e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.192029909820454e-05
[LightGBM] [Warning] lambda_l2 is set=0.014240435098409682, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014240435098409682
[LightGBM] [Warning] lambda_l1 is set=1.598191538280638e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.598191538280638e-05
[LightGBM] [Warning] lambda_l2 is set=0.03664664713239827, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03664664713239827
[LightGBM] [Warning] lambda_l1 is set=1.598191538280638e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.598191538280638e-05
[LightGBM] [Warning] lambda_l2 is set=0.03664664713239827, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03664664713239827
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.598191538280638e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.598191538280638e-05
[LightGBM] [Warning] lambda_l2 is set=0.03664664713239827, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03664664713239827
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:21,945] Trial 40 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 134, &#39;num_leaves&#39;: 21, &#39;max_depth&#39;: 42, &#39;learning_rate&#39;: 0.00665184952393037, &#39;subsample&#39;: 0.9036016577066851, &#39;min_child_weight&#39;: 11, &#39;lambda_l1&#39;: 0.00015555520268302708, &#39;lambda_l2&#39;: 0.0023044496904773963}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,083] Trial 41 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 121, &#39;num_leaves&#39;: 17, &#39;max_depth&#39;: 36, &#39;learning_rate&#39;: 0.00894529418570942, &#39;subsample&#39;: 0.9585988425658343, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 6.572598482059062e-06, &#39;lambda_l2&#39;: 0.004006666928811063}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00015555520268302708, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015555520268302708
[LightGBM] [Warning] lambda_l2 is set=0.0023044496904773963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023044496904773963
[LightGBM] [Warning] lambda_l1 is set=0.00015555520268302708, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015555520268302708
[LightGBM] [Warning] lambda_l2 is set=0.0023044496904773963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023044496904773963
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00015555520268302708, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015555520268302708
[LightGBM] [Warning] lambda_l2 is set=0.0023044496904773963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023044496904773963
[LightGBM] [Warning] lambda_l1 is set=6.572598482059062e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.572598482059062e-06
[LightGBM] [Warning] lambda_l2 is set=0.004006666928811063, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004006666928811063
[LightGBM] [Warning] lambda_l1 is set=6.572598482059062e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.572598482059062e-06
[LightGBM] [Warning] lambda_l2 is set=0.004006666928811063, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004006666928811063
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=6.572598482059062e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.572598482059062e-06
[LightGBM] [Warning] lambda_l2 is set=0.004006666928811063, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004006666928811063
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,238] Trial 42 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 123, &#39;num_leaves&#39;: 16, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.00803215498420095, &#39;subsample&#39;: 0.967903832696524, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 1.5447150527627438e-05, &#39;lambda_l2&#39;: 0.004454429070420966}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,371] Trial 43 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 154, &#39;num_leaves&#39;: 30, &#39;max_depth&#39;: 42, &#39;learning_rate&#39;: 0.006097878323050851, &#39;subsample&#39;: 0.9732345519755312, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 1.4617182257848815e-05, &#39;lambda_l2&#39;: 0.024721941155639613}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.5447150527627438e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5447150527627438e-05
[LightGBM] [Warning] lambda_l2 is set=0.004454429070420966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004454429070420966
[LightGBM] [Warning] lambda_l1 is set=1.5447150527627438e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5447150527627438e-05
[LightGBM] [Warning] lambda_l2 is set=0.004454429070420966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004454429070420966
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.5447150527627438e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5447150527627438e-05
[LightGBM] [Warning] lambda_l2 is set=0.004454429070420966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004454429070420966
[LightGBM] [Warning] lambda_l1 is set=1.4617182257848815e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4617182257848815e-05
[LightGBM] [Warning] lambda_l2 is set=0.024721941155639613, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.024721941155639613
[LightGBM] [Warning] lambda_l1 is set=1.4617182257848815e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4617182257848815e-05
[LightGBM] [Warning] lambda_l2 is set=0.024721941155639613, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.024721941155639613
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.4617182257848815e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4617182257848815e-05
[LightGBM] [Warning] lambda_l2 is set=0.024721941155639613, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.024721941155639613
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,510] Trial 44 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 94, &#39;num_leaves&#39;: 26, &#39;max_depth&#39;: 39, &#39;learning_rate&#39;: 0.012324636453361184, &#39;subsample&#39;: 0.937925314108157, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 1.8631851350856016e-06, &#39;lambda_l2&#39;: 0.003994267229989068}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,629] Trial 45 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 63, &#39;num_leaves&#39;: 20, &#39;max_depth&#39;: 28, &#39;learning_rate&#39;: 0.004444610182432694, &#39;subsample&#39;: 0.9683104852233237, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 2.9672742278777936e-05, &#39;lambda_l2&#39;: 0.0008076094841062773}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.8631851350856016e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8631851350856016e-06
[LightGBM] [Warning] lambda_l2 is set=0.003994267229989068, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003994267229989068
[LightGBM] [Warning] lambda_l1 is set=1.8631851350856016e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8631851350856016e-06
[LightGBM] [Warning] lambda_l2 is set=0.003994267229989068, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003994267229989068
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.8631851350856016e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8631851350856016e-06
[LightGBM] [Warning] lambda_l2 is set=0.003994267229989068, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003994267229989068
[LightGBM] [Warning] lambda_l1 is set=2.9672742278777936e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9672742278777936e-05
[LightGBM] [Warning] lambda_l2 is set=0.0008076094841062773, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008076094841062773
[LightGBM] [Warning] lambda_l1 is set=2.9672742278777936e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9672742278777936e-05
[LightGBM] [Warning] lambda_l2 is set=0.0008076094841062773, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008076094841062773
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.9672742278777936e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9672742278777936e-05
[LightGBM] [Warning] lambda_l2 is set=0.0008076094841062773, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008076094841062773
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,735] Trial 46 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 83, &#39;num_leaves&#39;: 35, &#39;max_depth&#39;: 33, &#39;learning_rate&#39;: 0.007017181461965246, &#39;subsample&#39;: 0.9945709655862462, &#39;min_child_weight&#39;: 13, &#39;lambda_l1&#39;: 1.0962590531412745e-05, &#39;lambda_l2&#39;: 0.0015835854261065996}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,851] Trial 47 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 122, &#39;num_leaves&#39;: 16, &#39;max_depth&#39;: 48, &#39;learning_rate&#39;: 0.005052050216363679, &#39;subsample&#39;: 0.9476492044835554, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 5.433331945616989e-05, &#39;lambda_l2&#39;: 0.01183527502462615}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.0962590531412745e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0962590531412745e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015835854261065996, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015835854261065996
[LightGBM] [Warning] lambda_l1 is set=1.0962590531412745e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0962590531412745e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015835854261065996, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015835854261065996
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.0962590531412745e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0962590531412745e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015835854261065996, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015835854261065996
[LightGBM] [Warning] lambda_l1 is set=5.433331945616989e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.433331945616989e-05
[LightGBM] [Warning] lambda_l2 is set=0.01183527502462615, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01183527502462615
[LightGBM] [Warning] lambda_l1 is set=5.433331945616989e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.433331945616989e-05
[LightGBM] [Warning] lambda_l2 is set=0.01183527502462615, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01183527502462615
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.433331945616989e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.433331945616989e-05
[LightGBM] [Warning] lambda_l2 is set=0.01183527502462615, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01183527502462615
[LightGBM] [Warning] lambda_l1 is set=2.0556117313633804e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0556117313633804e-05
[LightGBM] [Warning] lambda_l2 is set=0.004733366683819381, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004733366683819381
[LightGBM] [Warning] lambda_l1 is set=2.0556117313633804e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0556117313633804e-05
[LightGBM] [Warning] lambda_l2 is set=0.004733366683819381, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004733366683819381
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:22,973] Trial 48 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 107, &#39;num_leaves&#39;: 39, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.008261102258778309, &#39;subsample&#39;: 0.9159623542506099, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 2.0556117313633804e-05, &#39;lambda_l2&#39;: 0.004733366683819381}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:23,057] Trial 49 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 42, &#39;num_leaves&#39;: 31, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.011327956556435271, &#39;subsample&#39;: 0.8820506193733031, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 1.8677735091062601e-06, &#39;lambda_l2&#39;: 0.07377052912328594}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.0556117313633804e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0556117313633804e-05
[LightGBM] [Warning] lambda_l2 is set=0.004733366683819381, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004733366683819381
[LightGBM] [Warning] lambda_l1 is set=1.8677735091062601e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8677735091062601e-06
[LightGBM] [Warning] lambda_l2 is set=0.07377052912328594, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07377052912328594
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=1.8677735091062601e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8677735091062601e-06
[LightGBM] [Warning] lambda_l2 is set=0.07377052912328594, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07377052912328594
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.8677735091062601e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8677735091062601e-06
[LightGBM] [Warning] lambda_l2 is set=0.07377052912328594, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07377052912328594
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=1.7240421508839775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7240421508839775e-05
[LightGBM] [Warning] lambda_l2 is set=0.0025138013073124337, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0025138013073124337
[LightGBM] [Warning] lambda_l1 is set=1.7240421508839775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7240421508839775e-05
[LightGBM] [Warning] lambda_l2 is set=0.0025138013073124337, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0025138013073124337
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:23,214] Trial 50 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 140, &#39;num_leaves&#39;: 13, &#39;max_depth&#39;: 46, &#39;learning_rate&#39;: 0.0029764944880198863, &#39;subsample&#39;: 0.9243354862720288, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 1.7240421508839775e-05, &#39;lambda_l2&#39;: 0.0025138013073124337}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:23,330] Trial 51 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 121, &#39;num_leaves&#39;: 17, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.008258674214974471, &#39;subsample&#39;: 0.970456404335336, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 6.928370252490903e-06, &#39;lambda_l2&#39;: 0.0056555941528010295}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.7240421508839775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7240421508839775e-05
[LightGBM] [Warning] lambda_l2 is set=0.0025138013073124337, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0025138013073124337
[LightGBM] [Warning] lambda_l1 is set=6.928370252490903e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.928370252490903e-06
[LightGBM] [Warning] lambda_l2 is set=0.0056555941528010295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0056555941528010295
[LightGBM] [Warning] lambda_l1 is set=6.928370252490903e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.928370252490903e-06
[LightGBM] [Warning] lambda_l2 is set=0.0056555941528010295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0056555941528010295
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=6.928370252490903e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.928370252490903e-06
[LightGBM] [Warning] lambda_l2 is set=0.0056555941528010295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0056555941528010295
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:23,460] Trial 52 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 126, &#39;num_leaves&#39;: 21, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.005725714344409151, &#39;subsample&#39;: 0.9762747681684788, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 6.102777730502374e-06, &#39;lambda_l2&#39;: 0.006486623339561244}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:23,579] Trial 53 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 134, &#39;num_leaves&#39;: 23, &#39;max_depth&#39;: 43, &#39;learning_rate&#39;: 0.008556621653332635, &#39;subsample&#39;: 0.9575922956063982, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 1.2843596647423412e-05, &#39;lambda_l2&#39;: 0.0007135698180964508}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=6.102777730502374e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.102777730502374e-06
[LightGBM] [Warning] lambda_l2 is set=0.006486623339561244, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006486623339561244
[LightGBM] [Warning] lambda_l1 is set=6.102777730502374e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.102777730502374e-06
[LightGBM] [Warning] lambda_l2 is set=0.006486623339561244, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006486623339561244
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=6.102777730502374e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.102777730502374e-06
[LightGBM] [Warning] lambda_l2 is set=0.006486623339561244, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006486623339561244
[LightGBM] [Warning] lambda_l1 is set=1.2843596647423412e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2843596647423412e-05
[LightGBM] [Warning] lambda_l2 is set=0.0007135698180964508, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007135698180964508
[LightGBM] [Warning] lambda_l1 is set=1.2843596647423412e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2843596647423412e-05
[LightGBM] [Warning] lambda_l2 is set=0.0007135698180964508, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007135698180964508
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.2843596647423412e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2843596647423412e-05
[LightGBM] [Warning] lambda_l2 is set=0.0007135698180964508, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007135698180964508
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:23,722] Trial 54 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 162, &#39;num_leaves&#39;: 19, &#39;max_depth&#39;: 33, &#39;learning_rate&#39;: 0.00631919142529457, &#39;subsample&#39;: 0.9966110178049632, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 2.2246097237615687e-06, &#39;lambda_l2&#39;: 0.0013855373993605924}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.2246097237615687e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2246097237615687e-06
[LightGBM] [Warning] lambda_l2 is set=0.0013855373993605924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013855373993605924
[LightGBM] [Warning] lambda_l1 is set=2.2246097237615687e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2246097237615687e-06
[LightGBM] [Warning] lambda_l2 is set=0.0013855373993605924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013855373993605924
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.2246097237615687e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2246097237615687e-06
[LightGBM] [Warning] lambda_l2 is set=0.0013855373993605924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013855373993605924
[LightGBM] [Warning] lambda_l1 is set=6.3567300684341246e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.3567300684341246e-06
[LightGBM] [Warning] lambda_l2 is set=0.002100378757754492, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002100378757754492
[LightGBM] [Warning] lambda_l1 is set=6.3567300684341246e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.3567300684341246e-06
[LightGBM] [Warning] lambda_l2 is set=0.002100378757754492, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002100378757754492
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:23,911] Trial 55 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 149, &#39;num_leaves&#39;: 16, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.015077226028846383, &#39;subsample&#39;: 0.9050718903879762, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 6.3567300684341246e-06, &#39;lambda_l2&#39;: 0.002100378757754492}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=6.3567300684341246e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.3567300684341246e-06
[LightGBM] [Warning] lambda_l2 is set=0.002100378757754492, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002100378757754492
[LightGBM] [Warning] lambda_l1 is set=4.195650360255503e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.195650360255503e-05
[LightGBM] [Warning] lambda_l2 is set=0.000489015858930123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000489015858930123
[LightGBM] [Warning] lambda_l1 is set=4.195650360255503e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.195650360255503e-05
[LightGBM] [Warning] lambda_l2 is set=0.000489015858930123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000489015858930123
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,069] Trial 56 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 102, &#39;num_leaves&#39;: 46, &#39;max_depth&#39;: 29, &#39;learning_rate&#39;: 0.009756114731172516, &#39;subsample&#39;: 0.9330244546381431, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 4.195650360255503e-05, &#39;lambda_l2&#39;: 0.000489015858930123}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,184] Trial 57 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 116, &#39;num_leaves&#39;: 32, &#39;max_depth&#39;: 36, &#39;learning_rate&#39;: 0.007299482063937368, &#39;subsample&#39;: 0.8531695681633817, &#39;min_child_weight&#39;: 16, &#39;lambda_l1&#39;: 1.1955560194055853e-06, &#39;lambda_l2&#39;: 0.0033812367176032226}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.195650360255503e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.195650360255503e-05
[LightGBM] [Warning] lambda_l2 is set=0.000489015858930123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000489015858930123
[LightGBM] [Warning] lambda_l1 is set=1.1955560194055853e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1955560194055853e-06
[LightGBM] [Warning] lambda_l2 is set=0.0033812367176032226, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0033812367176032226
[LightGBM] [Warning] lambda_l1 is set=1.1955560194055853e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1955560194055853e-06
[LightGBM] [Warning] lambda_l2 is set=0.0033812367176032226, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0033812367176032226
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.1955560194055853e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1955560194055853e-06
[LightGBM] [Warning] lambda_l2 is set=0.0033812367176032226, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0033812367176032226
[LightGBM] [Warning] lambda_l1 is set=4.471160120158838e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.471160120158838e-06
[LightGBM] [Warning] lambda_l2 is set=0.005466185001517602, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005466185001517602
[LightGBM] [Warning] lambda_l1 is set=4.471160120158838e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.471160120158838e-06
[LightGBM] [Warning] lambda_l2 is set=0.005466185001517602, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005466185001517602
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,336] Trial 58 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 142, &#39;num_leaves&#39;: 25, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.004291075214176221, &#39;subsample&#39;: 0.9527116776858666, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 4.471160120158838e-06, &#39;lambda_l2&#39;: 0.005466185001517602}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,448] Trial 59 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 73, &#39;num_leaves&#39;: 28, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.004986173970993207, &#39;subsample&#39;: 0.9857430200037971, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 2.9775144985993903e-06, &#39;lambda_l2&#39;: 0.00024600062475967294}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=4.471160120158838e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.471160120158838e-06
[LightGBM] [Warning] lambda_l2 is set=0.005466185001517602, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005466185001517602
[LightGBM] [Warning] lambda_l1 is set=2.9775144985993903e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9775144985993903e-06
[LightGBM] [Warning] lambda_l2 is set=0.00024600062475967294, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024600062475967294
[LightGBM] [Warning] lambda_l1 is set=2.9775144985993903e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9775144985993903e-06
[LightGBM] [Warning] lambda_l2 is set=0.00024600062475967294, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024600062475967294
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.9775144985993903e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9775144985993903e-06
[LightGBM] [Warning] lambda_l2 is set=0.00024600062475967294, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024600062475967294
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,555] Trial 60 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 111, &#39;num_leaves&#39;: 20, &#39;max_depth&#39;: 25, &#39;learning_rate&#39;: 0.010965379170513417, &#39;subsample&#39;: 0.8553722001543269, &#39;min_child_weight&#39;: 20, &#39;lambda_l1&#39;: 9.29660430203313e-06, &#39;lambda_l2&#39;: 0.0011426730863797327}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,715] Trial 61 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 124, &#39;num_leaves&#39;: 17, &#39;max_depth&#39;: 36, &#39;learning_rate&#39;: 0.009355048099955791, &#39;subsample&#39;: 0.9632960619891893, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 5.29338165689883e-06, &#39;lambda_l2&#39;: 0.003123406975193162}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=9.29660430203313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.29660430203313e-06
[LightGBM] [Warning] lambda_l2 is set=0.0011426730863797327, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011426730863797327
[LightGBM] [Warning] lambda_l1 is set=9.29660430203313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.29660430203313e-06
[LightGBM] [Warning] lambda_l2 is set=0.0011426730863797327, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011426730863797327
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=9.29660430203313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.29660430203313e-06
[LightGBM] [Warning] lambda_l2 is set=0.0011426730863797327, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011426730863797327
[LightGBM] [Warning] lambda_l1 is set=5.29338165689883e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.29338165689883e-06
[LightGBM] [Warning] lambda_l2 is set=0.003123406975193162, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003123406975193162
[LightGBM] [Warning] lambda_l1 is set=5.29338165689883e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.29338165689883e-06
[LightGBM] [Warning] lambda_l2 is set=0.003123406975193162, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003123406975193162
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.29338165689883e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.29338165689883e-06
[LightGBM] [Warning] lambda_l2 is set=0.003123406975193162, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003123406975193162
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,867] Trial 62 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 119, &#39;num_leaves&#39;: 13, &#39;max_depth&#39;: 34, &#39;learning_rate&#39;: 0.008412953978774751, &#39;subsample&#39;: 0.9578790849310658, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 9.843562602784452e-06, &#39;lambda_l2&#39;: 0.0035448134180790726}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:24,984] Trial 63 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 131, &#39;num_leaves&#39;: 13, &#39;max_depth&#39;: 33, &#39;learning_rate&#39;: 0.007523805776549581, &#39;subsample&#39;: 0.9798749043169779, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 2.2124849666134824e-05, &#39;lambda_l2&#39;: 0.01166637692857167}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=9.843562602784452e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.843562602784452e-06
[LightGBM] [Warning] lambda_l2 is set=0.0035448134180790726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035448134180790726
[LightGBM] [Warning] lambda_l1 is set=9.843562602784452e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.843562602784452e-06
[LightGBM] [Warning] lambda_l2 is set=0.0035448134180790726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035448134180790726
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=9.843562602784452e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.843562602784452e-06
[LightGBM] [Warning] lambda_l2 is set=0.0035448134180790726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0035448134180790726
[LightGBM] [Warning] lambda_l1 is set=2.2124849666134824e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2124849666134824e-05
[LightGBM] [Warning] lambda_l2 is set=0.01166637692857167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01166637692857167
[LightGBM] [Warning] lambda_l1 is set=2.2124849666134824e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2124849666134824e-05
[LightGBM] [Warning] lambda_l2 is set=0.01166637692857167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01166637692857167
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.2124849666134824e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2124849666134824e-05
[LightGBM] [Warning] lambda_l2 is set=0.01166637692857167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01166637692857167
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:25,148] Trial 64 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 149, &#39;num_leaves&#39;: 15, &#39;max_depth&#39;: 30, &#39;learning_rate&#39;: 0.005619067642867699, &#39;subsample&#39;: 0.9151994737382102, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 1.1886141282383509e-05, &#39;lambda_l2&#39;: 0.0006894283377813407}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:25,277] Trial 65 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 136, &#39;num_leaves&#39;: 12, &#39;max_depth&#39;: 4, &#39;learning_rate&#39;: 0.01274341795675369, &#39;subsample&#39;: 0.943690454005105, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 3.051185541970629e-06, &#39;lambda_l2&#39;: 0.0003679435586667198}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.1886141282383509e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1886141282383509e-05
[LightGBM] [Warning] lambda_l2 is set=0.0006894283377813407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006894283377813407
[LightGBM] [Warning] lambda_l1 is set=1.1886141282383509e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1886141282383509e-05
[LightGBM] [Warning] lambda_l2 is set=0.0006894283377813407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006894283377813407
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.1886141282383509e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1886141282383509e-05
[LightGBM] [Warning] lambda_l2 is set=0.0006894283377813407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006894283377813407
[LightGBM] [Warning] lambda_l1 is set=3.051185541970629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.051185541970629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0003679435586667198, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003679435586667198
[LightGBM] [Warning] lambda_l1 is set=3.051185541970629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.051185541970629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0003679435586667198, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003679435586667198
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.051185541970629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.051185541970629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0003679435586667198, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003679435586667198
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:25,383] Trial 66 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 98, &#39;num_leaves&#39;: 6, &#39;max_depth&#39;: 34, &#39;learning_rate&#39;: 0.008311507549241816, &#39;subsample&#39;: 0.8971784823291481, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 3.118640587818236e-05, &#39;lambda_l2&#39;: 0.001498657766530597}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:25,480] Trial 67 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 116, &#39;num_leaves&#39;: 22, &#39;max_depth&#39;: 43, &#39;learning_rate&#39;: 0.01684301401229917, &#39;subsample&#39;: 0.9700313238310406, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 8.236987490837292e-05, &#39;lambda_l2&#39;: 0.006513588443390821}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=3.118640587818236e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.118640587818236e-05
[LightGBM] [Warning] lambda_l2 is set=0.001498657766530597, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001498657766530597
[LightGBM] [Warning] lambda_l1 is set=3.118640587818236e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.118640587818236e-05
[LightGBM] [Warning] lambda_l2 is set=0.001498657766530597, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001498657766530597
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] lambda_l1 is set=3.118640587818236e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.118640587818236e-05
[LightGBM] [Warning] lambda_l2 is set=0.001498657766530597, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001498657766530597
[LightGBM] [Warning] lambda_l1 is set=8.236987490837292e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.236987490837292e-05
[LightGBM] [Warning] lambda_l2 is set=0.006513588443390821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006513588443390821
[LightGBM] [Warning] lambda_l1 is set=8.236987490837292e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.236987490837292e-05
[LightGBM] [Warning] lambda_l2 is set=0.006513588443390821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006513588443390821
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=8.236987490837292e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.236987490837292e-05
[LightGBM] [Warning] lambda_l2 is set=0.006513588443390821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006513588443390821
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:25,601] Trial 68 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 109, &#39;num_leaves&#39;: 18, &#39;max_depth&#39;: 39, &#39;learning_rate&#39;: 0.006456276596770102, &#39;subsample&#39;: 0.8826285619497524, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 1.3286388381700297e-06, &#39;lambda_l2&#39;: 0.0018365529197301102}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.3286388381700297e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3286388381700297e-06
[LightGBM] [Warning] lambda_l2 is set=0.0018365529197301102, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0018365529197301102
[LightGBM] [Warning] lambda_l1 is set=1.3286388381700297e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3286388381700297e-06
[LightGBM] [Warning] lambda_l2 is set=0.0018365529197301102, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0018365529197301102
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.3286388381700297e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3286388381700297e-06
[LightGBM] [Warning] lambda_l2 is set=0.0018365529197301102, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0018365529197301102
[LightGBM] [Warning] lambda_l1 is set=4.491030045813413e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.491030045813413e-06
[LightGBM] [Warning] lambda_l2 is set=0.000891987114365967, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000891987114365967
[LightGBM] [Warning] lambda_l1 is set=4.491030045813413e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.491030045813413e-06
[LightGBM] [Warning] lambda_l2 is set=0.000891987114365967, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000891987114365967
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:25,754] Trial 69 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 126, &#39;num_leaves&#39;: 24, &#39;max_depth&#39;: 45, &#39;learning_rate&#39;: 0.010537490165201616, &#39;subsample&#39;: 0.868656308719646, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 4.491030045813413e-06, &#39;lambda_l2&#39;: 0.000891987114365967}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:25,836] Trial 70 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 87, &#39;num_leaves&#39;: 3, &#39;max_depth&#39;: 13, &#39;learning_rate&#39;: 0.012870696612213703, &#39;subsample&#39;: 0.927959972997101, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 9.417279923712775e-06, &#39;lambda_l2&#39;: 0.003026643404615558}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.491030045813413e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.491030045813413e-06
[LightGBM] [Warning] lambda_l2 is set=0.000891987114365967, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000891987114365967
[LightGBM] [Warning] lambda_l1 is set=9.417279923712775e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.417279923712775e-06
[LightGBM] [Warning] lambda_l2 is set=0.003026643404615558, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003026643404615558
[LightGBM] [Warning] lambda_l1 is set=9.417279923712775e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.417279923712775e-06
[LightGBM] [Warning] lambda_l2 is set=0.003026643404615558, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003026643404615558
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] lambda_l1 is set=9.417279923712775e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.417279923712775e-06
[LightGBM] [Warning] lambda_l2 is set=0.003026643404615558, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003026643404615558
[LightGBM] [Warning] lambda_l1 is set=6.754949993515433e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.754949993515433e-06
[LightGBM] [Warning] lambda_l2 is set=0.0032213201086072245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0032213201086072245
[LightGBM] [Warning] lambda_l1 is set=6.754949993515433e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.754949993515433e-06
[LightGBM] [Warning] lambda_l2 is set=0.0032213201086072245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0032213201086072245
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=6.754949993515433e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.754949993515433e-06
[LightGBM] [Warning] lambda_l2 is set=0.0032213201086072245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0032213201086072245
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:25,947] Trial 71 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 119, &#39;num_leaves&#39;: 16, &#39;max_depth&#39;: 36, &#39;learning_rate&#39;: 0.008981670495975298, &#39;subsample&#39;: 0.9554401161132904, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 6.754949993515433e-06, &#39;lambda_l2&#39;: 0.0032213201086072245}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:26,080] Trial 72 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 121, &#39;num_leaves&#39;: 8, &#39;max_depth&#39;: 37, &#39;learning_rate&#39;: 0.009331847628554558, &#39;subsample&#39;: 0.9484938898292653, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 3.2323583713785145e-06, &#39;lambda_l2&#39;: 0.004833080592826379}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=3.2323583713785145e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2323583713785145e-06
[LightGBM] [Warning] lambda_l2 is set=0.004833080592826379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004833080592826379
[LightGBM] [Warning] lambda_l1 is set=3.2323583713785145e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2323583713785145e-06
[LightGBM] [Warning] lambda_l2 is set=0.004833080592826379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004833080592826379
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] lambda_l1 is set=3.2323583713785145e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2323583713785145e-06
[LightGBM] [Warning] lambda_l2 is set=0.004833080592826379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004833080592826379
[LightGBM] [Warning] lambda_l1 is set=1.5152974252209142e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5152974252209142e-05
[LightGBM] [Warning] lambda_l2 is set=0.008411048216709413, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008411048216709413
[LightGBM] [Warning] lambda_l1 is set=1.5152974252209142e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5152974252209142e-05
[LightGBM] [Warning] lambda_l2 is set=0.008411048216709413, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008411048216709413
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:26,234] Trial 73 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 129, &#39;num_leaves&#39;: 15, &#39;max_depth&#39;: 32, &#39;learning_rate&#39;: 0.007201885520448547, &#39;subsample&#39;: 0.9105165398390079, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 1.5152974252209142e-05, &#39;lambda_l2&#39;: 0.008411048216709413}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:26,357] Trial 74 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 146, &#39;num_leaves&#39;: 19, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.004945021096431585, &#39;subsample&#39;: 0.9835897115269432, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 5.415954469347474e-06, &#39;lambda_l2&#39;: 0.001895810776345767}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.5152974252209142e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5152974252209142e-05
[LightGBM] [Warning] lambda_l2 is set=0.008411048216709413, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008411048216709413
[LightGBM] [Warning] lambda_l1 is set=5.415954469347474e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.415954469347474e-06
[LightGBM] [Warning] lambda_l2 is set=0.001895810776345767, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001895810776345767
[LightGBM] [Warning] lambda_l1 is set=5.415954469347474e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.415954469347474e-06
[LightGBM] [Warning] lambda_l2 is set=0.001895810776345767, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001895810776345767
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.415954469347474e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.415954469347474e-06
[LightGBM] [Warning] lambda_l2 is set=0.001895810776345767, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001895810776345767
[LightGBM] [Warning] lambda_l1 is set=5.558659245197923e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.558659245197923e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010702512595880493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010702512595880493
[LightGBM] [Warning] lambda_l1 is set=5.558659245197923e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.558659245197923e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010702512595880493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010702512595880493
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:26,436] Trial 75 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 20, &#39;num_leaves&#39;: 12, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.0055951519354886575, &#39;subsample&#39;: 0.9974009556721439, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 5.558659245197923e-06, &#39;lambda_l2&#39;: 0.0010702512595880493}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:26,573] Trial 76 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 144, &#39;num_leaves&#39;: 14, &#39;max_depth&#39;: 39, &#39;learning_rate&#39;: 0.004925842264390975, &#39;subsample&#39;: 0.9642212718042485, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 2.618066486083574e-06, &#39;lambda_l2&#39;: 0.000523557062827909}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=5.558659245197923e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.558659245197923e-06
[LightGBM] [Warning] lambda_l2 is set=0.0010702512595880493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010702512595880493
[LightGBM] [Warning] lambda_l1 is set=2.618066486083574e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.618066486083574e-06
[LightGBM] [Warning] lambda_l2 is set=0.000523557062827909, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000523557062827909
[LightGBM] [Warning] lambda_l1 is set=2.618066486083574e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.618066486083574e-06
[LightGBM] [Warning] lambda_l2 is set=0.000523557062827909, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000523557062827909
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.618066486083574e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.618066486083574e-06
[LightGBM] [Warning] lambda_l2 is set=0.000523557062827909, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000523557062827909
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:26,733] Trial 77 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 146, &#39;num_leaves&#39;: 16, &#39;max_depth&#39;: 32, &#39;learning_rate&#39;: 0.00514347814845432, &#39;subsample&#39;: 0.9867131199780864, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 2.6003229961074185e-06, &#39;lambda_l2&#39;: 0.0018182169820895656}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.6003229961074185e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6003229961074185e-06
[LightGBM] [Warning] lambda_l2 is set=0.0018182169820895656, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0018182169820895656
[LightGBM] [Warning] lambda_l1 is set=2.6003229961074185e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6003229961074185e-06
[LightGBM] [Warning] lambda_l2 is set=0.0018182169820895656, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0018182169820895656
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.6003229961074185e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6003229961074185e-06
[LightGBM] [Warning] lambda_l2 is set=0.0018182169820895656, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0018182169820895656
[LightGBM] [Warning] lambda_l1 is set=1.2467680355744796e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2467680355744796e-06
[LightGBM] [Warning] lambda_l2 is set=0.000504611436882802, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000504611436882802
[LightGBM] [Warning] lambda_l1 is set=1.2467680355744796e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2467680355744796e-06
[LightGBM] [Warning] lambda_l2 is set=0.000504611436882802, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000504611436882802
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:26,865] Trial 78 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 136, &#39;num_leaves&#39;: 14, &#39;max_depth&#39;: 39, &#39;learning_rate&#39;: 0.004099333426446498, &#39;subsample&#39;: 0.9606602846691438, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 1.2467680355744796e-06, &#39;lambda_l2&#39;: 0.000504611436882802}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.2467680355744796e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2467680355744796e-06
[LightGBM] [Warning] lambda_l2 is set=0.000504611436882802, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000504611436882802
[LightGBM] [Warning] lambda_l1 is set=1.5265562042694504e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5265562042694504e-06
[LightGBM] [Warning] lambda_l2 is set=0.0030608211610466288, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0030608211610466288
[LightGBM] [Warning] lambda_l1 is set=1.5265562042694504e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5265562042694504e-06
[LightGBM] [Warning] lambda_l2 is set=0.0030608211610466288, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0030608211610466288
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.5265562042694504e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5265562042694504e-06
[LightGBM] [Warning] lambda_l2 is set=0.0030608211610466288, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0030608211610466288
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:27,042] Trial 79 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 159, &#39;num_leaves&#39;: 19, &#39;max_depth&#39;: 27, &#39;learning_rate&#39;: 0.0066793520012611894, &#39;subsample&#39;: 0.9811964659446226, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 1.5265562042694504e-06, &#39;lambda_l2&#39;: 0.0030608211610466288}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:27,200] Trial 80 finished with value: 0.85 and parameters: {&#39;n_estimators&#39;: 153, &#39;num_leaves&#39;: 11, &#39;max_depth&#39;: 34, &#39;learning_rate&#39;: 0.00463336418574669, &#39;subsample&#39;: 0.9694640133850683, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 2.472135884073951e-06, &#39;lambda_l2&#39;: 0.0005824703864408477}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.472135884073951e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.472135884073951e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005824703864408477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005824703864408477
[LightGBM] [Warning] lambda_l1 is set=2.472135884073951e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.472135884073951e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005824703864408477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005824703864408477
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.472135884073951e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.472135884073951e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005824703864408477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005824703864408477
[LightGBM] [Warning] lambda_l1 is set=4.048487420629378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.048487420629378e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002854725785754581, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002854725785754581
[LightGBM] [Warning] lambda_l1 is set=4.048487420629378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.048487420629378e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002854725785754581, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002854725785754581
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:27,347] Trial 81 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 114, &#39;num_leaves&#39;: 20, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.008567601277555834, &#39;subsample&#39;: 0.9403856272380655, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 4.048487420629378e-06, &#39;lambda_l2&#39;: 0.0002854725785754581}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:27,482] Trial 82 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 143, &#39;num_leaves&#39;: 22, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.007841136629803236, &#39;subsample&#39;: 0.9399688622927305, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 3.8195969134172086e-06, &#39;lambda_l2&#39;: 0.0003868272525850513}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=4.048487420629378e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.048487420629378e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002854725785754581, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002854725785754581
[LightGBM] [Warning] lambda_l1 is set=3.8195969134172086e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8195969134172086e-06
[LightGBM] [Warning] lambda_l2 is set=0.0003868272525850513, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003868272525850513
[LightGBM] [Warning] lambda_l1 is set=3.8195969134172086e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8195969134172086e-06
[LightGBM] [Warning] lambda_l2 is set=0.0003868272525850513, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003868272525850513
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.8195969134172086e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8195969134172086e-06
[LightGBM] [Warning] lambda_l2 is set=0.0003868272525850513, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003868272525850513
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:27,610] Trial 83 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 116, &#39;num_leaves&#39;: 17, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.005833056167425802, &#39;subsample&#39;: 0.9526875203001611, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 1.0376966406326448e-06, &#39;lambda_l2&#39;: 0.00017803007802528583}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.0376966406326448e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0376966406326448e-06
[LightGBM] [Warning] lambda_l2 is set=0.00017803007802528583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017803007802528583
[LightGBM] [Warning] lambda_l1 is set=1.0376966406326448e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0376966406326448e-06
[LightGBM] [Warning] lambda_l2 is set=0.00017803007802528583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017803007802528583
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.0376966406326448e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0376966406326448e-06
[LightGBM] [Warning] lambda_l2 is set=0.00017803007802528583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017803007802528583
[LightGBM] [Warning] lambda_l1 is set=1.7776309613713254e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7776309613713254e-06
[LightGBM] [Warning] lambda_l2 is set=0.0008735159268082336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008735159268082336
[LightGBM] [Warning] lambda_l1 is set=1.7776309613713254e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7776309613713254e-06
[LightGBM] [Warning] lambda_l2 is set=0.0008735159268082336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008735159268082336
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.7776309613713254e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7776309613713254e-06
[LightGBM] [Warning] lambda_l2 is set=0.0008735159268082336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008735159268082336
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:27,777] Trial 84 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 104, &#39;num_leaves&#39;: 20, &#39;max_depth&#39;: 43, &#39;learning_rate&#39;: 0.008175753568860833, &#39;subsample&#39;: 0.9647061737557823, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 1.7776309613713254e-06, &#39;lambda_l2&#39;: 0.0008735159268082336}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:27,922] Trial 85 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 119, &#39;num_leaves&#39;: 13, &#39;max_depth&#39;: 36, &#39;learning_rate&#39;: 0.01045445189206744, &#39;subsample&#39;: 0.9755497098903094, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 8.942872875902887e-06, &#39;lambda_l2&#39;: 0.00032339671815938574}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=8.942872875902887e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.942872875902887e-06
[LightGBM] [Warning] lambda_l2 is set=0.00032339671815938574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00032339671815938574
[LightGBM] [Warning] lambda_l1 is set=8.942872875902887e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.942872875902887e-06
[LightGBM] [Warning] lambda_l2 is set=0.00032339671815938574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00032339671815938574
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=8.942872875902887e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.942872875902887e-06
[LightGBM] [Warning] lambda_l2 is set=0.00032339671815938574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00032339671815938574
[LightGBM] [Warning] lambda_l1 is set=4.580914342559408e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.580914342559408e-06
[LightGBM] [Warning] lambda_l2 is set=0.0021111209353061717, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021111209353061717
[LightGBM] [Warning] lambda_l1 is set=4.580914342559408e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.580914342559408e-06
[LightGBM] [Warning] lambda_l2 is set=0.0021111209353061717, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021111209353061717
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=4.580914342559408e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.580914342559408e-06
[LightGBM] [Warning] lambda_l2 is set=0.0021111209353061717, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021111209353061717
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:28,056] Trial 86 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 112, &#39;num_leaves&#39;: 14, &#39;max_depth&#39;: 45, &#39;learning_rate&#39;: 0.006699417440007089, &#39;subsample&#39;: 0.988792224788883, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 4.580914342559408e-06, &#39;lambda_l2&#39;: 0.0021111209353061717}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:28,240] Trial 87 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 138, &#39;num_leaves&#39;: 17, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.004953991466599352, &#39;subsample&#39;: 0.9564507423022808, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 6.838549631420261e-06, &#39;lambda_l2&#39;: 0.0002598544242091005}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=6.838549631420261e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.838549631420261e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002598544242091005, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002598544242091005
[LightGBM] [Warning] lambda_l1 is set=6.838549631420261e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.838549631420261e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002598544242091005, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002598544242091005
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=6.838549631420261e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.838549631420261e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002598544242091005, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002598544242091005
[LightGBM] [Warning] lambda_l1 is set=7.698971744900687e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.698971744900687e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002643892154861382, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002643892154861382
[LightGBM] [Warning] lambda_l1 is set=7.698971744900687e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.698971744900687e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002643892154861382, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002643892154861382
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:28,409] Trial 88 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 163, &#39;num_leaves&#39;: 9, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.005219352053431537, &#39;subsample&#39;: 0.954023795991757, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 7.698971744900687e-06, &#39;lambda_l2&#39;: 0.0002643892154861382}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:28,549] Trial 89 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 137, &#39;num_leaves&#39;: 16, &#39;max_depth&#39;: 39, &#39;learning_rate&#39;: 0.004652610874274893, &#39;subsample&#39;: 0.9991195902081317, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 2.254441963936314e-06, &#39;lambda_l2&#39;: 0.0001334219206998721}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.698971744900687e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.698971744900687e-06
[LightGBM] [Warning] lambda_l2 is set=0.0002643892154861382, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002643892154861382
[LightGBM] [Warning] lambda_l1 is set=2.254441963936314e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.254441963936314e-06
[LightGBM] [Warning] lambda_l2 is set=0.0001334219206998721, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001334219206998721
[LightGBM] [Warning] lambda_l1 is set=2.254441963936314e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.254441963936314e-06
[LightGBM] [Warning] lambda_l2 is set=0.0001334219206998721, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001334219206998721
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.254441963936314e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.254441963936314e-06
[LightGBM] [Warning] lambda_l2 is set=0.0001334219206998721, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001334219206998721
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:28,732] Trial 90 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 147, &#39;num_leaves&#39;: 15, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.003678929312998043, &#39;subsample&#39;: 0.9404288149770064, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 1.1613776597514722e-05, &#39;lambda_l2&#39;: 0.0012877018561166167}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.1613776597514722e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1613776597514722e-05
[LightGBM] [Warning] lambda_l2 is set=0.0012877018561166167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012877018561166167
[LightGBM] [Warning] lambda_l1 is set=1.1613776597514722e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1613776597514722e-05
[LightGBM] [Warning] lambda_l2 is set=0.0012877018561166167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012877018561166167
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.1613776597514722e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1613776597514722e-05
[LightGBM] [Warning] lambda_l2 is set=0.0012877018561166167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012877018561166167
[LightGBM] [Warning] lambda_l1 is set=3.9275830827841955e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9275830827841955e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005083262181797175, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005083262181797175
[LightGBM] [Warning] lambda_l1 is set=3.9275830827841955e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9275830827841955e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005083262181797175, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005083262181797175
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:28,899] Trial 91 finished with value: 0.925 and parameters: {&#39;n_estimators&#39;: 127, &#39;num_leaves&#39;: 19, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.006284996417060143, &#39;subsample&#39;: 0.9646954614624341, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 3.9275830827841955e-06, &#39;lambda_l2&#39;: 0.0005083262181797175}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.9275830827841955e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9275830827841955e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005083262181797175, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005083262181797175
[LightGBM] [Warning] lambda_l1 is set=5.9932339982061834e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.9932339982061834e-06
[LightGBM] [Warning] lambda_l2 is set=0.0004437257389959865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004437257389959865
[LightGBM] [Warning] lambda_l1 is set=5.9932339982061834e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.9932339982061834e-06
[LightGBM] [Warning] lambda_l2 is set=0.0004437257389959865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004437257389959865
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:29,079] Trial 92 finished with value: 0.9125 and parameters: {&#39;n_estimators&#39;: 152, &#39;num_leaves&#39;: 19, &#39;max_depth&#39;: 37, &#39;learning_rate&#39;: 0.005962535521271888, &#39;subsample&#39;: 0.965281394883039, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 5.9932339982061834e-06, &#39;lambda_l2&#39;: 0.0004437257389959865}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.9932339982061834e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.9932339982061834e-06
[LightGBM] [Warning] lambda_l2 is set=0.0004437257389959865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004437257389959865
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:29,425] Trial 93 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 128, &#39;num_leaves&#39;: 18, &#39;max_depth&#39;: 32, &#39;learning_rate&#39;: 0.009037571318474706, &#39;subsample&#39;: 0.9819404977824976, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 3.686674482784999e-06, &#39;lambda_l2&#39;: 0.00017631868662854494}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=3.686674482784999e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.686674482784999e-06
[LightGBM] [Warning] lambda_l2 is set=0.00017631868662854494, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017631868662854494
[LightGBM] [Warning] lambda_l1 is set=3.686674482784999e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.686674482784999e-06
[LightGBM] [Warning] lambda_l2 is set=0.00017631868662854494, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017631868662854494
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.686674482784999e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.686674482784999e-06
[LightGBM] [Warning] lambda_l2 is set=0.00017631868662854494, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017631868662854494
[LightGBM] [Warning] lambda_l1 is set=1.80933052330781e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.80933052330781e-05
[LightGBM] [Warning] lambda_l2 is set=0.0007794943345690912, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007794943345690912
[LightGBM] [Warning] lambda_l1 is set=1.80933052330781e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.80933052330781e-05
[LightGBM] [Warning] lambda_l2 is set=0.0007794943345690912, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007794943345690912
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:29,595] Trial 94 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 142, &#39;num_leaves&#39;: 15, &#39;max_depth&#39;: 30, &#39;learning_rate&#39;: 0.00770072243365956, &#39;subsample&#39;: 0.9495282019675462, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 1.80933052330781e-05, &#39;lambda_l2&#39;: 0.0007794943345690912}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.80933052330781e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.80933052330781e-05
[LightGBM] [Warning] lambda_l2 is set=0.0007794943345690912, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007794943345690912
[LightGBM] [Warning] lambda_l1 is set=1.624404157387591e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.624404157387591e-06
[LightGBM] [Warning] lambda_l2 is set=0.0042489096863963585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0042489096863963585
[LightGBM] [Warning] lambda_l1 is set=1.624404157387591e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.624404157387591e-06
[LightGBM] [Warning] lambda_l2 is set=0.0042489096863963585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0042489096863963585
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:17:29,766] Trial 95 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 125, &#39;num_leaves&#39;: 20, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.007262564329443067, &#39;subsample&#39;: 0.974560155853786, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 1.624404157387591e-06, &#39;lambda_l2&#39;: 0.0042489096863963585}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.624404157387591e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.624404157387591e-06
[LightGBM] [Warning] lambda_l2 is set=0.0042489096863963585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0042489096863963585
[LightGBM] [Warning] lambda_l1 is set=2.453456384381318e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.453456384381318e-06
[LightGBM] [Warning] lambda_l2 is set=0.00031233586526010186, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00031233586526010186
[LightGBM] [Warning] lambda_l1 is set=2.453456384381318e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.453456384381318e-06
[LightGBM] [Warning] lambda_l2 is set=0.00031233586526010186, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00031233586526010186
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:29,966] Trial 96 finished with value: 0.875 and parameters: {&#39;n_estimators&#39;: 132, &#39;num_leaves&#39;: 17, &#39;max_depth&#39;: 37, &#39;learning_rate&#39;: 0.011506254178151053, &#39;subsample&#39;: 0.9598782317507987, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 2.453456384381318e-06, &#39;lambda_l2&#39;: 0.00031233586526010186}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:30,145] Trial 97 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 171, &#39;num_leaves&#39;: 13, &#39;max_depth&#39;: 39, &#39;learning_rate&#39;: 0.004135150281133584, &#39;subsample&#39;: 0.9317604559045105, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 5.016690140760783e-06, &#39;lambda_l2&#39;: 0.0026672642544824875}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.453456384381318e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.453456384381318e-06
[LightGBM] [Warning] lambda_l2 is set=0.00031233586526010186, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00031233586526010186
[LightGBM] [Warning] lambda_l1 is set=5.016690140760783e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.016690140760783e-06
[LightGBM] [Warning] lambda_l2 is set=0.0026672642544824875, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0026672642544824875
[LightGBM] [Warning] lambda_l1 is set=5.016690140760783e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.016690140760783e-06
[LightGBM] [Warning] lambda_l2 is set=0.0026672642544824875, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0026672642544824875
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.016690140760783e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.016690140760783e-06
[LightGBM] [Warning] lambda_l2 is set=0.0026672642544824875, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0026672642544824875
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:30,315] Trial 98 finished with value: 0.9 and parameters: {&#39;n_estimators&#39;: 97, &#39;num_leaves&#39;: 11, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.009712711561787971, &#39;subsample&#39;: 0.9889087827845482, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 7.491964894785809e-06, &#39;lambda_l2&#39;: 0.0005758872387049087}. Best is trial 31 with value: 0.925.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.491964894785809e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.491964894785809e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005758872387049087, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005758872387049087
[LightGBM] [Warning] lambda_l1 is set=7.491964894785809e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.491964894785809e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005758872387049087, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005758872387049087
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.491964894785809e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.491964894785809e-06
[LightGBM] [Warning] lambda_l2 is set=0.0005758872387049087, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005758872387049087
[LightGBM] [Warning] lambda_l1 is set=1.3725919276627476e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3725919276627476e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015107890737038193, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015107890737038193
[LightGBM] [Warning] lambda_l1 is set=1.3725919276627476e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3725919276627476e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015107890737038193, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015107890737038193
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\1949815063.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
[I 2023-10-18 03:17:30,496] Trial 99 finished with value: 0.8875 and parameters: {&#39;n_estimators&#39;: 119, &#39;num_leaves&#39;: 17, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.006296241142144173, &#39;subsample&#39;: 0.9441557607650782, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 1.3725919276627476e-05, &#39;lambda_l2&#39;: 0.0015107890737038193}. Best is trial 31 with value: 0.925.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=1.3725919276627476e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3725919276627476e-05
[LightGBM] [Warning] lambda_l2 is set=0.0015107890737038193, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015107890737038193

Melhores hiperparâmetros: {&#39;n_estimators&#39;: 140, &#39;num_leaves&#39;: 29, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.007551211447829674, &#39;subsample&#39;: 0.8750804543836551, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 2.013838835210629e-06, &#39;lambda_l2&#39;: 0.0007771472931457983}

Melhor Recall: 0.925
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Treinando-o-modelo">Treinando o modelo<a class="anchor-link" href="#Treinando-o-modelo">&#182;</a></h2><ul>
<li>Utilizando os melhores parâmetros obtidos</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Criando o modelo com os melhores parâmetros encontrados</span>
<span class="n">modelo_under</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">melhores_hiperparametros_under</span><span class="p">)</span>

<span class="c1"># Treinando o modelo com os dados de Undersampling</span>
<span class="n">modelo_under</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_undersampled</span><span class="p">,</span> <span class="n">y_train_undersampled</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.013838835210629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.013838835210629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0007771472931457983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007771472931457983
[LightGBM] [Warning] lambda_l1 is set=2.013838835210629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.013838835210629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0007771472931457983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007771472931457983
[LightGBM] [Info] Number of positive: 303, number of negative: 309
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 6127
[LightGBM] [Info] Number of data points in the train set: 612, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495098 -&gt; initscore=-0.019608
[LightGBM] [Info] Start training from score -0.019608
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[33]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LGBMClassifier(lambda_l1=2.013838835210629e-06, lambda_l2=0.0007771472931457983,
               learning_rate=0.007551211447829674, max_depth=41,
               min_child_weight=5, n_estimators=140, num_leaves=29,
               subsample=0.8750804543836551)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(lambda_l1=2.013838835210629e-06, lambda_l2=0.0007771472931457983,
               learning_rate=0.007551211447829674, max_depth=41,
               min_child_weight=5, n_estimators=140, num_leaves=29,
               subsample=0.8750804543836551)</pre></div></div></div></div></div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Coletando os resultados da previsão</span>
<span class="n">y_pred_undersampled</span> <span class="o">=</span> <span class="n">modelo_under</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_undersampled</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.013838835210629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.013838835210629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0007771472931457983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007771472931457983
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Resultados-com-Undersampling">Resultados com Undersampling<a class="anchor-link" href="#Resultados-com-Undersampling">&#182;</a></h2><ul>
<li>Com base nas métricas de Acurácia, Precision, Recall e F1-Score e na matriz de confusão, para os dados de Undersampling, pode-se concluir que <strong>o modelo aprendeu a classificar transações corretamente!</strong></li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Coletando as métricas de classificação obtidas</span>
<span class="n">metricas</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_undersampled</span><span class="p">,</span> <span class="n">y_pred_undersampled</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metricas</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.92      0.95      0.93        74
           1       0.95      0.93      0.94        80

    accuracy                           0.94       154
   macro avg       0.93      0.94      0.94       154
weighted avg       0.94      0.94      0.94       154

</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Matriz-de-confus%C3%A3o">Matriz de confus&#227;o<a class="anchor-link" href="#Matriz-de-confus%C3%A3o">&#182;</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_undersampled</span><span class="p">,</span> <span class="n">y_pred_undersampled</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">"d"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"Blues"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Previsão do modelo'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Resultado esperado'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Matriz de confusão para dados Undersampled</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Dados-do-Oversampling">Dados do Oversampling<a class="anchor-link" href="#Dados-do-Oversampling">&#182;</a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Split-nos-dados">Split nos dados<a class="anchor-link" href="#Split-nos-dados">&#182;</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_oversampled</span><span class="p">,</span> <span class="n">X_test_oversampled</span><span class="p">,</span> <span class="n">y_train_oversampled</span><span class="p">,</span> <span class="n">y_test_oversampled</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_oversampled</span><span class="p">,</span> <span class="n">y_oversampled</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Describe de treino:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_train_oversampled</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Describe de teste:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">X_test_oversampled</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Distribuição de fraude na base de treino:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_train_oversampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_train_oversampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Distribuição de fraude na base de teste:'</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_test_oversampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">y_test_oversampled</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()[</span><span class="s1">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Describe de treino:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>...</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
      <td>363939.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-2.404933</td>
      <td>1.878857</td>
      <td>-3.534989</td>
      <td>2.260561</td>
      <td>-1.628606</td>
      <td>-0.731397</td>
      <td>-2.853631</td>
      <td>0.326825</td>
      <td>-1.303156</td>
      <td>-2.892411</td>
      <td>...</td>
      <td>0.450927</td>
      <td>-0.029360</td>
      <td>0.024533</td>
      <td>-0.051693</td>
      <td>0.047915</td>
      <td>0.017700</td>
      <td>0.092641</td>
      <td>0.053988</td>
      <td>0.013025</td>
      <td>0.993551</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.638260</td>
      <td>3.759554</td>
      <td>6.309037</td>
      <td>3.141433</td>
      <td>4.244152</td>
      <td>1.719986</td>
      <td>5.837551</td>
      <td>5.029557</td>
      <td>2.292661</td>
      <td>4.546144</td>
      <td>...</td>
      <td>2.942064</td>
      <td>1.194509</td>
      <td>0.888467</td>
      <td>0.541842</td>
      <td>0.611314</td>
      <td>0.448488</td>
      <td>0.991765</td>
      <td>0.428524</td>
      <td>0.539853</td>
      <td>3.231968</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-56.407510</td>
      <td>-72.715728</td>
      <td>-48.325589</td>
      <td>-5.600607</td>
      <td>-113.743307</td>
      <td>-26.160506</td>
      <td>-43.557242</td>
      <td>-50.943369</td>
      <td>-13.434066</td>
      <td>-24.588262</td>
      <td>...</td>
      <td>-22.889347</td>
      <td>-10.933144</td>
      <td>-36.666000</td>
      <td>-2.836627</td>
      <td>-8.696627</td>
      <td>-2.604551</td>
      <td>-9.793568</td>
      <td>-15.430084</td>
      <td>-0.994197</td>
      <td>-0.307692</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-2.892902</td>
      <td>-0.123841</td>
      <td>-5.073751</td>
      <td>-0.071535</td>
      <td>-1.786741</td>
      <td>-1.558279</td>
      <td>-3.135290</td>
      <td>-0.185293</td>
      <td>-2.306596</td>
      <td>-4.711603</td>
      <td>...</td>
      <td>-0.156564</td>
      <td>-0.524164</td>
      <td>-0.222020</td>
      <td>-0.384057</td>
      <td>-0.290042</td>
      <td>-0.279640</td>
      <td>-0.063064</td>
      <td>-0.049169</td>
      <td>-0.432551</td>
      <td>-0.277677</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-0.736215</td>
      <td>1.001466</td>
      <td>-1.391565</td>
      <td>1.363570</td>
      <td>-0.454020</td>
      <td>-0.693902</td>
      <td>-0.660562</td>
      <td>0.161672</td>
      <td>-0.692027</td>
      <td>-0.882357</td>
      <td>...</td>
      <td>0.167892</td>
      <td>0.015634</td>
      <td>-0.036477</td>
      <td>0.003133</td>
      <td>0.053346</td>
      <td>-0.025029</td>
      <td>0.048589</td>
      <td>0.037574</td>
      <td>-0.084400</td>
      <td>-0.031189</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.018622</td>
      <td>2.807563</td>
      <td>0.332659</td>
      <td>4.214363</td>
      <td>0.454256</td>
      <td>0.012099</td>
      <td>0.265575</td>
      <td>0.861237</td>
      <td>0.150657</td>
      <td>-0.000700</td>
      <td>...</td>
      <td>0.682453</td>
      <td>0.524132</td>
      <td>0.178347</td>
      <td>0.345122</td>
      <td>0.383275</td>
      <td>0.292446</td>
      <td>0.470157</td>
      <td>0.222585</td>
      <td>0.522423</td>
      <td>1.020280</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.446505</td>
      <td>22.057729</td>
      <td>4.226108</td>
      <td>16.875344</td>
      <td>34.801666</td>
      <td>73.301626</td>
      <td>120.589494</td>
      <td>20.007208</td>
      <td>10.392889</td>
      <td>15.331742</td>
      <td>...</td>
      <td>27.202839</td>
      <td>8.361985</td>
      <td>22.528412</td>
      <td>4.584549</td>
      <td>5.826159</td>
      <td>3.517346</td>
      <td>31.612198</td>
      <td>33.847808</td>
      <td>1.035450</td>
      <td>359.009231</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 30 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Describe de teste:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Time_scaled</th>
      <th>Amount_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>...</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
      <td>90985.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-2.396286</td>
      <td>1.880639</td>
      <td>-3.541312</td>
      <td>2.255512</td>
      <td>-1.626985</td>
      <td>-0.737132</td>
      <td>-2.857265</td>
      <td>0.332257</td>
      <td>-1.307436</td>
      <td>-2.896073</td>
      <td>...</td>
      <td>0.448047</td>
      <td>-0.027416</td>
      <td>0.027016</td>
      <td>-0.054872</td>
      <td>0.051053</td>
      <td>0.018402</td>
      <td>0.099151</td>
      <td>0.053531</td>
      <td>0.011876</td>
      <td>0.976990</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.625844</td>
      <td>3.735883</td>
      <td>6.308186</td>
      <td>3.146201</td>
      <td>4.231322</td>
      <td>1.721184</td>
      <td>5.819096</td>
      <td>5.030960</td>
      <td>2.285681</td>
      <td>4.540968</td>
      <td>...</td>
      <td>2.935867</td>
      <td>1.190283</td>
      <td>0.892944</td>
      <td>0.540070</td>
      <td>0.611747</td>
      <td>0.446986</td>
      <td>0.984141</td>
      <td>0.424730</td>
      <td>0.539680</td>
      <td>3.020380</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-37.558067</td>
      <td>-47.429676</td>
      <td>-31.103611</td>
      <td>-5.251492</td>
      <td>-35.182120</td>
      <td>-20.367836</td>
      <td>-43.514876</td>
      <td>-73.216718</td>
      <td>-13.434065</td>
      <td>-24.584438</td>
      <td>...</td>
      <td>-34.830382</td>
      <td>-8.887017</td>
      <td>-19.935025</td>
      <td>-2.732373</td>
      <td>-5.785255</td>
      <td>-1.855355</td>
      <td>-9.895244</td>
      <td>-8.424041</td>
      <td>-0.994150</td>
      <td>-0.307692</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-2.906842</td>
      <td>-0.130423</td>
      <td>-5.076942</td>
      <td>-0.079760</td>
      <td>-1.785555</td>
      <td>-1.559340</td>
      <td>-3.145847</td>
      <td>-0.184426</td>
      <td>-2.317096</td>
      <td>-4.715008</td>
      <td>...</td>
      <td>-0.157734</td>
      <td>-0.519178</td>
      <td>-0.221432</td>
      <td>-0.389817</td>
      <td>-0.287905</td>
      <td>-0.276636</td>
      <td>-0.061239</td>
      <td>-0.048916</td>
      <td>-0.433021</td>
      <td>-0.276788</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-0.733467</td>
      <td>0.998563</td>
      <td>-1.400956</td>
      <td>1.350581</td>
      <td>-0.456095</td>
      <td>-0.704408</td>
      <td>-0.668369</td>
      <td>0.161126</td>
      <td>-0.707695</td>
      <td>-0.884654</td>
      <td>...</td>
      <td>0.167459</td>
      <td>0.015759</td>
      <td>-0.036013</td>
      <td>0.001213</td>
      <td>0.056076</td>
      <td>-0.024212</td>
      <td>0.050230</td>
      <td>0.037435</td>
      <td>-0.084631</td>
      <td>-0.033986</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.026015</td>
      <td>2.808074</td>
      <td>0.336205</td>
      <td>4.208387</td>
      <td>0.442369</td>
      <td>0.007480</td>
      <td>0.259787</td>
      <td>0.865040</td>
      <td>0.150345</td>
      <td>0.000245</td>
      <td>...</td>
      <td>0.677432</td>
      <td>0.523972</td>
      <td>0.177855</td>
      <td>0.340172</td>
      <td>0.385936</td>
      <td>0.292865</td>
      <td>0.471705</td>
      <td>0.221120</td>
      <td>0.522083</td>
      <td>1.017992</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.454930</td>
      <td>22.045528</td>
      <td>4.040465</td>
      <td>12.112906</td>
      <td>29.162172</td>
      <td>21.550496</td>
      <td>36.877368</td>
      <td>20.007151</td>
      <td>10.348407</td>
      <td>13.164571</td>
      <td>...</td>
      <td>27.202839</td>
      <td>10.503090</td>
      <td>22.083545</td>
      <td>3.962197</td>
      <td>7.519589</td>
      <td>3.118588</td>
      <td>6.578849</td>
      <td>22.620072</td>
      <td>1.035380</td>
      <td>109.893986</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 30 columns</p>
</div>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Distribuição de fraude na base de treino:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    181971
1    181968
Name: Class, dtype: int64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>0    0.500004
1    0.499996
Name: Class, dtype: float64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Distribuição de fraude na base de teste:
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>1    45494
0    45491
Name: Class, dtype: int64</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>1    0.500016
0    0.499984
Name: Class, dtype: float64</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Ajuste-de-Hiperpar%C3%A2metros-utilizando-a-biblioteca-Optuna">Ajuste de Hiperpar&#226;metros utilizando a biblioteca Optuna<a class="anchor-link" href="#Ajuste-de-Hiperpar%C3%A2metros-utilizando-a-biblioteca-Optuna">&#182;</a></h3><ul>
<li><p><strong>Optuna</strong> é uma biblioteca que permite criar "estudos" que vão testar uma série de hiperparâmetros para modelos de machine learning, e retornar os que obtiverem os melhores resultados.</p>
</li>
<li><p>Essa biblioteca será útil para encontrar os melhores hiperparâmetros para o classificador.</p>
</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Definindo a função que o Optuna irá utilizar para testar os hiperparâmetros</span>
<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="c1"># Definindo os hiperparâmetros da LightGBM</span>
    <span class="n">parametros</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'n_estimators'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'n_estimators'</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="c1"># Quantidade máxima de nós</span>
        <span class="s1">'num_leaves'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'num_leaves'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="c1"># Quantidade máxima de folhas</span>
        <span class="s1">'max_depth'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'max_depth'</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="c1"># Profundidade máxima das árvores</span>
        <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'learning_rate'</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="c1"># Taxa de aprendizado</span>
        <span class="s1">'subsample'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_uniform</span><span class="p">(</span><span class="s1">'subsample'</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="c1"># Subsample usado para impedir overfitting</span>
        <span class="s1">'min_child_weight'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">'min_child_weight'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="c1"># Quantidade mínima para criar um novo nó</span>
        <span class="s1">'lambda_l1'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'lambda_l1'</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="c1"># Penalização Lasso nas árvores</span>
        <span class="s1">'lambda_l2'</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_loguniform</span><span class="p">(</span><span class="s1">'lambda_l2'</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="c1"># Penalização Ridge nas árvores</span>
    <span class="p">}</span>

    <span class="c1"># Criando o modelo LightGBM com os hiperparâmetros otimizados</span>
    <span class="n">modelo</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">parametros</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>

    <span class="c1"># Treinando o modelo nos dados já balanceados pelo Oversampling</span>
    <span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_oversampled</span><span class="p">,</span> <span class="n">y_train_oversampled</span><span class="p">)</span>

    <span class="c1"># Previsões para a base de testes</span>
    <span class="n">y_pred_oversampled</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_oversampled</span><span class="p">)</span>

    <span class="c1"># Realiza o cálculo da métrica de Recall, que seria a métrica mais segura dadas as condições originais dos dados</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_oversampled</span><span class="p">,</span> <span class="n">y_pred_oversampled</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">recall</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Criando a instância do estudo</span>
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">'maximize'</span><span class="p">)</span> <span class="c1"># Maximizar a Recall</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Selecionando os melhores parâmetros com base na Recall</span>
<span class="n">melhores_hiperparametros_over</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_params</span>
<span class="n">melhor_recall_over</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_value</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Melhores hiperparâmetros: </span><span class="si">{</span><span class="n">melhores_hiperparametros_over</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Melhor Recall: </span><span class="si">{</span><span class="n">melhor_recall_over</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:34,791] A new study created in memory with name: no-name-de52c451-fb52-40d9-8938-483b7b6d6ceb
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.7965438831410411, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7965438831410411
[LightGBM] [Warning] lambda_l2 is set=0.0031005537941302275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0031005537941302275
[LightGBM] [Warning] lambda_l1 is set=0.7965438831410411, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7965438831410411
[LightGBM] [Warning] lambda_l2 is set=0.0031005537941302275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0031005537941302275
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038814 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:35,816] Trial 0 finished with value: 0.9502132149294412 and parameters: {&#39;n_estimators&#39;: 29, &#39;num_leaves&#39;: 20, &#39;max_depth&#39;: 49, &#39;learning_rate&#39;: 0.0031069368503198113, &#39;subsample&#39;: 0.8912190657040824, &#39;min_child_weight&#39;: 14, &#39;lambda_l1&#39;: 0.7965438831410411, &#39;lambda_l2&#39;: 0.0031005537941302275}. Best is trial 0 with value: 0.9502132149294412.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.7965438831410411, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7965438831410411
[LightGBM] [Warning] lambda_l2 is set=0.0031005537941302275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0031005537941302275
[LightGBM] [Warning] lambda_l1 is set=4.5660037962733195e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5660037962733195e-06
[LightGBM] [Warning] lambda_l2 is set=3.547214288217545e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.547214288217545e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.5660037962733195e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5660037962733195e-06
[LightGBM] [Warning] lambda_l2 is set=3.547214288217545e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.547214288217545e-05
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036314 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:36,999] Trial 1 finished with value: 0.8655866707697718 and parameters: {&#39;n_estimators&#39;: 101, &#39;num_leaves&#39;: 2, &#39;max_depth&#39;: 10, &#39;learning_rate&#39;: 0.002164189570323491, &#39;subsample&#39;: 0.6996185144251545, &#39;min_child_weight&#39;: 19, &#39;lambda_l1&#39;: 4.5660037962733195e-06, &#39;lambda_l2&#39;: 3.547214288217545e-05}. Best is trial 0 with value: 0.9502132149294412.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.5660037962733195e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5660037962733195e-06
[LightGBM] [Warning] lambda_l2 is set=3.547214288217545e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.547214288217545e-05
[LightGBM] [Warning] lambda_l1 is set=0.004264695670010312, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004264695670010312
[LightGBM] [Warning] lambda_l2 is set=0.0007470454926863893, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007470454926863893
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.004264695670010312, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004264695670010312
[LightGBM] [Warning] lambda_l2 is set=0.0007470454926863893, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007470454926863893
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028631 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:39,533] Trial 2 finished with value: 0.9688969974062513 and parameters: {&#39;n_estimators&#39;: 115, &#39;num_leaves&#39;: 25, &#39;max_depth&#39;: 47, &#39;learning_rate&#39;: 0.011802573816000798, &#39;subsample&#39;: 0.663508866132689, &#39;min_child_weight&#39;: 19, &#39;lambda_l1&#39;: 0.004264695670010312, &#39;lambda_l2&#39;: 0.0007470454926863893}. Best is trial 2 with value: 0.9688969974062513.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.004264695670010312, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004264695670010312
[LightGBM] [Warning] lambda_l2 is set=0.0007470454926863893, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007470454926863893
[LightGBM] [Warning] lambda_l1 is set=0.775693816577622, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.775693816577622
[LightGBM] [Warning] lambda_l2 is set=0.0014583552196960764, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0014583552196960764
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.775693816577622, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.775693816577622
[LightGBM] [Warning] lambda_l2 is set=0.0014583552196960764, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0014583552196960764
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038822 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:41,166] Trial 3 finished with value: 0.977513518266145 and parameters: {&#39;n_estimators&#39;: 55, &#39;num_leaves&#39;: 39, &#39;max_depth&#39;: 25, &#39;learning_rate&#39;: 0.018062261865835882, &#39;subsample&#39;: 0.7569869993185833, &#39;min_child_weight&#39;: 10, &#39;lambda_l1&#39;: 0.775693816577622, &#39;lambda_l2&#39;: 0.0014583552196960764}. Best is trial 3 with value: 0.977513518266145.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.775693816577622, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.775693816577622
[LightGBM] [Warning] lambda_l2 is set=0.0014583552196960764, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0014583552196960764
[LightGBM] [Warning] lambda_l1 is set=0.02103843662665488, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02103843662665488
[LightGBM] [Warning] lambda_l2 is set=0.0002128921159183057, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002128921159183057
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.02103843662665488, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02103843662665488
[LightGBM] [Warning] lambda_l2 is set=0.0002128921159183057, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002128921159183057
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030266 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:43,564] Trial 4 finished with value: 0.9814481030465556 and parameters: {&#39;n_estimators&#39;: 124, &#39;num_leaves&#39;: 14, &#39;max_depth&#39;: 34, &#39;learning_rate&#39;: 0.03623869621466859, &#39;subsample&#39;: 0.7904714153031922, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.02103843662665488, &#39;lambda_l2&#39;: 0.0002128921159183057}. Best is trial 4 with value: 0.9814481030465556.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.02103843662665488, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02103843662665488
[LightGBM] [Warning] lambda_l2 is set=0.0002128921159183057, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002128921159183057
[LightGBM] [Warning] lambda_l1 is set=0.2387221099029869, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2387221099029869
[LightGBM] [Warning] lambda_l2 is set=0.0016877375491044446, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0016877375491044446
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.2387221099029869, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2387221099029869
[LightGBM] [Warning] lambda_l2 is set=0.0016877375491044446, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0016877375491044446
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036706 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:44,521] Trial 5 finished with value: 0.9737987426913439 and parameters: {&#39;n_estimators&#39;: 22, &#39;num_leaves&#39;: 30, &#39;max_depth&#39;: 50, &#39;learning_rate&#39;: 0.05664248258422379, &#39;subsample&#39;: 0.7518078345433366, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 0.2387221099029869, &#39;lambda_l2&#39;: 0.0016877375491044446}. Best is trial 4 with value: 0.9814481030465556.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.2387221099029869, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2387221099029869
[LightGBM] [Warning] lambda_l2 is set=0.0016877375491044446, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0016877375491044446
[LightGBM] [Warning] lambda_l1 is set=0.3828821458483766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3828821458483766
[LightGBM] [Warning] lambda_l2 is set=0.00045100317062221715, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00045100317062221715
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.3828821458483766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3828821458483766
[LightGBM] [Warning] lambda_l2 is set=0.00045100317062221715, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00045100317062221715
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031720 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.3828821458483766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3828821458483766
[LightGBM] [Warning] lambda_l2 is set=0.00045100317062221715, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00045100317062221715
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:48,841] Trial 6 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 181, &#39;num_leaves&#39;: 37, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.04926240577582323, &#39;subsample&#39;: 0.7316863020085818, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.3828821458483766, &#39;lambda_l2&#39;: 0.00045100317062221715}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.1732089639376815e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1732089639376815e-05
[LightGBM] [Warning] lambda_l2 is set=0.0029623849496243676, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0029623849496243676
[LightGBM] [Warning] lambda_l1 is set=1.1732089639376815e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1732089639376815e-05
[LightGBM] [Warning] lambda_l2 is set=0.0029623849496243676, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0029623849496243676
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035579 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:52,309] Trial 7 finished with value: 0.9778871939156812 and parameters: {&#39;n_estimators&#39;: 139, &#39;num_leaves&#39;: 46, &#39;max_depth&#39;: 25, &#39;learning_rate&#39;: 0.003459727901482284, &#39;subsample&#39;: 0.9763333018185998, &#39;min_child_weight&#39;: 17, &#39;lambda_l1&#39;: 1.1732089639376815e-05, &#39;lambda_l2&#39;: 0.0029623849496243676}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.1732089639376815e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1732089639376815e-05
[LightGBM] [Warning] lambda_l2 is set=0.0029623849496243676, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0029623849496243676
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.018509462778876135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.018509462778876135
[LightGBM] [Warning] lambda_l2 is set=9.7341589241452e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.7341589241452e-05
[LightGBM] [Warning] lambda_l1 is set=0.018509462778876135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.018509462778876135
[LightGBM] [Warning] lambda_l2 is set=9.7341589241452e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.7341589241452e-05
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023201 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:54,737] Trial 8 finished with value: 0.9429155493032049 and parameters: {&#39;n_estimators&#39;: 128, &#39;num_leaves&#39;: 15, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.0016036479890505818, &#39;subsample&#39;: 0.80622934719068, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.018509462778876135, &#39;lambda_l2&#39;: 9.7341589241452e-05}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.018509462778876135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.018509462778876135
[LightGBM] [Warning] lambda_l2 is set=9.7341589241452e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.7341589241452e-05
[LightGBM] [Warning] lambda_l1 is set=0.013332380392938417, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.013332380392938417
[LightGBM] [Warning] lambda_l2 is set=0.0017921342102144807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017921342102144807
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.013332380392938417, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.013332380392938417
[LightGBM] [Warning] lambda_l2 is set=0.0017921342102144807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017921342102144807
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032567 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:20:55,762] Trial 9 finished with value: 0.9382775750648437 and parameters: {&#39;n_estimators&#39;: 35, &#39;num_leaves&#39;: 10, &#39;max_depth&#39;: 33, &#39;learning_rate&#39;: 0.0137621678699859, &#39;subsample&#39;: 0.8921191926183345, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 0.013332380392938417, &#39;lambda_l2&#39;: 0.0017921342102144807}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.013332380392938417, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.013332380392938417
[LightGBM] [Warning] lambda_l2 is set=0.0017921342102144807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017921342102144807
[LightGBM] [Warning] lambda_l1 is set=0.0001865433238139677, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001865433238139677
[LightGBM] [Warning] lambda_l2 is set=0.12687233592239772, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12687233592239772
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0001865433238139677, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001865433238139677
[LightGBM] [Warning] lambda_l2 is set=0.12687233592239772, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12687233592239772
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037108 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0001865433238139677, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001865433238139677
[LightGBM] [Warning] lambda_l2 is set=0.12687233592239772, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12687233592239772
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:00,613] Trial 10 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 189, &#39;num_leaves&#39;: 36, &#39;max_depth&#39;: 15, &#39;learning_rate&#39;: 0.16384374550816524, &#39;subsample&#39;: 0.6111757933500629, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.0001865433238139677, &#39;lambda_l2&#39;: 0.12687233592239772}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0002076835508378969, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002076835508378969
[LightGBM] [Warning] lambda_l2 is set=0.20540546614255564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20540546614255564
[LightGBM] [Warning] lambda_l1 is set=0.0002076835508378969, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002076835508378969
[LightGBM] [Warning] lambda_l2 is set=0.20540546614255564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20540546614255564
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035948 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0002076835508378969, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002076835508378969
[LightGBM] [Warning] lambda_l2 is set=0.20540546614255564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20540546614255564
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:05,717] Trial 11 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 198, &#39;num_leaves&#39;: 36, &#39;max_depth&#39;: 12, &#39;learning_rate&#39;: 0.19448891436942936, &#39;subsample&#39;: 0.6068810469588015, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.0002076835508378969, &#39;lambda_l2&#39;: 0.20540546614255564}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0002306137395720167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002306137395720167
[LightGBM] [Warning] lambda_l2 is set=1.648458046632147e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.648458046632147e-06
[LightGBM] [Warning] lambda_l1 is set=0.0002306137395720167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002306137395720167
[LightGBM] [Warning] lambda_l2 is set=1.648458046632147e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.648458046632147e-06
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033672 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0002306137395720167, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002306137395720167
[LightGBM] [Warning] lambda_l2 is set=1.648458046632147e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.648458046632147e-06
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:11,540] Trial 12 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 197, &#39;num_leaves&#39;: 49, &#39;max_depth&#39;: 19, &#39;learning_rate&#39;: 0.18740535789747398, &#39;subsample&#39;: 0.6021020432995058, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.0002306137395720167, &#39;lambda_l2&#39;: 1.648458046632147e-06}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0007418947114436029, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007418947114436029
[LightGBM] [Warning] lambda_l2 is set=0.9379068621610464, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9379068621610464
[LightGBM] [Warning] lambda_l1 is set=0.0007418947114436029, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007418947114436029
[LightGBM] [Warning] lambda_l2 is set=0.9379068621610464, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9379068621610464
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017530 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0007418947114436029, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007418947114436029
[LightGBM] [Warning] lambda_l2 is set=0.9379068621610464, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9379068621610464
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:14,703] Trial 13 finished with value: 0.9879104936914758 and parameters: {&#39;n_estimators&#39;: 165, &#39;num_leaves&#39;: 38, &#39;max_depth&#39;: 3, &#39;learning_rate&#39;: 0.08809936963843913, &#39;subsample&#39;: 0.6817037756487222, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 0.0007418947114436029, &#39;lambda_l2&#39;: 0.9379068621610464}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=5.683111142813972e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.683111142813972e-05
[LightGBM] [Warning] lambda_l2 is set=0.04010097020486311, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04010097020486311
[LightGBM] [Warning] lambda_l1 is set=5.683111142813972e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.683111142813972e-05
[LightGBM] [Warning] lambda_l2 is set=0.04010097020486311, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04010097020486311
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025426 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.683111142813972e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.683111142813972e-05
[LightGBM] [Warning] lambda_l2 is set=0.04010097020486311, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04010097020486311
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:19,997] Trial 14 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 166, &#39;num_leaves&#39;: 30, &#39;max_depth&#39;: 18, &#39;learning_rate&#39;: 0.09542979416155771, &#39;subsample&#39;: 0.627518553080361, &#39;min_child_weight&#39;: 13, &#39;lambda_l1&#39;: 5.683111142813972e-05, &#39;lambda_l2&#39;: 0.04010097020486311}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.5086904485004158e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5086904485004158e-06
[LightGBM] [Warning] lambda_l2 is set=0.01763124706803618, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01763124706803618
[LightGBM] [Warning] lambda_l1 is set=1.5086904485004158e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5086904485004158e-06
[LightGBM] [Warning] lambda_l2 is set=0.01763124706803618, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01763124706803618
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043618 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=1.5086904485004158e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5086904485004158e-06
[LightGBM] [Warning] lambda_l2 is set=0.01763124706803618, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01763124706803618
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:25,878] Trial 15 finished with value: 0.9994284960654152 and parameters: {&#39;n_estimators&#39;: 170, &#39;num_leaves&#39;: 42, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.03357437585219594, &#39;subsample&#39;: 0.6556413982102188, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 1.5086904485004158e-06, &#39;lambda_l2&#39;: 0.01763124706803618}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0019843959512907787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019843959512907787
[LightGBM] [Warning] lambda_l2 is set=0.060526541777496196, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.060526541777496196
[LightGBM] [Warning] lambda_l1 is set=0.0019843959512907787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019843959512907787
[LightGBM] [Warning] lambda_l2 is set=0.060526541777496196, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.060526541777496196
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037646 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:30,248] Trial 16 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 85, &#39;num_leaves&#39;: 32, &#39;max_depth&#39;: 30, &#39;learning_rate&#39;: 0.10606255340383655, &#39;subsample&#39;: 0.7137320892193406, &#39;min_child_weight&#39;: 13, &#39;lambda_l1&#39;: 0.0019843959512907787, &#39;lambda_l2&#39;: 0.060526541777496196}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0019843959512907787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019843959512907787
[LightGBM] [Warning] lambda_l2 is set=0.060526541777496196, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.060526541777496196
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.10175778172850711, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10175778172850711
[LightGBM] [Warning] lambda_l2 is set=0.01226254972559693, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01226254972559693
[LightGBM] [Warning] lambda_l1 is set=0.10175778172850711, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10175778172850711
[LightGBM] [Warning] lambda_l2 is set=0.01226254972559693, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01226254972559693
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041108 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.10175778172850711, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10175778172850711
[LightGBM] [Warning] lambda_l2 is set=0.01226254972559693, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01226254972559693
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:36,251] Trial 17 finished with value: 0.9999780190794391 and parameters: {&#39;n_estimators&#39;: 183, &#39;num_leaves&#39;: 24, &#39;max_depth&#39;: 17, &#39;learning_rate&#39;: 0.051445036266391485, &#39;subsample&#39;: 0.6474580579908964, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 0.10175778172850711, &#39;lambda_l2&#39;: 0.01226254972559693}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0005863107102863994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005863107102863994
[LightGBM] [Warning] lambda_l2 is set=0.9043973885631855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9043973885631855
[LightGBM] [Warning] lambda_l1 is set=0.0005863107102863994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005863107102863994
[LightGBM] [Warning] lambda_l2 is set=0.9043973885631855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9043973885631855
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039900 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0005863107102863994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005863107102863994
[LightGBM] [Warning] lambda_l2 is set=0.9043973885631855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9043973885631855
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:41,380] Trial 18 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 147, &#39;num_leaves&#39;: 42, &#39;max_depth&#39;: 42, &#39;learning_rate&#39;: 0.19708908457104907, &#39;subsample&#39;: 0.7161523906974101, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 0.0005863107102863994, &#39;lambda_l2&#39;: 0.9043973885631855}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=4.041888939715811e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.041888939715811e-05
[LightGBM] [Warning] lambda_l2 is set=0.1457933738092917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1457933738092917
[LightGBM] [Warning] lambda_l1 is set=4.041888939715811e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.041888939715811e-05
[LightGBM] [Warning] lambda_l2 is set=0.1457933738092917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1457933738092917
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037676 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=4.041888939715811e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.041888939715811e-05
[LightGBM] [Warning] lambda_l2 is set=0.1457933738092917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1457933738092917
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:44,235] Trial 19 finished with value: 0.9913614982195454 and parameters: {&#39;n_estimators&#39;: 151, &#39;num_leaves&#39;: 35, &#39;max_depth&#39;: 3, &#39;learning_rate&#39;: 0.11039117708289177, &#39;subsample&#39;: 0.6355857549573107, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 4.041888939715811e-05, &#39;lambda_l2&#39;: 0.1457933738092917}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.003663308686652999, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003663308686652999
[LightGBM] [Warning] lambda_l2 is set=0.012228335457738129, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012228335457738129
[LightGBM] [Warning] lambda_l1 is set=0.003663308686652999, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003663308686652999
[LightGBM] [Warning] lambda_l2 is set=0.012228335457738129, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012228335457738129
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041918 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.003663308686652999, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003663308686652999
[LightGBM] [Warning] lambda_l2 is set=0.012228335457738129, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012228335457738129
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:50,181] Trial 20 finished with value: 0.9982195454345628 and parameters: {&#39;n_estimators&#39;: 180, &#39;num_leaves&#39;: 44, &#39;max_depth&#39;: 22, &#39;learning_rate&#39;: 0.024946545617177487, &#39;subsample&#39;: 0.6811792421824981, &#39;min_child_weight&#39;: 11, &#39;lambda_l1&#39;: 0.003663308686652999, &#39;lambda_l2&#39;: 0.012228335457738129}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00019715582887684131, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019715582887684131
[LightGBM] [Warning] lambda_l2 is set=0.18407032063474368, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18407032063474368
[LightGBM] [Warning] lambda_l1 is set=0.00019715582887684131, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019715582887684131
[LightGBM] [Warning] lambda_l2 is set=0.18407032063474368, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18407032063474368
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041782 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00019715582887684131, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019715582887684131
[LightGBM] [Warning] lambda_l2 is set=0.18407032063474368, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18407032063474368
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:21:56,357] Trial 21 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 197, &#39;num_leaves&#39;: 36, &#39;max_depth&#39;: 11, &#39;learning_rate&#39;: 0.1817427202479822, &#39;subsample&#39;: 0.6018292896706078, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.00019715582887684131, &#39;lambda_l2&#39;: 0.18407032063474368}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0001434835291160498, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001434835291160498
[LightGBM] [Warning] lambda_l2 is set=0.23869254689373304, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23869254689373304
[LightGBM] [Warning] lambda_l1 is set=0.0001434835291160498, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001434835291160498
[LightGBM] [Warning] lambda_l2 is set=0.23869254689373304, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23869254689373304
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043116 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0001434835291160498, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001434835291160498
[LightGBM] [Warning] lambda_l2 is set=0.23869254689373304, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23869254689373304
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:02,284] Trial 22 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 198, &#39;num_leaves&#39;: 33, &#39;max_depth&#39;: 10, &#39;learning_rate&#39;: 0.06385465817821269, &#39;subsample&#39;: 0.6056997288626638, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 0.0001434835291160498, &#39;lambda_l2&#39;: 0.23869254689373304}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0007848051693889538, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007848051693889538
[LightGBM] [Warning] lambda_l2 is set=0.05710878981067987, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05710878981067987
[LightGBM] [Warning] lambda_l1 is set=0.0007848051693889538, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007848051693889538
[LightGBM] [Warning] lambda_l2 is set=0.05710878981067987, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05710878981067987
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042796 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0007848051693889538, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007848051693889538
[LightGBM] [Warning] lambda_l2 is set=0.05710878981067987, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05710878981067987
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:07,743] Trial 23 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 180, &#39;num_leaves&#39;: 29, &#39;max_depth&#39;: 14, &#39;learning_rate&#39;: 0.14153794580608958, &#39;subsample&#39;: 0.6324060085096299, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 0.0007848051693889538, &#39;lambda_l2&#39;: 0.05710878981067987}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.9719832628408645e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9719832628408645e-05
[LightGBM] [Warning] lambda_l2 is set=0.37329330305751085, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.37329330305751085
[LightGBM] [Warning] lambda_l1 is set=2.9719832628408645e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9719832628408645e-05
[LightGBM] [Warning] lambda_l2 is set=0.37329330305751085, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.37329330305751085
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042220 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.9719832628408645e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9719832628408645e-05
[LightGBM] [Warning] lambda_l2 is set=0.37329330305751085, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.37329330305751085
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:12,526] Trial 24 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 157, &#39;num_leaves&#39;: 40, &#39;max_depth&#39;: 7, &#39;learning_rate&#39;: 0.12232064843360231, &#39;subsample&#39;: 0.6567784251804724, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 2.9719832628408645e-05, &#39;lambda_l2&#39;: 0.37329330305751085}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00029001057285563727, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029001057285563727
[LightGBM] [Warning] lambda_l2 is set=0.006657195477038382, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006657195477038382
[LightGBM] [Warning] lambda_l1 is set=0.00029001057285563727, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029001057285563727
[LightGBM] [Warning] lambda_l2 is set=0.006657195477038382, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006657195477038382
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039864 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00029001057285563727, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029001057285563727
[LightGBM] [Warning] lambda_l2 is set=0.006657195477038382, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006657195477038382
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:19,010] Trial 25 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 184, &#39;num_leaves&#39;: 46, &#39;max_depth&#39;: 30, &#39;learning_rate&#39;: 0.07934726210885557, &#39;subsample&#39;: 0.6846524647126585, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 0.00029001057285563727, &#39;lambda_l2&#39;: 0.006657195477038382}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.446408002635624e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.446408002635624e-05
[LightGBM] [Warning] lambda_l2 is set=0.06987896484329949, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06987896484329949
[LightGBM] [Warning] lambda_l1 is set=7.446408002635624e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.446408002635624e-05
[LightGBM] [Warning] lambda_l2 is set=0.06987896484329949, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06987896484329949
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041694 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:21,830] Trial 26 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 78, &#39;num_leaves&#39;: 35, &#39;max_depth&#39;: 15, &#39;learning_rate&#39;: 0.13178088096436988, &#39;subsample&#39;: 0.6005047191074979, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 7.446408002635624e-05, &#39;lambda_l2&#39;: 0.06987896484329949}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.446408002635624e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.446408002635624e-05
[LightGBM] [Warning] lambda_l2 is set=0.06987896484329949, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06987896484329949
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.6005862226076212e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6005862226076212e-05
[LightGBM] [Warning] lambda_l2 is set=0.028039778155795336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028039778155795336
[LightGBM] [Warning] lambda_l1 is set=1.6005862226076212e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6005862226076212e-05
[LightGBM] [Warning] lambda_l2 is set=0.028039778155795336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028039778155795336
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043027 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=1.6005862226076212e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6005862226076212e-05
[LightGBM] [Warning] lambda_l2 is set=0.028039778155795336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028039778155795336
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:27,481] Trial 27 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 199, &#39;num_leaves&#39;: 23, &#39;max_depth&#39;: 23, &#39;learning_rate&#39;: 0.07171345467949547, &#39;subsample&#39;: 0.6313890868557164, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 1.6005862226076212e-05, &#39;lambda_l2&#39;: 0.028039778155795336}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=9.401504094177196e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.401504094177196e-05
[LightGBM] [Warning] lambda_l2 is set=0.1277775224942746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1277775224942746
[LightGBM] [Warning] lambda_l1 is set=9.401504094177196e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.401504094177196e-05
[LightGBM] [Warning] lambda_l2 is set=0.1277775224942746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1277775224942746
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039578 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=9.401504094177196e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.401504094177196e-05
[LightGBM] [Warning] lambda_l2 is set=0.1277775224942746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1277775224942746
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:31,331] Trial 28 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 138, &#39;num_leaves&#39;: 50, &#39;max_depth&#39;: 7, &#39;learning_rate&#39;: 0.19554824377548022, &#39;subsample&#39;: 0.726515942710098, &#39;min_child_weight&#39;: 16, &#39;lambda_l1&#39;: 9.401504094177196e-05, &#39;lambda_l2&#39;: 0.1277775224942746}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.06311987297956165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06311987297956165
[LightGBM] [Warning] lambda_l2 is set=0.005868735706903017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005868735706903017
[LightGBM] [Warning] lambda_l1 is set=0.06311987297956165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06311987297956165
[LightGBM] [Warning] lambda_l2 is set=0.005868735706903017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005868735706903017
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040785 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.06311987297956165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06311987297956165
[LightGBM] [Warning] lambda_l2 is set=0.005868735706903017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005868735706903017
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:36,712] Trial 29 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 170, &#39;num_leaves&#39;: 27, &#39;max_depth&#39;: 21, &#39;learning_rate&#39;: 0.0521513207168882, &#39;subsample&#39;: 0.6651255447551244, &#39;min_child_weight&#39;: 11, &#39;lambda_l1&#39;: 0.06311987297956165, &#39;lambda_l2&#39;: 0.005868735706903017}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0020844811041668405, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020844811041668405
[LightGBM] [Warning] lambda_l2 is set=0.4381921208935957, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4381921208935957
[LightGBM] [Warning] lambda_l1 is set=0.0020844811041668405, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020844811041668405
[LightGBM] [Warning] lambda_l2 is set=0.4381921208935957, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4381921208935957
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037031 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.0020844811041668405, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020844811041668405
[LightGBM] [Warning] lambda_l2 is set=0.4381921208935957, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4381921208935957
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:41,695] Trial 30 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 186, &#39;num_leaves&#39;: 19, &#39;max_depth&#39;: 28, &#39;learning_rate&#39;: 0.12519760189103202, &#39;subsample&#39;: 0.6276434836551739, &#39;min_child_weight&#39;: 15, &#39;lambda_l1&#39;: 0.0020844811041668405, &#39;lambda_l2&#39;: 0.4381921208935957}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0002458507652409347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002458507652409347
[LightGBM] [Warning] lambda_l2 is set=2.1732005146828404e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1732005146828404e-06
[LightGBM] [Warning] lambda_l1 is set=0.0002458507652409347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002458507652409347
[LightGBM] [Warning] lambda_l2 is set=2.1732005146828404e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1732005146828404e-06
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034768 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0002458507652409347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002458507652409347
[LightGBM] [Warning] lambda_l2 is set=2.1732005146828404e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1732005146828404e-06
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:47,667] Trial 31 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 191, &#39;num_leaves&#39;: 50, &#39;max_depth&#39;: 19, &#39;learning_rate&#39;: 0.16092294053752493, &#39;subsample&#39;: 0.604304037563694, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.0002458507652409347, &#39;lambda_l2&#39;: 2.1732005146828404e-06}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00035211860301660844, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00035211860301660844
[LightGBM] [Warning] lambda_l2 is set=6.770910434205465e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.770910434205465e-06
[LightGBM] [Warning] lambda_l1 is set=0.00035211860301660844, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00035211860301660844
[LightGBM] [Warning] lambda_l2 is set=6.770910434205465e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.770910434205465e-06
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039616 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00035211860301660844, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00035211860301660844
[LightGBM] [Warning] lambda_l2 is set=6.770910434205465e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.770910434205465e-06
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:53,147] Trial 32 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 200, &#39;num_leaves&#39;: 46, &#39;max_depth&#39;: 14, &#39;learning_rate&#39;: 0.19595456858419935, &#39;subsample&#39;: 0.6857762411408362, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 0.00035211860301660844, &#39;lambda_l2&#39;: 6.770910434205465e-06}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00015842195343890084, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015842195343890084
[LightGBM] [Warning] lambda_l2 is set=0.0005154787953681867, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005154787953681867
[LightGBM] [Warning] lambda_l1 is set=0.00015842195343890084, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015842195343890084
[LightGBM] [Warning] lambda_l2 is set=0.0005154787953681867, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005154787953681867
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036418 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00015842195343890084, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015842195343890084
[LightGBM] [Warning] lambda_l2 is set=0.0005154787953681867, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005154787953681867
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:22:58,809] Trial 33 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 178, &#39;num_leaves&#39;: 38, &#39;max_depth&#39;: 12, &#39;learning_rate&#39;: 0.09205196791429238, &#39;subsample&#39;: 0.6564293058659167, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 0.00015842195343890084, &#39;lambda_l2&#39;: 0.0005154787953681867}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0013036698302731646, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013036698302731646
[LightGBM] [Warning] lambda_l2 is set=1.9319534022730996e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9319534022730996e-05
[LightGBM] [Warning] lambda_l1 is set=0.0013036698302731646, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013036698302731646
[LightGBM] [Warning] lambda_l2 is set=1.9319534022730996e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9319534022730996e-05
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008306 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:01,770] Trial 34 finished with value: 0.9861520200465995 and parameters: {&#39;n_estimators&#39;: 156, &#39;num_leaves&#39;: 4, &#39;max_depth&#39;: 8, &#39;learning_rate&#39;: 0.14151882365955282, &#39;subsample&#39;: 0.6156327872675763, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 0.0013036698302731646, &#39;lambda_l2&#39;: 1.9319534022730996e-05}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0013036698302731646, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013036698302731646
[LightGBM] [Warning] lambda_l2 is set=1.9319534022730996e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9319534022730996e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00038291087183044625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00038291087183044625
[LightGBM] [Warning] lambda_l2 is set=0.0003651757487376388, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003651757487376388
[LightGBM] [Warning] lambda_l1 is set=0.00038291087183044625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00038291087183044625
[LightGBM] [Warning] lambda_l2 is set=0.0003651757487376388, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003651757487376388
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032175 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:05,512] Trial 35 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 107, &#39;num_leaves&#39;: 42, &#39;max_depth&#39;: 36, &#39;learning_rate&#39;: 0.07117343664645127, &#39;subsample&#39;: 0.641859676951522, &#39;min_child_weight&#39;: 20, &#39;lambda_l1&#39;: 0.00038291087183044625, &#39;lambda_l2&#39;: 0.0003651757487376388}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00038291087183044625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00038291087183044625
[LightGBM] [Warning] lambda_l2 is set=0.0003651757487376388, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0003651757487376388
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.005795080225792297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005795080225792297
[LightGBM] [Warning] lambda_l2 is set=0.0007855496342028123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007855496342028123
[LightGBM] [Warning] lambda_l1 is set=0.005795080225792297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005795080225792297
[LightGBM] [Warning] lambda_l2 is set=0.0007855496342028123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007855496342028123
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032159 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.005795080225792297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005795080225792297
[LightGBM] [Warning] lambda_l2 is set=0.0007855496342028123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007855496342028123
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:11,178] Trial 36 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 190, &#39;num_leaves&#39;: 33, &#39;max_depth&#39;: 46, &#39;learning_rate&#39;: 0.14180206305615645, &#39;subsample&#39;: 0.7041026272901264, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.005795080225792297, &#39;lambda_l2&#39;: 0.0007855496342028123}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0011167863970053136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0011167863970053136
[LightGBM] [Warning] lambda_l2 is set=8.039489850171275e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.039489850171275e-05
[LightGBM] [Warning] lambda_l1 is set=0.0011167863970053136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0011167863970053136
[LightGBM] [Warning] lambda_l2 is set=8.039489850171275e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.039489850171275e-05
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034832 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.0011167863970053136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0011167863970053136
[LightGBM] [Warning] lambda_l2 is set=8.039489850171275e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.039489850171275e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:16,356] Trial 37 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 173, &#39;num_leaves&#39;: 48, &#39;max_depth&#39;: 20, &#39;learning_rate&#39;: 0.04438211056951084, &#39;subsample&#39;: 0.621706173509447, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 0.0011167863970053136, &#39;lambda_l2&#39;: 8.039489850171275e-05}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0001394252218879136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001394252218879136
[LightGBM] [Warning] lambda_l2 is set=1.026812323140813e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.026812323140813e-06
[LightGBM] [Warning] lambda_l1 is set=0.0001394252218879136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001394252218879136
[LightGBM] [Warning] lambda_l2 is set=1.026812323140813e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.026812323140813e-06
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037982 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0001394252218879136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001394252218879136
[LightGBM] [Warning] lambda_l2 is set=1.026812323140813e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.026812323140813e-06
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:20,898] Trial 38 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 160, &#39;num_leaves&#39;: 40, &#39;max_depth&#39;: 25, &#39;learning_rate&#39;: 0.09443537682865273, &#39;subsample&#39;: 0.739654517960474, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 0.0001394252218879136, &#39;lambda_l2&#39;: 1.026812323140813e-06}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0004972217576248992, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004972217576248992
[LightGBM] [Warning] lambda_l2 is set=0.00018631271788235556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018631271788235556
[LightGBM] [Warning] lambda_l1 is set=0.0004972217576248992, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004972217576248992
[LightGBM] [Warning] lambda_l2 is set=0.00018631271788235556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018631271788235556
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033721 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:23,161] Trial 39 finished with value: 0.9974502132149294 and parameters: {&#39;n_estimators&#39;: 93, &#39;num_leaves&#39;: 20, &#39;max_depth&#39;: 16, &#39;learning_rate&#39;: 0.06597202506689775, &#39;subsample&#39;: 0.6720611029122991, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 0.0004972217576248992, &#39;lambda_l2&#39;: 0.00018631271788235556}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0004972217576248992, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004972217576248992
[LightGBM] [Warning] lambda_l2 is set=0.00018631271788235556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018631271788235556
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.853547531180989, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.853547531180989
[LightGBM] [Warning] lambda_l2 is set=0.001363668806393406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001363668806393406
[LightGBM] [Warning] lambda_l1 is set=0.853547531180989, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.853547531180989
[LightGBM] [Warning] lambda_l2 is set=0.001363668806393406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001363668806393406
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038485 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.853547531180989, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.853547531180989
[LightGBM] [Warning] lambda_l2 is set=0.001363668806393406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001363668806393406
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:26,613] Trial 40 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 122, &#39;num_leaves&#39;: 27, &#39;max_depth&#39;: 28, &#39;learning_rate&#39;: 0.15559817797620135, &#39;subsample&#39;: 0.7699832504145917, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 0.853547531180989, &#39;lambda_l2&#39;: 0.001363668806393406}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.115837271136366e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.115837271136366e-05
[LightGBM] [Warning] lambda_l2 is set=0.031161816864982983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031161816864982983
[LightGBM] [Warning] lambda_l1 is set=7.115837271136366e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.115837271136366e-05
[LightGBM] [Warning] lambda_l2 is set=0.031161816864982983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031161816864982983
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028151 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.115837271136366e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.115837271136366e-05
[LightGBM] [Warning] lambda_l2 is set=0.031161816864982983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031161816864982983
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:31,635] Trial 41 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 189, &#39;num_leaves&#39;: 30, &#39;max_depth&#39;: 19, &#39;learning_rate&#39;: 0.10188133999336645, &#39;subsample&#39;: 0.6210597741746806, &#39;min_child_weight&#39;: 13, &#39;lambda_l1&#39;: 7.115837271136366e-05, &#39;lambda_l2&#39;: 0.031161816864982983}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.884584803966609e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.884584803966609e-05
[LightGBM] [Warning] lambda_l2 is set=0.0032547264130936954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0032547264130936954
[LightGBM] [Warning] lambda_l1 is set=2.884584803966609e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.884584803966609e-05
[LightGBM] [Warning] lambda_l2 is set=0.0032547264130936954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0032547264130936954
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040791 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=2.884584803966609e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.884584803966609e-05
[LightGBM] [Warning] lambda_l2 is set=0.0032547264130936954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0032547264130936954
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:36,397] Trial 42 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 167, &#39;num_leaves&#39;: 37, &#39;max_depth&#39;: 18, &#39;learning_rate&#39;: 0.08366901316132619, &#39;subsample&#39;: 0.6430356631536593, &#39;min_child_weight&#39;: 14, &#39;lambda_l1&#39;: 2.884584803966609e-05, &#39;lambda_l2&#39;: 0.0032547264130936954}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.193906976051784e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.193906976051784e-06
[LightGBM] [Warning] lambda_l2 is set=5.1898751328953876e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.1898751328953876e-05
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=7.193906976051784e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.193906976051784e-06
[LightGBM] [Warning] lambda_l2 is set=5.1898751328953876e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.1898751328953876e-05
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041736 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.193906976051784e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.193906976051784e-06
[LightGBM] [Warning] lambda_l2 is set=5.1898751328953876e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.1898751328953876e-05
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:40,895] Trial 43 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 175, &#39;num_leaves&#39;: 31, &#39;max_depth&#39;: 13, &#39;learning_rate&#39;: 0.12235232520398928, &#39;subsample&#39;: 0.6194119791268813, &#39;min_child_weight&#39;: 12, &#39;lambda_l1&#39;: 7.193906976051784e-06, &#39;lambda_l2&#39;: 5.1898751328953876e-05}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.3712578944231632, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3712578944231632
[LightGBM] [Warning] lambda_l2 is set=1.2504836946457401e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2504836946457401e-05
[LightGBM] [Warning] lambda_l1 is set=0.3712578944231632, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3712578944231632
[LightGBM] [Warning] lambda_l2 is set=1.2504836946457401e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2504836946457401e-05
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043128 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.3712578944231632, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3712578944231632
[LightGBM] [Warning] lambda_l2 is set=1.2504836946457401e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2504836946457401e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:45,487] Trial 44 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 191, &#39;num_leaves&#39;: 34, &#39;max_depth&#39;: 33, &#39;learning_rate&#39;: 0.163201725232607, &#39;subsample&#39;: 0.6508460942073692, &#39;min_child_weight&#39;: 10, &#39;lambda_l1&#39;: 0.3712578944231632, &#39;lambda_l2&#39;: 1.2504836946457401e-05}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=5.132851271534764e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.132851271534764e-05
[LightGBM] [Warning] lambda_l2 is set=0.000239677096021487, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000239677096021487
[LightGBM] [Warning] lambda_l1 is set=5.132851271534764e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.132851271534764e-05
[LightGBM] [Warning] lambda_l2 is set=0.000239677096021487, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000239677096021487
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032718 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.132851271534764e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.132851271534764e-05
[LightGBM] [Warning] lambda_l2 is set=0.000239677096021487, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000239677096021487
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:49,456] Trial 45 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 143, &#39;num_leaves&#39;: 29, &#39;max_depth&#39;: 23, &#39;learning_rate&#39;: 0.10391098193379311, &#39;subsample&#39;: 0.6699445822645996, &#39;min_child_weight&#39;: 16, &#39;lambda_l1&#39;: 5.132851271534764e-05, &#39;lambda_l2&#39;: 0.000239677096021487}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00010112072907133065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010112072907133065
[LightGBM] [Warning] lambda_l2 is set=0.08548027968484422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08548027968484422
[LightGBM] [Warning] lambda_l1 is set=0.00010112072907133065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010112072907133065
[LightGBM] [Warning] lambda_l2 is set=0.08548027968484422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08548027968484422
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023122 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:50,909] Trial 46 finished with value: 0.9869653141073548 and parameters: {&#39;n_estimators&#39;: 44, &#39;num_leaves&#39;: 44, &#39;max_depth&#39;: 17, &#39;learning_rate&#39;: 0.04112136975382366, &#39;subsample&#39;: 0.697063259098125, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 0.00010112072907133065, &#39;lambda_l2&#39;: 0.08548027968484422}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00010112072907133065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010112072907133065
[LightGBM] [Warning] lambda_l2 is set=0.08548027968484422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08548027968484422
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0005315338393726118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005315338393726118
[LightGBM] [Warning] lambda_l2 is set=0.03497029285250779, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03497029285250779
[LightGBM] [Warning] lambda_l1 is set=0.0005315338393726118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005315338393726118
[LightGBM] [Warning] lambda_l2 is set=0.03497029285250779, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03497029285250779
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026093 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.0005315338393726118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005315338393726118
[LightGBM] [Warning] lambda_l2 is set=0.03497029285250779, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03497029285250779
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:55,098] Trial 47 finished with value: 0.9999780190794391 and parameters: {&#39;n_estimators&#39;: 163, &#39;num_leaves&#39;: 22, &#39;max_depth&#39;: 41, &#39;learning_rate&#39;: 0.05558729589884408, &#39;subsample&#39;: 0.6399236144886189, &#39;min_child_weight&#39;: 13, &#39;lambda_l1&#39;: 0.0005315338393726118, &#39;lambda_l2&#39;: 0.03497029285250779}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.7650037028609303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7650037028609303e-05
[LightGBM] [Warning] lambda_l2 is set=0.0022639281762034677, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0022639281762034677
[LightGBM] [Warning] lambda_l1 is set=1.7650037028609303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7650037028609303e-05
[LightGBM] [Warning] lambda_l2 is set=0.0022639281762034677, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0022639281762034677
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041514 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:23:58,953] Trial 48 finished with value: 0.9951641974765904 and parameters: {&#39;n_estimators&#39;: 134, &#39;num_leaves&#39;: 40, &#39;max_depth&#39;: 8, &#39;learning_rate&#39;: 0.0322146188203088, &#39;subsample&#39;: 0.6164905087957421, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 1.7650037028609303e-05, &#39;lambda_l2&#39;: 0.0022639281762034677}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=1.7650037028609303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7650037028609303e-05
[LightGBM] [Warning] lambda_l2 is set=0.0022639281762034677, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0022639281762034677
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00024212834828208181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00024212834828208181
[LightGBM] [Warning] lambda_l2 is set=0.0007435520056594922, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007435520056594922
[LightGBM] [Warning] lambda_l1 is set=0.00024212834828208181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00024212834828208181
[LightGBM] [Warning] lambda_l2 is set=0.0007435520056594922, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007435520056594922
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029853 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:01,064] Trial 49 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 62, &#39;num_leaves&#39;: 27, &#39;max_depth&#39;: 25, &#39;learning_rate&#39;: 0.1691330335301425, &#39;subsample&#39;: 0.6615083891395293, &#39;min_child_weight&#39;: 18, &#39;lambda_l1&#39;: 0.00024212834828208181, &#39;lambda_l2&#39;: 0.0007435520056594922}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00024212834828208181, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00024212834828208181
[LightGBM] [Warning] lambda_l2 is set=0.0007435520056594922, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007435520056594922
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=5.759176020830391e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.759176020830391e-05
[LightGBM] [Warning] lambda_l2 is set=0.0001235350625063021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001235350625063021
[LightGBM] [Warning] lambda_l1 is set=5.759176020830391e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.759176020830391e-05
[LightGBM] [Warning] lambda_l2 is set=0.0001235350625063021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001235350625063021
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037884 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.759176020830391e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.759176020830391e-05
[LightGBM] [Warning] lambda_l2 is set=0.0001235350625063021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001235350625063021
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:04,219] Trial 50 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 150, &#39;num_leaves&#39;: 36, &#39;max_depth&#39;: 5, &#39;learning_rate&#39;: 0.19907515742084034, &#39;subsample&#39;: 0.6975326153573058, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 5.759176020830391e-05, &#39;lambda_l2&#39;: 0.0001235350625063021}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.010001291335952223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010001291335952223
[LightGBM] [Warning] lambda_l2 is set=0.09917111941867937, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.09917111941867937
[LightGBM] [Warning] lambda_l1 is set=0.010001291335952223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010001291335952223
[LightGBM] [Warning] lambda_l2 is set=0.09917111941867937, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.09917111941867937
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020641 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:06,920] Trial 51 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 88, &#39;num_leaves&#39;: 32, &#39;max_depth&#39;: 30, &#39;learning_rate&#39;: 0.11758854305910432, &#39;subsample&#39;: 0.6006840004417661, &#39;min_child_weight&#39;: 12, &#39;lambda_l1&#39;: 0.010001291335952223, &#39;lambda_l2&#39;: 0.09917111941867937}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.010001291335952223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010001291335952223
[LightGBM] [Warning] lambda_l2 is set=0.09917111941867937, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.09917111941867937
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.03170126462930942, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03170126462930942
[LightGBM] [Warning] lambda_l2 is set=0.04598075988944659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04598075988944659
[LightGBM] [Warning] lambda_l1 is set=0.03170126462930942, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03170126462930942
[LightGBM] [Warning] lambda_l2 is set=0.04598075988944659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04598075988944659
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031823 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:08,908] Trial 52 finished with value: 0.9990108585747571 and parameters: {&#39;n_estimators&#39;: 63, &#39;num_leaves&#39;: 25, &#39;max_depth&#39;: 31, &#39;learning_rate&#39;: 0.0983937821711146, &#39;subsample&#39;: 0.7146914007292653, &#39;min_child_weight&#39;: 14, &#39;lambda_l1&#39;: 0.03170126462930942, &#39;lambda_l2&#39;: 0.04598075988944659}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.03170126462930942, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03170126462930942
[LightGBM] [Warning] lambda_l2 is set=0.04598075988944659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04598075988944659
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.002312006626611796, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002312006626611796
[LightGBM] [Warning] lambda_l2 is set=0.283221919814331, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.283221919814331
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=0.002312006626611796, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002312006626611796
[LightGBM] [Warning] lambda_l2 is set=0.283221919814331, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.283221919814331
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035841 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:11,091] Trial 53 finished with value: 0.9983953927990504 and parameters: {&#39;n_estimators&#39;: 74, &#39;num_leaves&#39;: 31, &#39;max_depth&#39;: 36, &#39;learning_rate&#39;: 0.0719276282040167, &#39;subsample&#39;: 0.6336606506984996, &#39;min_child_weight&#39;: 13, &#39;lambda_l1&#39;: 0.002312006626611796, &#39;lambda_l2&#39;: 0.283221919814331}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.002312006626611796, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002312006626611796
[LightGBM] [Warning] lambda_l2 is set=0.283221919814331, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.283221919814331
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.2019962510492609, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2019962510492609
[LightGBM] [Warning] lambda_l2 is set=0.1565431560448936, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1565431560448936
[LightGBM] [Warning] lambda_l1 is set=0.2019962510492609, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2019962510492609
[LightGBM] [Warning] lambda_l2 is set=0.1565431560448936, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1565431560448936
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032376 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.2019962510492609, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2019962510492609
[LightGBM] [Warning] lambda_l2 is set=0.1565431560448936, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1565431560448936
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:15,622] Trial 54 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 183, &#39;num_leaves&#39;: 38, &#39;max_depth&#39;: 11, &#39;learning_rate&#39;: 0.11279846359605616, &#39;subsample&#39;: 0.8040364793730451, &#39;min_child_weight&#39;: 12, &#39;lambda_l1&#39;: 0.2019962510492609, &#39;lambda_l2&#39;: 0.1565431560448936}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0007288724407801853, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007288724407801853
[LightGBM] [Warning] lambda_l2 is set=0.06286119812091452, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06286119812091452
[LightGBM] [Warning] lambda_l1 is set=0.0007288724407801853, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007288724407801853
[LightGBM] [Warning] lambda_l2 is set=0.06286119812091452, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06286119812091452
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038199 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0007288724407801853, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007288724407801853
[LightGBM] [Warning] lambda_l2 is set=0.06286119812091452, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06286119812091452
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:20,733] Trial 55 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 194, &#39;num_leaves&#39;: 34, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.08523592483667058, &#39;subsample&#39;: 0.766157912092612, &#39;min_child_weight&#39;: 10, &#39;lambda_l1&#39;: 0.0007288724407801853, &#39;lambda_l2&#39;: 0.06286119812091452}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00015060109947196337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015060109947196337
[LightGBM] [Warning] lambda_l2 is set=0.5394854678164966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5394854678164966
[LightGBM] [Warning] lambda_l1 is set=0.00015060109947196337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015060109947196337
[LightGBM] [Warning] lambda_l2 is set=0.5394854678164966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5394854678164966
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025993 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00015060109947196337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00015060109947196337
[LightGBM] [Warning] lambda_l2 is set=0.5394854678164966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5394854678164966
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:24,100] Trial 56 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 110, &#39;num_leaves&#39;: 43, &#39;max_depth&#39;: 27, &#39;learning_rate&#39;: 0.15980138773641422, &#39;subsample&#39;: 0.6516567528596607, &#39;min_child_weight&#39;: 14, &#39;lambda_l1&#39;: 0.00015060109947196337, &#39;lambda_l2&#39;: 0.5394854678164966}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=3.706516166546454e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.706516166546454e-05
[LightGBM] [Warning] lambda_l2 is set=0.19800068443362512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19800068443362512
[LightGBM] [Warning] lambda_l1 is set=3.706516166546454e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.706516166546454e-05
[LightGBM] [Warning] lambda_l2 is set=0.19800068443362512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19800068443362512
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033387 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=3.706516166546454e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.706516166546454e-05
[LightGBM] [Warning] lambda_l2 is set=0.19800068443362512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19800068443362512
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:28,699] Trial 57 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 178, &#39;num_leaves&#39;: 29, &#39;max_depth&#39;: 15, &#39;learning_rate&#39;: 0.13487583935938915, &#39;subsample&#39;: 0.677523348351846, &#39;min_child_weight&#39;: 15, &#39;lambda_l1&#39;: 3.706516166546454e-05, &#39;lambda_l2&#39;: 0.19800068443362512}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0002819498636833977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002819498636833977
[LightGBM] [Warning] lambda_l2 is set=0.01594966249107861, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01594966249107861
[LightGBM] [Warning] lambda_l1 is set=0.0002819498636833977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002819498636833977
[LightGBM] [Warning] lambda_l2 is set=0.01594966249107861, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01594966249107861
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031397 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.0002819498636833977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002819498636833977
[LightGBM] [Warning] lambda_l2 is set=0.01594966249107861, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01594966249107861
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:34,402] Trial 58 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 195, &#39;num_leaves&#39;: 36, &#39;max_depth&#39;: 32, &#39;learning_rate&#39;: 0.06323527481628241, &#39;subsample&#39;: 0.6097182376582118, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.0002819498636833977, &#39;lambda_l2&#39;: 0.01594966249107861}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.001125581933884339, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001125581933884339
[LightGBM] [Warning] lambda_l2 is set=0.022626035801515905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.022626035801515905
[LightGBM] [Warning] lambda_l1 is set=0.001125581933884339, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001125581933884339
[LightGBM] [Warning] lambda_l2 is set=0.022626035801515905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.022626035801515905
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043182 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:37,705] Trial 59 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 99, &#39;num_leaves&#39;: 39, &#39;max_depth&#39;: 44, &#39;learning_rate&#39;: 0.11074490421034906, &#39;subsample&#39;: 0.6354543553034044, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 0.001125581933884339, &#39;lambda_l2&#39;: 0.022626035801515905}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.001125581933884339, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001125581933884339
[LightGBM] [Warning] lambda_l2 is set=0.022626035801515905, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.022626035801515905
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=9.728805146894944e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.728805146894944e-05
[LightGBM] [Warning] lambda_l2 is set=0.12069034704818783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12069034704818783
[LightGBM] [Warning] lambda_l1 is set=9.728805146894944e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.728805146894944e-05
[LightGBM] [Warning] lambda_l2 is set=0.12069034704818783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12069034704818783
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033958 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=9.728805146894944e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.728805146894944e-05
[LightGBM] [Warning] lambda_l2 is set=0.12069034704818783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12069034704818783
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:42,704] Trial 60 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 184, &#39;num_leaves&#39;: 33, &#39;max_depth&#39;: 22, &#39;learning_rate&#39;: 0.08028259058688623, &#39;subsample&#39;: 0.6242030001721868, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 9.728805146894944e-05, &#39;lambda_l2&#39;: 0.12069034704818783}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0005109581958963343, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005109581958963343
[LightGBM] [Warning] lambda_l2 is set=0.6966584861573881, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6966584861573881
[LightGBM] [Warning] lambda_l1 is set=0.0005109581958963343, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005109581958963343
[LightGBM] [Warning] lambda_l2 is set=0.6966584861573881, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6966584861573881
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039930 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0005109581958963343, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005109581958963343
[LightGBM] [Warning] lambda_l2 is set=0.6966584861573881, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6966584861573881
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:46,952] Trial 61 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 149, &#39;num_leaves&#39;: 41, &#39;max_depth&#39;: 48, &#39;learning_rate&#39;: 0.1794506914228734, &#39;subsample&#39;: 0.7265462537220942, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.0005109581958963343, &#39;lambda_l2&#39;: 0.6966584861573881}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0017561535009379286, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017561535009379286
[LightGBM] [Warning] lambda_l2 is set=0.30767834172429703, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30767834172429703
[LightGBM] [Warning] lambda_l1 is set=0.0017561535009379286, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017561535009379286
[LightGBM] [Warning] lambda_l2 is set=0.30767834172429703, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30767834172429703
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034274 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0017561535009379286, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017561535009379286
[LightGBM] [Warning] lambda_l2 is set=0.30767834172429703, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30767834172429703
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:50,878] Trial 62 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 119, &#39;num_leaves&#39;: 46, &#39;max_depth&#39;: 44, &#39;learning_rate&#39;: 0.15716574144913806, &#39;subsample&#39;: 0.6003392830499963, &#39;min_child_weight&#39;: 11, &#39;lambda_l1&#39;: 0.0017561535009379286, &#39;lambda_l2&#39;: 0.30767834172429703}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00020235906180219638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00020235906180219638
[LightGBM] [Warning] lambda_l2 is set=0.9533932099486341, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9533932099486341
[LightGBM] [Warning] lambda_l1 is set=0.00020235906180219638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00020235906180219638
[LightGBM] [Warning] lambda_l2 is set=0.9533932099486341, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9533932099486341
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033519 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00020235906180219638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00020235906180219638
[LightGBM] [Warning] lambda_l2 is set=0.9533932099486341, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9533932099486341
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:24:55,463] Trial 63 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 170, &#39;num_leaves&#39;: 37, &#39;max_depth&#39;: 42, &#39;learning_rate&#39;: 0.19431748678530328, &#39;subsample&#39;: 0.7423133549093633, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.00020235906180219638, &#39;lambda_l2&#39;: 0.9533932099486341}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.003256914130320319, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003256914130320319
[LightGBM] [Warning] lambda_l2 is set=0.5772536293292543, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5772536293292543
[LightGBM] [Warning] lambda_l1 is set=0.003256914130320319, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003256914130320319
[LightGBM] [Warning] lambda_l2 is set=0.5772536293292543, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5772536293292543
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032874 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.003256914130320319, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003256914130320319
[LightGBM] [Warning] lambda_l2 is set=0.5772536293292543, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5772536293292543
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:00,202] Trial 64 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 174, &#39;num_leaves&#39;: 42, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.13447552285742298, &#39;subsample&#39;: 0.6901512618586654, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 0.003256914130320319, &#39;lambda_l2&#39;: 0.5772536293292543}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0006797513544126077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006797513544126077
[LightGBM] [Warning] lambda_l2 is set=0.21655237779883366, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21655237779883366
[LightGBM] [Warning] lambda_l1 is set=0.0006797513544126077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006797513544126077
[LightGBM] [Warning] lambda_l2 is set=0.21655237779883366, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21655237779883366
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036769 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0006797513544126077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006797513544126077
[LightGBM] [Warning] lambda_l2 is set=0.21655237779883366, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21655237779883366
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:05,609] Trial 65 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 200, &#39;num_leaves&#39;: 48, &#39;max_depth&#39;: 38, &#39;learning_rate&#39;: 0.19838116639426245, &#39;subsample&#39;: 0.6684229541035756, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 0.0006797513544126077, &#39;lambda_l2&#39;: 0.21655237779883366}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.007216963555656789, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007216963555656789
[LightGBM] [Warning] lambda_l2 is set=0.3858516602233309, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3858516602233309
[LightGBM] [Warning] lambda_l1 is set=0.007216963555656789, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007216963555656789
[LightGBM] [Warning] lambda_l2 is set=0.3858516602233309, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3858516602233309
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039928 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.007216963555656789, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007216963555656789
[LightGBM] [Warning] lambda_l2 is set=0.3858516602233309, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3858516602233309
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:11,907] Trial 66 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 185, &#39;num_leaves&#39;: 44, &#39;max_depth&#39;: 13, &#39;learning_rate&#39;: 0.13979094173057896, &#39;subsample&#39;: 0.7093999002569971, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 0.007216963555656789, &#39;lambda_l2&#39;: 0.3858516602233309}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0201280286184607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0201280286184607
[LightGBM] [Warning] lambda_l2 is set=0.047705416514713314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.047705416514713314
[LightGBM] [Warning] lambda_l1 is set=0.0201280286184607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0201280286184607
[LightGBM] [Warning] lambda_l2 is set=0.047705416514713314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.047705416514713314
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041161 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0201280286184607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0201280286184607
[LightGBM] [Warning] lambda_l2 is set=0.047705416514713314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.047705416514713314
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:17,880] Trial 67 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 166, &#39;num_leaves&#39;: 48, &#39;max_depth&#39;: 17, &#39;learning_rate&#39;: 0.1011747264276488, &#39;subsample&#39;: 0.6544139334221879, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 0.0201280286184607, &#39;lambda_l2&#39;: 0.047705416514713314}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00044733647430462054, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00044733647430462054
[LightGBM] [Warning] lambda_l2 is set=0.10038025359911261, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10038025359911261
[LightGBM] [Warning] lambda_l1 is set=0.00044733647430462054, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00044733647430462054
[LightGBM] [Warning] lambda_l2 is set=0.10038025359911261, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10038025359911261
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041530 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00044733647430462054, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00044733647430462054
[LightGBM] [Warning] lambda_l2 is set=0.10038025359911261, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10038025359911261
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:22,822] Trial 68 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 155, &#39;num_leaves&#39;: 35, &#39;max_depth&#39;: 10, &#39;learning_rate&#39;: 0.11899477097561333, &#39;subsample&#39;: 0.6098502354119593, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.00044733647430462054, &#39;lambda_l2&#39;: 0.10038025359911261}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00028303958339130197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00028303958339130197
[LightGBM] [Warning] lambda_l2 is set=0.20117915943381173, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20117915943381173
[LightGBM] [Warning] lambda_l1 is set=0.00028303958339130197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00028303958339130197
[LightGBM] [Warning] lambda_l2 is set=0.20117915943381173, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20117915943381173
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044721 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00028303958339130197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00028303958339130197
[LightGBM] [Warning] lambda_l2 is set=0.20117915943381173, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20117915943381173
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:26,956] Trial 69 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 131, &#39;num_leaves&#39;: 32, &#39;max_depth&#39;: 50, &#39;learning_rate&#39;: 0.16121687617401517, &#39;subsample&#39;: 0.6275043429986976, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 0.00028303958339130197, &#39;lambda_l2&#39;: 0.20117915943381173}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0008636911004780502, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008636911004780502
[LightGBM] [Warning] lambda_l2 is set=0.010429128866125485, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.010429128866125485
[LightGBM] [Warning] lambda_l1 is set=0.0008636911004780502, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008636911004780502
[LightGBM] [Warning] lambda_l2 is set=0.010429128866125485, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.010429128866125485
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043451 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0008636911004780502, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008636911004780502
[LightGBM] [Warning] lambda_l2 is set=0.010429128866125485, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.010429128866125485
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:33,559] Trial 70 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 194, &#39;num_leaves&#39;: 38, &#39;max_depth&#39;: 29, &#39;learning_rate&#39;: 0.08773154486569101, &#39;subsample&#39;: 0.6821690818561901, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 0.0008636911004780502, &#39;lambda_l2&#39;: 0.010429128866125485}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00019712962497602893, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019712962497602893
[LightGBM] [Warning] lambda_l2 is set=0.07956251198088399, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07956251198088399
[LightGBM] [Warning] lambda_l1 is set=0.00019712962497602893, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019712962497602893
[LightGBM] [Warning] lambda_l2 is set=0.07956251198088399, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07956251198088399
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063460 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00019712962497602893, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00019712962497602893
[LightGBM] [Warning] lambda_l2 is set=0.07956251198088399, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07956251198088399
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:39,452] Trial 71 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 188, &#39;num_leaves&#39;: 36, &#39;max_depth&#39;: 12, &#39;learning_rate&#39;: 0.17911095588045384, &#39;subsample&#39;: 0.6143235820794062, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.00019712962497602893, &#39;lambda_l2&#39;: 0.07956251198088399}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00011226277775886284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00011226277775886284
[LightGBM] [Warning] lambda_l2 is set=0.29377778504539664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29377778504539664
[LightGBM] [Warning] lambda_l1 is set=0.00011226277775886284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00011226277775886284
[LightGBM] [Warning] lambda_l2 is set=0.29377778504539664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29377778504539664
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038553 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00011226277775886284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00011226277775886284
[LightGBM] [Warning] lambda_l2 is set=0.29377778504539664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29377778504539664
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:45,643] Trial 72 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 178, &#39;num_leaves&#39;: 34, &#39;max_depth&#39;: 9, &#39;learning_rate&#39;: 0.14024172093529902, &#39;subsample&#39;: 0.6408411693966237, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 0.00011226277775886284, &#39;lambda_l2&#39;: 0.29377778504539664}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.500637209493499e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.500637209493499e-05
[LightGBM] [Warning] lambda_l2 is set=0.15179493520676696, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15179493520676696
[LightGBM] [Warning] lambda_l1 is set=7.500637209493499e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.500637209493499e-05
[LightGBM] [Warning] lambda_l2 is set=0.15179493520676696, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15179493520676696
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041589 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=7.500637209493499e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.500637209493499e-05
[LightGBM] [Warning] lambda_l2 is set=0.15179493520676696, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15179493520676696
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:50,576] Trial 73 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 196, &#39;num_leaves&#39;: 39, &#39;max_depth&#39;: 5, &#39;learning_rate&#39;: 0.17191289582582403, &#39;subsample&#39;: 0.6005023065093525, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 7.500637209493499e-05, &#39;lambda_l2&#39;: 0.15179493520676696}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.000368050996613337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000368050996613337
[LightGBM] [Warning] lambda_l2 is set=0.9756106857085353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9756106857085353
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=0.000368050996613337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000368050996613337
[LightGBM] [Warning] lambda_l2 is set=0.9756106857085353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9756106857085353
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044938 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.000368050996613337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000368050996613337
[LightGBM] [Warning] lambda_l2 is set=0.9756106857085353, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9756106857085353
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:25:56,575] Trial 74 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 200, &#39;num_leaves&#39;: 31, &#39;max_depth&#39;: 14, &#39;learning_rate&#39;: 0.12257830826585385, &#39;subsample&#39;: 0.6236629539520651, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.000368050996613337, &#39;lambda_l2&#39;: 0.9756106857085353}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00014496883035480714, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00014496883035480714
[LightGBM] [Warning] lambda_l2 is set=0.3996396970853748, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3996396970853748
[LightGBM] [Warning] lambda_l1 is set=0.00014496883035480714, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00014496883035480714
[LightGBM] [Warning] lambda_l2 is set=0.3996396970853748, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3996396970853748
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038601 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00014496883035480714, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00014496883035480714
[LightGBM] [Warning] lambda_l2 is set=0.3996396970853748, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3996396970853748
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:01,645] Trial 75 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 181, &#39;num_leaves&#39;: 41, &#39;max_depth&#39;: 20, &#39;learning_rate&#39;: 0.14936564485015594, &#39;subsample&#39;: 0.6466439574206361, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 0.00014496883035480714, &#39;lambda_l2&#39;: 0.3996396970853748}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0014164318192995485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0014164318192995485
[LightGBM] [Warning] lambda_l2 is set=0.03749902675386078, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03749902675386078
[LightGBM] [Warning] lambda_l1 is set=0.0014164318192995485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0014164318192995485
[LightGBM] [Warning] lambda_l2 is set=0.03749902675386078, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03749902675386078
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044858 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0014164318192995485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0014164318192995485
[LightGBM] [Warning] lambda_l2 is set=0.03749902675386078, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03749902675386078
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:06,881] Trial 76 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 190, &#39;num_leaves&#39;: 28, &#39;max_depth&#39;: 15, &#39;learning_rate&#39;: 0.09736040757516827, &#39;subsample&#39;: 0.6302776445590025, &#39;min_child_weight&#39;: 15, &#39;lambda_l1&#39;: 0.0014164318192995485, &#39;lambda_l2&#39;: 0.03749902675386078}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00021661894265937533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021661894265937533
[LightGBM] [Warning] lambda_l2 is set=0.07294456026408444, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07294456026408444
[LightGBM] [Warning] lambda_l1 is set=0.00021661894265937533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021661894265937533
[LightGBM] [Warning] lambda_l2 is set=0.07294456026408444, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07294456026408444
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045402 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00021661894265937533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021661894265937533
[LightGBM] [Warning] lambda_l2 is set=0.07294456026408444, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07294456026408444
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:11,432] Trial 77 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 172, &#39;num_leaves&#39;: 33, &#39;max_depth&#39;: 24, &#39;learning_rate&#39;: 0.17387224867179957, &#39;subsample&#39;: 0.6127341673118505, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 0.00021661894265937533, &#39;lambda_l2&#39;: 0.07294456026408444}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=5.164968876087045e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.164968876087045e-05
[LightGBM] [Warning] lambda_l2 is set=0.023761812281363176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023761812281363176
[LightGBM] [Warning] lambda_l1 is set=5.164968876087045e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.164968876087045e-05
[LightGBM] [Warning] lambda_l2 is set=0.023761812281363176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023761812281363176
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039169 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=5.164968876087045e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.164968876087045e-05
[LightGBM] [Warning] lambda_l2 is set=0.023761812281363176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023761812281363176
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:15,941] Trial 78 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 161, &#39;num_leaves&#39;: 36, &#39;max_depth&#39;: 18, &#39;learning_rate&#39;: 0.12934005513735528, &#39;subsample&#39;: 0.6636036815650226, &#39;min_child_weight&#39;: 12, &#39;lambda_l1&#39;: 5.164968876087045e-05, &#39;lambda_l2&#39;: 0.023761812281363176}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0006088806028554963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006088806028554963
[LightGBM] [Warning] lambda_l2 is set=0.05580265222068701, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05580265222068701
[LightGBM] [Warning] lambda_l1 is set=0.0006088806028554963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006088806028554963
[LightGBM] [Warning] lambda_l2 is set=0.05580265222068701, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05580265222068701
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036806 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:17,724] Trial 79 finished with value: 0.9992526487009276 and parameters: {&#39;n_estimators&#39;: 77, &#39;num_leaves&#39;: 11, &#39;max_depth&#39;: 34, &#39;learning_rate&#39;: 0.19753618206871412, &#39;subsample&#39;: 0.6093015386604425, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 0.0006088806028554963, &#39;lambda_l2&#39;: 0.05580265222068701}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0006088806028554963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0006088806028554963
[LightGBM] [Warning] lambda_l2 is set=0.05580265222068701, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05580265222068701
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0009017131372107724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009017131372107724
[LightGBM] [Warning] lambda_l2 is set=0.12678151913652252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12678151913652252
[LightGBM] [Warning] lambda_l1 is set=0.0009017131372107724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009017131372107724
[LightGBM] [Warning] lambda_l2 is set=0.12678151913652252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12678151913652252
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027703 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0009017131372107724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009017131372107724
[LightGBM] [Warning] lambda_l2 is set=0.12678151913652252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12678151913652252
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:21,567] Trial 80 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 143, &#39;num_leaves&#39;: 30, &#39;max_depth&#39;: 11, &#39;learning_rate&#39;: 0.11125279290230018, &#39;subsample&#39;: 0.7218745132257647, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 0.0009017131372107724, &#39;lambda_l2&#39;: 0.12678151913652252}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00033991637955231384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00033991637955231384
[LightGBM] [Warning] lambda_l2 is set=0.5884785398030011, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5884785398030011
[LightGBM] [Warning] lambda_l1 is set=0.00033991637955231384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00033991637955231384
[LightGBM] [Warning] lambda_l2 is set=0.5884785398030011, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5884785398030011
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034718 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=0.00033991637955231384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00033991637955231384
[LightGBM] [Warning] lambda_l2 is set=0.5884785398030011, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5884785398030011
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:26,770] Trial 81 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 196, &#39;num_leaves&#39;: 35, &#39;max_depth&#39;: 10, &#39;learning_rate&#39;: 0.06070690664588626, &#39;subsample&#39;: 0.6196497243527137, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.00033991637955231384, &#39;lambda_l2&#39;: 0.5884785398030011}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00010192634615249165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010192634615249165
[LightGBM] [Warning] lambda_l2 is set=0.24028672170858198, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24028672170858198
[LightGBM] [Warning] lambda_l1 is set=0.00010192634615249165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010192634615249165
[LightGBM] [Warning] lambda_l2 is set=0.24028672170858198, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24028672170858198
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041129 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00010192634615249165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010192634615249165
[LightGBM] [Warning] lambda_l2 is set=0.24028672170858198, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24028672170858198
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:30,813] Trial 82 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 187, &#39;num_leaves&#39;: 33, &#39;max_depth&#39;: 6, &#39;learning_rate&#39;: 0.07436272682416654, &#39;subsample&#39;: 0.6383414455045859, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 0.00010192634615249165, &#39;lambda_l2&#39;: 0.24028672170858198}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00018970941443302748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018970941443302748
[LightGBM] [Warning] lambda_l2 is set=0.16860821341252982, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16860821341252982
[LightGBM] [Warning] lambda_l1 is set=0.00018970941443302748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018970941443302748
[LightGBM] [Warning] lambda_l2 is set=0.16860821341252982, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16860821341252982
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033881 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00018970941443302748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018970941443302748
[LightGBM] [Warning] lambda_l2 is set=0.16860821341252982, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16860821341252982
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:35,662] Trial 83 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 192, &#39;num_leaves&#39;: 37, &#39;max_depth&#39;: 12, &#39;learning_rate&#39;: 0.048750207442813796, &#39;subsample&#39;: 0.607354066237618, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 0.00018970941443302748, &#39;lambda_l2&#39;: 0.16860821341252982}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0001524296201190945, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001524296201190945
[LightGBM] [Warning] lambda_l2 is set=0.42602460377154955, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42602460377154955
[LightGBM] [Warning] lambda_l1 is set=0.0001524296201190945, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001524296201190945
[LightGBM] [Warning] lambda_l2 is set=0.42602460377154955, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42602460377154955
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037731 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0001524296201190945, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001524296201190945
[LightGBM] [Warning] lambda_l2 is set=0.42602460377154955, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42602460377154955
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:40,003] Trial 84 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 177, &#39;num_leaves&#39;: 32, &#39;max_depth&#39;: 8, &#39;learning_rate&#39;: 0.14821078599632595, &#39;subsample&#39;: 0.6280271310659811, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.0001524296201190945, &#39;lambda_l2&#39;: 0.42602460377154955}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.202971814245476e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.202971814245476e-05
[LightGBM] [Warning] lambda_l2 is set=0.27968904640580433, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27968904640580433
[LightGBM] [Warning] lambda_l1 is set=7.202971814245476e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.202971814245476e-05
[LightGBM] [Warning] lambda_l2 is set=0.27968904640580433, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27968904640580433
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037392 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:42,704] Trial 85 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 85, &#39;num_leaves&#39;: 45, &#39;max_depth&#39;: 16, &#39;learning_rate&#39;: 0.08794738155841365, &#39;subsample&#39;: 0.6498915436998526, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 7.202971814245476e-05, &#39;lambda_l2&#39;: 0.27968904640580433}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=7.202971814245476e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.202971814245476e-05
[LightGBM] [Warning] lambda_l2 is set=0.27968904640580433, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27968904640580433
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00038483842440746396, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00038483842440746396
[LightGBM] [Warning] lambda_l2 is set=0.08836651293017192, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08836651293017192
[LightGBM] [Warning] lambda_l1 is set=0.00038483842440746396, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00038483842440746396
[LightGBM] [Warning] lambda_l2 is set=0.08836651293017192, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08836651293017192
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044798 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00038483842440746396, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00038483842440746396
[LightGBM] [Warning] lambda_l2 is set=0.08836651293017192, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08836651293017192
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:48,258] Trial 86 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 182, &#39;num_leaves&#39;: 26, &#39;max_depth&#39;: 26, &#39;learning_rate&#39;: 0.1069217067094131, &#39;subsample&#39;: 0.6182075338060655, &#39;min_child_weight&#39;: 10, &#39;lambda_l1&#39;: 0.00038483842440746396, &#39;lambda_l2&#39;: 0.08836651293017192}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0001247918164731571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001247918164731571
[LightGBM] [Warning] lambda_l2 is set=0.714097688690101, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.714097688690101
[LightGBM] [Warning] lambda_l1 is set=0.0001247918164731571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001247918164731571
[LightGBM] [Warning] lambda_l2 is set=0.714097688690101, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.714097688690101
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038400 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0001247918164731571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001247918164731571
[LightGBM] [Warning] lambda_l2 is set=0.714097688690101, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.714097688690101
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:26:54,612] Trial 87 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 197, &#39;num_leaves&#39;: 40, &#39;max_depth&#39;: 13, &#39;learning_rate&#39;: 0.0670508416170121, &#39;subsample&#39;: 0.6002508144372556, &#39;min_child_weight&#39;: 11, &#39;lambda_l1&#39;: 0.0001247918164731571, &#39;lambda_l2&#39;: 0.714097688690101}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.8479306126799758e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8479306126799758e-05
[LightGBM] [Warning] lambda_l2 is set=0.12189118177589521, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12189118177589521
[LightGBM] [Warning] lambda_l1 is set=2.8479306126799758e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8479306126799758e-05
[LightGBM] [Warning] lambda_l2 is set=0.12189118177589521, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12189118177589521
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030554 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] lambda_l1 is set=2.8479306126799758e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8479306126799758e-05
[LightGBM] [Warning] lambda_l2 is set=0.12189118177589521, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12189118177589521
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:00,499] Trial 88 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 186, &#39;num_leaves&#39;: 34, &#39;max_depth&#39;: 21, &#39;learning_rate&#39;: 0.12242017960161652, &#39;subsample&#39;: 0.6599375745767462, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 2.8479306126799758e-05, &#39;lambda_l2&#39;: 0.12189118177589521}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.03565245142180677, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03565245142180677
[LightGBM] [Warning] lambda_l2 is set=0.0039562732499717895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0039562732499717895
[LightGBM] [Warning] lambda_l1 is set=0.03565245142180677, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03565245142180677
[LightGBM] [Warning] lambda_l2 is set=0.0039562732499717895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0039562732499717895
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041970 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:01,854] Trial 89 finished with value: 0.9935156284345188 and parameters: {&#39;n_estimators&#39;: 26, &#39;num_leaves&#39;: 30, &#39;max_depth&#39;: 19, &#39;learning_rate&#39;: 0.150795755751722, &#39;subsample&#39;: 0.6923166036317501, &#39;min_child_weight&#39;: 3, &#39;lambda_l1&#39;: 0.03565245142180677, &#39;lambda_l2&#39;: 0.0039562732499717895}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.03565245142180677, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03565245142180677
[LightGBM] [Warning] lambda_l2 is set=0.0039562732499717895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0039562732499717895
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.00024129705324223594, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00024129705324223594
[LightGBM] [Warning] lambda_l2 is set=0.05687534513972259, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05687534513972259
[LightGBM] [Warning] lambda_l1 is set=0.00024129705324223594, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00024129705324223594
[LightGBM] [Warning] lambda_l2 is set=0.05687534513972259, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05687534513972259
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042002 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.00024129705324223594, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00024129705324223594
[LightGBM] [Warning] lambda_l2 is set=0.05687534513972259, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05687534513972259
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:07,284] Trial 90 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 168, &#39;num_leaves&#39;: 39, &#39;max_depth&#39;: 40, &#39;learning_rate&#39;: 0.07696375248490306, &#39;subsample&#39;: 0.6344123219106951, &#39;min_child_weight&#39;: 13, &#39;lambda_l1&#39;: 0.00024129705324223594, &#39;lambda_l2&#39;: 0.05687534513972259}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0005996503821638292, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005996503821638292
[LightGBM] [Warning] lambda_l2 is set=0.03390170870501376, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03390170870501376
[LightGBM] [Warning] lambda_l1 is set=0.0005996503821638292, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005996503821638292
[LightGBM] [Warning] lambda_l2 is set=0.03390170870501376, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03390170870501376
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040911 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0005996503821638292, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005996503821638292
[LightGBM] [Warning] lambda_l2 is set=0.03390170870501376, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03390170870501376
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:12,815] Trial 91 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 191, &#39;num_leaves&#39;: 50, &#39;max_depth&#39;: 14, &#39;learning_rate&#39;: 0.1736748073322487, &#39;subsample&#39;: 0.6171522754082762, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 0.0005996503821638292, &#39;lambda_l2&#39;: 0.03390170870501376}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.5663349793735516, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5663349793735516
[LightGBM] [Warning] lambda_l2 is set=0.20875808302409063, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20875808302409063
[LightGBM] [Warning] lambda_l1 is set=0.5663349793735516, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5663349793735516
[LightGBM] [Warning] lambda_l2 is set=0.20875808302409063, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20875808302409063
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040176 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.5663349793735516, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5663349793735516
[LightGBM] [Warning] lambda_l2 is set=0.20875808302409063, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20875808302409063
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:18,280] Trial 92 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 180, &#39;num_leaves&#39;: 28, &#39;max_depth&#39;: 16, &#39;learning_rate&#39;: 0.13384450717993449, &#39;subsample&#39;: 0.7019872931538748, &#39;min_child_weight&#39;: 7, &#39;lambda_l1&#39;: 0.5663349793735516, &#39;lambda_l2&#39;: 0.20875808302409063}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0010776242717791954, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010776242717791954
[LightGBM] [Warning] lambda_l2 is set=0.0011921540240373346, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011921540240373346
[LightGBM] [Warning] lambda_l1 is set=0.0010776242717791954, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010776242717791954
[LightGBM] [Warning] lambda_l2 is set=0.0011921540240373346, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011921540240373346
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045216 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0010776242717791954, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010776242717791954
[LightGBM] [Warning] lambda_l2 is set=0.0011921540240373346, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011921540240373346
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:24,249] Trial 93 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 200, &#39;num_leaves&#39;: 25, &#39;max_depth&#39;: 11, &#39;learning_rate&#39;: 0.15070764802302156, &#39;subsample&#39;: 0.6743237686833508, &#39;min_child_weight&#39;: 5, &#39;lambda_l1&#39;: 0.0010776242717791954, &#39;lambda_l2&#39;: 0.0011921540240373346}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0003291289002337415, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003291289002337415
[LightGBM] [Warning] lambda_l2 is set=0.10799281774701464, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10799281774701464
[LightGBM] [Warning] lambda_l1 is set=0.0003291289002337415, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003291289002337415
[LightGBM] [Warning] lambda_l2 is set=0.10799281774701464, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10799281774701464
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040482 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0003291289002337415, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003291289002337415
[LightGBM] [Warning] lambda_l2 is set=0.10799281774701464, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10799281774701464
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:29,607] Trial 94 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 193, &#39;num_leaves&#39;: 29, &#39;max_depth&#39;: 9, &#39;learning_rate&#39;: 0.09914182520951488, &#39;subsample&#39;: 0.6090305653136627, &#39;min_child_weight&#39;: 2, &#39;lambda_l1&#39;: 0.0003291289002337415, &#39;lambda_l2&#39;: 0.10799281774701464}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0004546622757648482, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004546622757648482
[LightGBM] [Warning] lambda_l2 is set=0.06992276182136915, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06992276182136915
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] lambda_l1 is set=0.0004546622757648482, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004546622757648482
[LightGBM] [Warning] lambda_l2 is set=0.06992276182136915, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06992276182136915
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041243 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0004546622757648482, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004546622757648482
[LightGBM] [Warning] lambda_l2 is set=0.06992276182136915, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06992276182136915
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:32,975] Trial 95 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 104, &#39;num_leaves&#39;: 31, &#39;max_depth&#39;: 18, &#39;learning_rate&#39;: 0.1761702968702763, &#39;subsample&#39;: 0.6438390265662547, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.0004546622757648482, &#39;lambda_l2&#39;: 0.06992276182136915}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.11046564279389143, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11046564279389143
[LightGBM] [Warning] lambda_l2 is set=0.04126628676623815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04126628676623815
[LightGBM] [Warning] lambda_l1 is set=0.11046564279389143, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11046564279389143
[LightGBM] [Warning] lambda_l2 is set=0.04126628676623815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04126628676623815
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041644 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.11046564279389143, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11046564279389143
[LightGBM] [Warning] lambda_l2 is set=0.04126628676623815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04126628676623815
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:38,400] Trial 96 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 186, &#39;num_leaves&#39;: 37, &#39;max_depth&#39;: 14, &#39;learning_rate&#39;: 0.05664354415643028, &#39;subsample&#39;: 0.628738863107996, &#39;min_child_weight&#39;: 4, &#39;lambda_l1&#39;: 0.11046564279389143, &#39;lambda_l2&#39;: 0.04126628676623815}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0026384944094387957, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0026384944094387957
[LightGBM] [Warning] lambda_l2 is set=0.17173970436286515, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17173970436286515
[LightGBM] [Warning] lambda_l1 is set=0.0026384944094387957, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0026384944094387957
[LightGBM] [Warning] lambda_l2 is set=0.17173970436286515, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17173970436286515
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038371 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0026384944094387957, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0026384944094387957
[LightGBM] [Warning] lambda_l2 is set=0.17173970436286515, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17173970436286515
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:43,313] Trial 97 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 174, &#39;num_leaves&#39;: 34, &#39;max_depth&#39;: 32, &#39;learning_rate&#39;: 0.1140001186446663, &#39;subsample&#39;: 0.6237349888001834, &#39;min_child_weight&#39;: 9, &#39;lambda_l1&#39;: 0.0026384944094387957, &#39;lambda_l2&#39;: 0.17173970436286515}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0013588700863319033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013588700863319033
[LightGBM] [Warning] lambda_l2 is set=2.726030308237682e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.726030308237682e-05
[LightGBM] [Warning] lambda_l1 is set=0.0013588700863319033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013588700863319033
[LightGBM] [Warning] lambda_l2 is set=2.726030308237682e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.726030308237682e-05
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034815 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] lambda_l1 is set=0.0013588700863319033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013588700863319033
[LightGBM] [Warning] lambda_l2 is set=2.726030308237682e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.726030308237682e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:48,539] Trial 98 finished with value: 1.0 and parameters: {&#39;n_estimators&#39;: 164, &#39;num_leaves&#39;: 32, &#39;max_depth&#39;: 37, &#39;learning_rate&#39;: 0.1362776794056648, &#39;subsample&#39;: 0.608574142886984, &#39;min_child_weight&#39;: 6, &#39;lambda_l1&#39;: 0.0013588700863319033, &#39;lambda_l2&#39;: 2.726030308237682e-05}. Best is trial 6 with value: 1.0.
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;learning_rate&#39;: trial.suggest_loguniform(&#39;learning_rate&#39;, 0.001, 0.2), # Taxa de aprendizado
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  &#39;subsample&#39;: trial.suggest_uniform(&#39;subsample&#39;, 0.6, 1.0), # Subsample usado para impedir overfitting
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l1&#39;: trial.suggest_loguniform(&#39;lambda_l1&#39;, 1e-6, 1.0), # Penalização Lasso nas árvores
C:\Users\Lucas\AppData\Local\Temp\ipykernel_10400\3320587262.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  &#39;lambda_l2&#39;: trial.suggest_loguniform(&#39;lambda_l2&#39;, 1e-6, 1.0), # Penalização Ridge nas árvores
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0040949657216811895, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0040949657216811895
[LightGBM] [Warning] lambda_l2 is set=0.0017626066514385738, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017626066514385738
[LightGBM] [Warning] lambda_l1 is set=0.0040949657216811895, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0040949657216811895
[LightGBM] [Warning] lambda_l2 is set=0.0017626066514385738, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017626066514385738
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031732 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>[I 2023-10-18 03:27:50,273] Trial 99 finished with value: 0.9999780190794391 and parameters: {&#39;n_estimators&#39;: 41, &#39;num_leaves&#39;: 43, &#39;max_depth&#39;: 17, &#39;learning_rate&#39;: 0.1986239493686178, &#39;subsample&#39;: 0.6364757362552657, &#39;min_child_weight&#39;: 1, &#39;lambda_l1&#39;: 0.0040949657216811895, &#39;lambda_l2&#39;: 0.0017626066514385738}. Best is trial 6 with value: 1.0.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.0040949657216811895, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0040949657216811895
[LightGBM] [Warning] lambda_l2 is set=0.0017626066514385738, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017626066514385738

Melhores hiperparâmetros: {&#39;n_estimators&#39;: 181, &#39;num_leaves&#39;: 37, &#39;max_depth&#39;: 35, &#39;learning_rate&#39;: 0.04926240577582323, &#39;subsample&#39;: 0.7316863020085818, &#39;min_child_weight&#39;: 8, &#39;lambda_l1&#39;: 0.3828821458483766, &#39;lambda_l2&#39;: 0.00045100317062221715}

Melhor Recall: 1.0
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Treinando-o-modelo">Treinando o modelo<a class="anchor-link" href="#Treinando-o-modelo">&#182;</a></h2><ul>
<li>Utilizando os melhores parâmetros obtidos</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Criando o modelo com os melhores parâmetros encontrados</span>
<span class="n">modelo_over</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">melhores_hiperparametros_over</span><span class="p">)</span>

<span class="c1"># Treinando o modelo com os dados de Oversampling</span>
<span class="n">modelo_over</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_oversampled</span><span class="p">,</span> <span class="n">y_train_oversampled</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.3828821458483766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3828821458483766
[LightGBM] [Warning] lambda_l2 is set=0.00045100317062221715, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00045100317062221715
[LightGBM] [Warning] lambda_l1 is set=0.3828821458483766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3828821458483766
[LightGBM] [Warning] lambda_l2 is set=0.00045100317062221715, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00045100317062221715
[LightGBM] [Info] Number of positive: 181968, number of negative: 181971
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036519 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 7650
[LightGBM] [Info] Number of data points in the train set: 363939, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -&gt; initscore=-0.000016
[LightGBM] [Info] Start training from score -0.000016
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LGBMClassifier(lambda_l1=0.3828821458483766, lambda_l2=0.00045100317062221715,
               learning_rate=0.04926240577582323, max_depth=35,
               min_child_weight=8, n_estimators=181, num_leaves=37,
               subsample=0.7316863020085818)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(lambda_l1=0.3828821458483766, lambda_l2=0.00045100317062221715,
               learning_rate=0.04926240577582323, max_depth=35,
               min_child_weight=8, n_estimators=181, num_leaves=37,
               subsample=0.7316863020085818)</pre></div></div></div></div></div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Coletando os resultados da previsão</span>
<span class="n">y_pred_oversampled</span> <span class="o">=</span> <span class="n">modelo_over</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_oversampled</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.3828821458483766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3828821458483766
[LightGBM] [Warning] lambda_l2 is set=0.00045100317062221715, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00045100317062221715
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Resultados-com-Oversampling">Resultados com Oversampling<a class="anchor-link" href="#Resultados-com-Oversampling">&#182;</a></h2><ul>
<li>Com base nas métricas de Acurácia, Precision, Recall e F1-Score e na matriz de confusão, para os dados de Oversampling, pode-se concluir que <strong>o modelo teve um valor muito próximo de 100% de acerto, mas isso não é um bom sinal. Outras bases de testes devem ser aplicadas para legitimizar a qualidade do modelo.</strong></li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Coletando as métricas de classificação obtidas</span>
<span class="n">metricas</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_oversampled</span><span class="p">,</span> <span class="n">y_pred_oversampled</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metricas</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     45491
           1       1.00      1.00      1.00     45494

    accuracy                           1.00     90985
   macro avg       1.00      1.00      1.00     90985
weighted avg       1.00      1.00      1.00     90985

</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="Matriz-de-confus%C3%A3o">Matriz de confus&#227;o<a class="anchor-link" href="#Matriz-de-confus%C3%A3o">&#182;</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_oversampled</span><span class="p">,</span> <span class="n">y_pred_oversampled</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">"d"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"Blues"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Previsão do modelo'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Resultado esperado'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Matriz de confusão para dados Oversampled</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Dados-originais">Dados originais<a class="anchor-link" href="#Dados-originais">&#182;</a></h1><h4 id="Validando-os-modelos-utilizando-a-base-original">Validando os modelos utilizando a base original<a class="anchor-link" href="#Validando-os-modelos-utilizando-a-base-original">&#182;</a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Modelo-do-Undersampling">Modelo do Undersampling<a class="anchor-link" href="#Modelo-do-Undersampling">&#182;</a></h2><h4 id="Resultado:-Para-a-base-original,-o-modelo-classificou-bem-os-casos-de-n%C3%A3o-fraude,-mas-olhando-para-os-casos-de-fraude,-o-modelo-n%C3%A3o-obteve-o-resultado-esperado-em-rela%C3%A7%C3%A3o-ao-que-ele-previu,-acertando-somente-5%25-do-total-previsto-como-fraude.-A-Acur%C3%A1cia-ficou-inviesada-por-conta-da-quantidade-de-acertos-obtidos-nos-casos-de-n%C3%A3o-fraude,-e-por-isso-n%C3%A3o-%C3%A9-uma-medida-confi%C3%A1vel-neste-caso.">Resultado: Para a base original, o modelo classificou bem os casos de n&#227;o fraude, mas olhando para os casos de fraude, o modelo n&#227;o obteve o resultado esperado em rela&#231;&#227;o ao que ele previu, acertando somente 5% do total previsto como fraude. A Acur&#225;cia ficou inviesada por conta da quantidade de acertos obtidos nos casos de n&#227;o fraude, e por isso n&#227;o &#233; uma medida confi&#225;vel neste caso.<a class="anchor-link" href="#Resultado:-Para-a-base-original,-o-modelo-classificou-bem-os-casos-de-n%C3%A3o-fraude,-mas-olhando-para-os-casos-de-fraude,-o-modelo-n%C3%A3o-obteve-o-resultado-esperado-em-rela%C3%A7%C3%A3o-ao-que-ele-previu,-acertando-somente-5%25-do-total-previsto-como-fraude.-A-Acur%C3%A1cia-ficou-inviesada-por-conta-da-quantidade-de-acertos-obtidos-nos-casos-de-n%C3%A3o-fraude,-e-por-isso-n%C3%A3o-%C3%A9-uma-medida-confi%C3%A1vel-neste-caso.">&#182;</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">modelo_under</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[44]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LGBMClassifier(boosting_type=LGBMClassifier(lambda_l1=2.013838835210629e-06,
                                            lambda_l2=0.0007771472931457983,
                                            learning_rate=0.007551211447829674,
                                            max_depth=41, min_child_weight=5,
                                            n_estimators=140, num_leaves=29,
                                            subsample=0.8750804543836551))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(boosting_type=LGBMClassifier(lambda_l1=2.013838835210629e-06,
                                            lambda_l2=0.0007771472931457983,
                                            learning_rate=0.007551211447829674,
                                            max_depth=41, min_child_weight=5,
                                            n_estimators=140, num_leaves=29,
                                            subsample=0.8750804543836551))</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">boosting_type: LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(lambda_l1=2.013838835210629e-06, lambda_l2=0.0007771472931457983,
               learning_rate=0.007551211447829674, max_depth=41,
               min_child_weight=5, n_estimators=140, num_leaves=29,
               subsample=0.8750804543836551)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" ><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(lambda_l1=2.013838835210629e-06, lambda_l2=0.0007771472931457983,
               learning_rate=0.007551211447829674, max_depth=41,
               min_child_weight=5, n_estimators=140, num_leaves=29,
               subsample=0.8750804543836551)</pre></div></div></div></div></div></div></div></div></div></div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred_undersampled_original</span> <span class="o">=</span> <span class="n">modelo_under</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_original</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=2.013838835210629e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.013838835210629e-06
[LightGBM] [Warning] lambda_l2 is set=0.0007771472931457983, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007771472931457983
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Coletando as métricas de classificação obtidas</span>
<span class="n">metricas</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_original</span><span class="p">,</span> <span class="n">y_pred_undersampled_original</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metricas</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       1.00      0.97      0.98     56853
           1       0.05      0.91      0.09       109

    accuracy                           0.97     56962
   macro avg       0.52      0.94      0.54     56962
weighted avg       1.00      0.97      0.98     56962

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_original</span><span class="p">,</span> <span class="n">y_pred_undersampled_original</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">"d"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"Blues"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Previsão do modelo'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Resultado esperado'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Matriz de confusão do modelo de Undersampling com os dados originais</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Modelo-do-Oversampling">Modelo do Oversampling<a class="anchor-link" href="#Modelo-do-Oversampling">&#182;</a></h2><h4 id="Resultado:-Para-a-base-original,-ese-modelo-obteve-uma-boa-performance-no-geral,-podendo-ser-classificado-como-superior-ao-modelo-treinado-com-os-dados-do-Undersampling.-Destaque-para-85%25-de-acerto-dos-casos-previstos-como-fraude-pelo-modelo!">Resultado: Para a base original, ese modelo obteve uma boa performance no geral, podendo ser classificado como superior ao modelo treinado com os dados do Undersampling. Destaque para 85% de acerto dos casos previstos como fraude pelo modelo!<a class="anchor-link" href="#Resultado:-Para-a-base-original,-ese-modelo-obteve-uma-boa-performance-no-geral,-podendo-ser-classificado-como-superior-ao-modelo-treinado-com-os-dados-do-Undersampling.-Destaque-para-85%25-de-acerto-dos-casos-previstos-como-fraude-pelo-modelo!">&#182;</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[49]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">modelo_over</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[49]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LGBMClassifier(boosting_type=LGBMClassifier(lambda_l1=0.3828821458483766,
                                            lambda_l2=0.00045100317062221715,
                                            learning_rate=0.04926240577582323,
                                            max_depth=35, min_child_weight=8,
                                            n_estimators=181, num_leaves=37,
                                            subsample=0.7316863020085818))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(boosting_type=LGBMClassifier(lambda_l1=0.3828821458483766,
                                            lambda_l2=0.00045100317062221715,
                                            learning_rate=0.04926240577582323,
                                            max_depth=35, min_child_weight=8,
                                            n_estimators=181, num_leaves=37,
                                            subsample=0.7316863020085818))</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">boosting_type: LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(lambda_l1=0.3828821458483766, lambda_l2=0.00045100317062221715,
               learning_rate=0.04926240577582323, max_depth=35,
               min_child_weight=8, n_estimators=181, num_leaves=37,
               subsample=0.7316863020085818)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">LGBMClassifier</label><div class="sk-toggleable__content"><pre>LGBMClassifier(lambda_l1=0.3828821458483766, lambda_l2=0.00045100317062221715,
               learning_rate=0.04926240577582323, max_depth=35,
               min_child_weight=8, n_estimators=181, num_leaves=37,
               subsample=0.7316863020085818)</pre></div></div></div></div></div></div></div></div></div></div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred_oversampled_original</span> <span class="o">=</span> <span class="n">modelo_over</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_original</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[LightGBM] [Warning] lambda_l1 is set=0.3828821458483766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3828821458483766
[LightGBM] [Warning] lambda_l2 is set=0.00045100317062221715, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00045100317062221715
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Coletando as métricas de classificação obtidas</span>
<span class="n">metricas</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_original</span><span class="p">,</span> <span class="n">y_pred_oversampled_original</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metricas</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56853
           1       0.57      0.85      0.69       109

    accuracy                           1.00     56962
   macro avg       0.79      0.93      0.84     56962
weighted avg       1.00      1.00      1.00     56962

</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_original</span><span class="p">,</span> <span class="n">y_pred_oversampled_original</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">"d"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"Blues"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Previsão do modelo'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Resultado esperado'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Matriz de confusão do modelo de Oversampling com os dados originais</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
class="
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Conclus%C3%A3o">Conclus&#227;o<a class="anchor-link" href="#Conclus%C3%A3o">&#182;</a></h1><h3 id="Das-metodologias-de-balanceamento-de-classes-aplicadas,-o-Oversampling-foi-o-que-obteve-o-melhor-modelo-para-ambas-as-classes.">Das metodologias de balanceamento de classes aplicadas, o Oversampling foi o que obteve o melhor modelo para ambas as classes.<a class="anchor-link" href="#Das-metodologias-de-balanceamento-de-classes-aplicadas,-o-Oversampling-foi-o-que-obteve-o-melhor-modelo-para-ambas-as-classes.">&#182;</a></h3>
</div>
</div>
</div>
</div>
</body>







</html>
